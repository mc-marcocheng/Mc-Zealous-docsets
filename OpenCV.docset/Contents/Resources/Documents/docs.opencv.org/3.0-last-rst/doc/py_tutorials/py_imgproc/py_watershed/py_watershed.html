<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  
<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:29 GMT -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Image Segmentation with Watershed Algorithm</title>
    
    <link rel="stylesheet" href="../../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '3.0.0-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../_static/insertIframe.js"></script>
    <link rel="top" title="OpenCV 3.0.0-dev documentation" href="../../../../index.html" />
    <link rel="up" title="Image Processing in OpenCV" href="../py_table_of_contents_imgproc/py_table_of_contents_imgproc.html" />
    <link rel="next" title="Interactive Foreground Extraction using GrabCut Algorithm" href="../py_grabcut/py_grabcut.html" />
    <link rel="prev" title="Hough Circle Transform" href="../py_houghcircles/py_houghcircles.html" />
    <link href='../../../../../../fonts.googleapis.com/css8a7c.css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
    </style>
    <script type="text/javascript">
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py_grabcut/py_grabcut.html" title="Interactive Foreground Extraction using GrabCut Algorithm"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../py_houghcircles/py_houghcircles.html" title="Hough Circle Transform"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../py_tutorials.html" >OpenCV-Python Tutorials</a> &raquo;</li>
          <li><a href="../py_table_of_contents_imgproc/py_table_of_contents_imgproc.html" accesskey="U">Image Processing in OpenCV</a> &raquo;</li> 
      </ul>
    </div>  
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../index.html">
              <img class="logo" src="../../../../_static/opencv-logo2.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="http://docs.opencv.org/3.0-last-rst/search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Image Segmentation with Watershed Algorithm</a><ul>
<li><a class="reference internal" href="#goal">Goal</a></li>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#code">Code</a></li>
<li><a class="reference internal" href="#additional-resources">Additional Resources</a></li>
<li><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../py_houghcircles/py_houghcircles.html"
                        title="previous chapter">Hough Circle Transform</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../py_grabcut/py_grabcut.html"
                        title="next chapter">Interactive Foreground Extraction using GrabCut Algorithm</a></p>
        </div>
      </div>
  <body>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="image-segmentation-with-watershed-algorithm">
<span id="watershed"></span><h1>Image Segmentation with Watershed Algorithm<a class="headerlink" href="#image-segmentation-with-watershed-algorithm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="goal">
<h2>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt>In this chapter,</dt>
<dd><ul class="first last simple">
<li>We will learn to use marker-based image segmentation using watershed algorithm</li>
<li>We will see: <strong>cv2.watershed()</strong></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Permalink to this headline">¶</a></h2>
<p>Any grayscale image can be viewed as a topographic surface where high intensity denotes peaks and hills while low intensity denotes valleys. You start filling every isolated valleys (local minima) with different colored water (labels). As the water rises, depending on the peaks (gradients) nearby, water from different valleys, obviously with different colors will start to merge. To avoid that, you build barriers in the locations where water merges. You continue the work of filling water and building barriers until all the peaks are under water. Then the barriers you created gives you the segmentation result. This is the &#8220;philosophy&#8221; behind the watershed. You can visit the <a class="reference external" href="http://cmm.ensmp.fr/~beucher/wtshed.html">CMM webpage on watershed</a> to understand it with the help of some animations.</p>
<p>But this approach gives you oversegmented result due to noise or any other irregularities in the image. So OpenCV implemented a marker-based watershed algorithm where you specify which are all valley points are to be merged and which are not. It is an interactive image segmentation. What we do is to give different labels for our object we know. Label the region which we are sure of being the foreground or object with one color (or intensity), label the region which we are sure of being background or non-object with another color and finally the region which we are not sure of anything, label it with 0. That is our marker. Then apply watershed algorithm. Then our marker will be updated with the labels we gave, and the boundaries of objects will have a value of -1.</p>
</div>
<div class="section" id="code">
<h2>Code<a class="headerlink" href="#code" title="Permalink to this headline">¶</a></h2>
<p>Below we will see an example on how to use the Distance Transform along with watershed to segment mutually touching objects.</p>
<p>Consider the coins image below, the coins are touching each other. Even if you threshold it, it will be touching each other.</p>
<blockquote>
<div><img alt="Coins" class="align-center" src="../../../../_images/water_coins.jpg" />
</div></blockquote>
<p>We start with finding an approximate estimate of the coins. For that, we can use the Otsu&#8217;s binarization.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">&#39;coins.png&#39;</span><span class="p">)</span>
<span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">ret</span><span class="p">,</span> <span class="n">thresh</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_BINARY_INV</span><span class="o">+</span><span class="n">cv2</span><span class="o">.</span><span class="n">THRESH_OTSU</span><span class="p">)</span>
</pre></div>
</div>
<p>Result:</p>
<blockquote>
<div><img alt="Thresholding" class="align-center" src="../../../../_images/water_thresh.jpg" />
</div></blockquote>
<p>Now we need to remove any small white noises in the image. For that we can use morphological opening. To remove any small holes in the object, we can use morphological closing. So, now we know for sure that region near to center of objects are foreground and region much away from the object are background. Only region we are not sure is the boundary region of coins.</p>
<p>So we need to extract the area which we are sure they are coins. Erosion removes the boundary pixels. So whatever remaining, we can be sure it is coin. That would work if objects were not touching each other. But since they are touching each other, another good option would be to find the distance transform and apply a proper threshold. Next we need to find the area which we are sure they are not coins. For that, we dilate the result. Dilation increases object boundary to background. This way, we can make sure whatever region in background in result is really a background, since boundary region is removed. See the image below.</p>
<blockquote>
<div><img alt="Foreground and Background" class="align-center" src="../../../../_images/water_fgbg.jpg" />
</div></blockquote>
<p>The remaining regions are those which we don&#8217;t have any idea, whether it is coins or background. Watershed algorithm should find it. These areas are normally around the boundaries of coins where foreground and background meet (Or even two different coins meet). We call it border. It can be obtained from subtracting sure_fg area from sure_bg area.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># noise removal</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">opening</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">morphologyEx</span><span class="p">(</span><span class="n">thresh</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_OPEN</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="c"># sure background area</span>
<span class="n">sure_bg</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dilate</span><span class="p">(</span><span class="n">opening</span><span class="p">,</span><span class="n">kernel</span><span class="p">,</span><span class="n">iterations</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c"># Finding sure foreground area</span>
<span class="n">dist_transform</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">distanceTransform</span><span class="p">(</span><span class="n">opening</span><span class="p">,</span><span class="n">cv2</span><span class="o">.</span><span class="n">DIST_L2</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ret</span><span class="p">,</span> <span class="n">sure_fg</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">dist_transform</span><span class="p">,</span><span class="mf">0.7</span><span class="o">*</span><span class="n">dist_transform</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

<span class="c"># Finding unknown region</span>
<span class="n">sure_fg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">sure_fg</span><span class="p">)</span>
<span class="n">unknown</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">sure_bg</span><span class="p">,</span><span class="n">sure_fg</span><span class="p">)</span>
</pre></div>
</div>
<p>See the result. In the thresholded image, we get some regions of coins which we are sure of coins and they are detached now. (In some cases, you may be interested in only foreground segmentation, not in separating the mutually touching objects. In that case, you need not use distance transform, just erosion is sufficient. Erosion is just another method to extract sure foreground area, that&#8217;s all.)</p>
<blockquote>
<div><img alt="Distance Transform" class="align-center" src="../../../../_images/water_dt.jpg" />
</div></blockquote>
<p>Now we know for sure which are region of coins, which are background and all. So we create marker (it is an array of same size as that of original image, but with int32 datatype) and label the regions inside it. The regions we know for sure (whether foreground or background) are labelled with any positive integers, but different integers, and the area we don&#8217;t know for sure are just left as zero. For this we use <strong>cv2.connectedComponents()</strong>. It labels background of the image with 0, then other objects are labelled with integers starting from 1.</p>
<p>But we know that if background is marked with 0, watershed will consider it as unknown area. So we want to mark it with different integer. Instead, we will mark unknown region, defined by <tt class="docutils literal"><span class="pre">unknown</span></tt>, with 0.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Marker labelling</span>
<span class="n">ret</span><span class="p">,</span> <span class="n">markers</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">connectedComponents</span><span class="p">(</span><span class="n">sure_fg</span><span class="p">)</span>

<span class="c"># Add one to all labels so that sure background is not 0, but 1</span>
<span class="n">markers</span> <span class="o">=</span> <span class="n">markers</span><span class="o">+</span><span class="mi">1</span>

<span class="c"># Now, mark the region of unknown with zero</span>
<span class="n">markers</span><span class="p">[</span><span class="n">unknown</span><span class="o">==</span><span class="mi">255</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
<p>See the result shown in JET colormap. The dark blue region shows unknown region. Sure coins are colored with different values. Remaining area which are sure background are shown in lighter blue compared to unknown region.</p>
<blockquote>
<div><img alt="Marker Image" class="align-center" src="../../../../_images/water_marker.jpg" />
</div></blockquote>
<p>Now our marker is ready. It is time for final step, apply watershed. Then marker image will be modified. The boundary region will be marked with -1.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">markers</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">watershed</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">markers</span><span class="p">)</span>
<span class="n">img</span><span class="p">[</span><span class="n">markers</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>See the result below. For some coins, the region where they touch are segmented properly and for some, they are not.</p>
<blockquote>
<div><img alt="Result" class="align-center" src="../../../../_images/water_result.jpg" />
</div></blockquote>
</div>
<div class="section" id="additional-resources">
<h2>Additional Resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>CMM page on <a class="reference external" href="http://cmm.ensmp.fr/~beucher/wtshed.html">Watershed Tranformation</a></li>
</ol>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>OpenCV samples has an interactive sample on watershed segmentation, <cite>watershed.py</cite>. Run it, Enjoy it, then learn it.</li>
</ol>
</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org/">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org/">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py_grabcut/py_grabcut.html" title="Interactive Foreground Extraction using GrabCut Algorithm"
             >next</a> |</li>
        <li class="right" >
          <a href="../py_houghcircles/py_houghcircles.html" title="Hough Circle Transform"
             >previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../py_tutorials.html" >OpenCV-Python Tutorials</a> &raquo;</li>
          <li><a href="../py_table_of_contents_imgproc/py_table_of_contents_imgproc.html" >Image Processing in OpenCV</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Dec 30, 2014.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
      <a href="../../../../_sources/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.txt" rel="nofollow">Show this page source.</a>
    </div>
  </body>

<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/py_tutorials/py_imgproc/py_watershed/py_watershed.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:29 GMT -->
</html>