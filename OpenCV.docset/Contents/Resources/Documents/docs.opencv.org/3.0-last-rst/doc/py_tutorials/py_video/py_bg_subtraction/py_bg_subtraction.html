<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  
<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:36 GMT -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Background Subtraction</title>
    
    <link rel="stylesheet" href="../../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '3.0.0-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../_static/insertIframe.js"></script>
    <link rel="top" title="OpenCV 3.0.0-dev documentation" href="../../../../index.html" />
    <link rel="up" title="Video Analysis" href="../py_table_of_contents_video/py_table_of_contents_video.html" />
    <link rel="next" title="Camera Calibration and 3D Reconstruction" href="../../py_calib3d/py_table_of_contents_calib3d/py_table_of_contents_calib3d.html" />
    <link rel="prev" title="Optical Flow" href="../py_lucas_kanade/py_lucas_kanade.html" />
    <link href='../../../../../../fonts.googleapis.com/css8a7c.css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
    </style>
    <script type="text/javascript">
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py_calib3d/py_table_of_contents_calib3d/py_table_of_contents_calib3d.html" title="Camera Calibration and 3D Reconstruction"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../py_lucas_kanade/py_lucas_kanade.html" title="Optical Flow"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../py_tutorials.html" >OpenCV-Python Tutorials</a> &raquo;</li>
          <li><a href="../py_table_of_contents_video/py_table_of_contents_video.html" accesskey="U">Video Analysis</a> &raquo;</li> 
      </ul>
    </div>  
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../index.html">
              <img class="logo" src="../../../../_static/opencv-logo2.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="http://docs.opencv.org/3.0-last-rst/search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Background Subtraction</a><ul>
<li><a class="reference internal" href="#goal">Goal</a></li>
<li><a class="reference internal" href="#basics">Basics</a><ul>
<li><a class="reference internal" href="#backgroundsubtractormog">BackgroundSubtractorMOG</a></li>
<li><a class="reference internal" href="#backgroundsubtractormog2">BackgroundSubtractorMOG2</a></li>
<li><a class="reference internal" href="#backgroundsubtractorgmg">BackgroundSubtractorGMG</a></li>
</ul>
</li>
<li><a class="reference internal" href="#results">Results</a></li>
<li><a class="reference internal" href="#additional-resources">Additional Resources</a></li>
<li><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../py_lucas_kanade/py_lucas_kanade.html"
                        title="previous chapter">Optical Flow</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../../py_calib3d/py_table_of_contents_calib3d/py_table_of_contents_calib3d.html"
                        title="next chapter">Camera Calibration and 3D Reconstruction</a></p>
        </div>
      </div>
  <body>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="background-subtraction">
<span id="py-background-subtraction"></span><h1>Background Subtraction<a class="headerlink" href="#background-subtraction" title="Permalink to this headline">¶</a></h1>
<div class="section" id="goal">
<h2>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h2>
<p>In this chapter,</p>
<blockquote>
<div><ul class="simple">
<li>We will familiarize with the background subtraction methods available in OpenCV.</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="basics">
<h2>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h2>
<p>Background subtraction is a major preprocessing steps in many vision based applications. For example, consider the cases like visitor counter where a static camera takes the number of visitors entering or leaving the room, or a traffic camera extracting information about the vehicles etc. In all these cases, first you need to extract the person or vehicles alone. Technically, you need to extract the moving foreground from static background.</p>
<p>If you have an image of background alone, like image of the room without visitors, image of the road without vehicles etc, it is an easy job. Just subtract the new image from the background. You get the foreground objects alone. But in most of the cases, you may not have such an image, so we need to extract the background from whatever images we have. It become more complicated when there is shadow of the vehicles. Since shadow is also moving, simple subtraction will mark that also as foreground. It complicates things.</p>
<p>Several algorithms were introduced for this purpose. OpenCV has implemented three such algorithms which is very easy to use. We will see them one-by-one.</p>
<div class="section" id="backgroundsubtractormog">
<h3>BackgroundSubtractorMOG<a class="headerlink" href="#backgroundsubtractormog" title="Permalink to this headline">¶</a></h3>
<p>It is a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It was introduced in the paper &#8220;An improved adaptive background mixture model for real-time tracking with shadow detection&#8221; by P. KadewTraKuPong and R. Bowden in 2001. It uses a method to model each background pixel by a mixture of K Gaussian distributions (K = 3 to 5). The weights of the mixture represent the time proportions that those colours stay in the scene. The probable background colours are the ones which stay longer and more static.</p>
<p>While coding, we need to create a background object using the function, <strong>cv2.createBackgroundSubtractorMOG()</strong>. It has some optional parameters like length of history, number of gaussian mixtures, threshold etc. It is all set to some default values. Then inside the video loop, use <tt class="docutils literal"><span class="pre">backgroundsubtractor.apply()</span></tt> method to get the foreground mask.</p>
<p>See a simple example below:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s">&#39;vtest.avi&#39;</span><span class="p">)</span>

<span class="n">fgbg</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">createBackgroundSubtractorMOG</span><span class="p">()</span>

<span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

    <span class="n">fgmask</span> <span class="o">=</span> <span class="n">fgbg</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">&#39;frame&#39;</span><span class="p">,</span><span class="n">fgmask</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">27</span><span class="p">:</span>
        <span class="k">break</span>

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
<p>( All the results are shown at the end for comparison).</p>
</div>
<div class="section" id="backgroundsubtractormog2">
<h3>BackgroundSubtractorMOG2<a class="headerlink" href="#backgroundsubtractormog2" title="Permalink to this headline">¶</a></h3>
<p>It is also a Gaussian Mixture-based Background/Foreground Segmentation Algorithm. It is based on two papers by Z.Zivkovic, &#8220;Improved adaptive Gausian mixture model for background subtraction&#8221; in 2004 and &#8220;Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction&#8221; in 2006. One important feature of this algorithm is that it selects the appropriate number of gaussian distribution for each pixel. (Remember, in last case, we took a K gaussian distributions throughout the algorithm). It provides better adaptibility to varying scenes due illumination changes etc.</p>
<p>As in previous case, we have to create a background subtractor object. Here, you have an option of selecting whether shadow to be detected or not. If <tt class="docutils literal"><span class="pre">detectShadows</span> <span class="pre">=</span> <span class="pre">True</span></tt> (which is so by default), it detects and marks shadows, but decreases the speed. Shadows will be marked in gray color.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s">&#39;vtest.avi&#39;</span><span class="p">)</span>

<span class="n">fgbg</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">createBackgroundSubtractorMOG2</span><span class="p">()</span>

<span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

    <span class="n">fgmask</span> <span class="o">=</span> <span class="n">fgbg</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">&#39;frame&#39;</span><span class="p">,</span><span class="n">fgmask</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">27</span><span class="p">:</span>
        <span class="k">break</span>

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
<p>(Results given at the end)</p>
</div>
<div class="section" id="backgroundsubtractorgmg">
<h3>BackgroundSubtractorGMG<a class="headerlink" href="#backgroundsubtractorgmg" title="Permalink to this headline">¶</a></h3>
<p>This algorithm combines statistical background image estimation and per-pixel Bayesian segmentation. It was introduced by Andrew B. Godbehere, Akihiro Matsukawa, Ken Goldberg in their paper &#8220;Visual Tracking of Human Visitors under Variable-Lighting Conditions for a Responsive Audio Art Installation&#8221; in 2012. As per the paper, the system ran a successful interactive audio art installation called “Are We There Yet?” from March 31 - July 31 2011 at the Contemporary Jewish Museum in San Francisco, California.</p>
<p>It uses first few (120 by default) frames for background modelling. It employs probabilistic foreground segmentation algorithm that identifies possible foreground objects using Bayesian inference. The estimates are adaptive; newer observations are more heavily weighted than old observations to accommodate variable illumination. Several morphological filtering operations like closing and opening are done to remove unwanted noise. You will get a black window during first few frames.</p>
<p>It would be better to apply morphological opening to the result to remove the noises.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s">&#39;vtest.avi&#39;</span><span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getStructuringElement</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_ELLIPSE</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">fgbg</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">createBackgroundSubtractorGMG</span><span class="p">()</span>

<span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

    <span class="n">fgmask</span> <span class="o">=</span> <span class="n">fgbg</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="n">fgmask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">morphologyEx</span><span class="p">(</span><span class="n">fgmask</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_OPEN</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>

    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">&#39;frame&#39;</span><span class="p">,</span><span class="n">fgmask</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">27</span><span class="p">:</span>
        <span class="k">break</span>

<span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p><strong>Original Frame</strong></p>
<p>Below image shows the 200th frame of a video</p>
<blockquote>
<div><img alt="Original frame" class="align-center" src="../../../../_images/resframe.jpg" />
</div></blockquote>
<p><strong>Result of BackgroundSubtractorMOG</strong></p>
<blockquote>
<div><img alt="Result of BackgroundSubtractorMOG" class="align-center" src="../../../../_images/resmog.jpg" />
</div></blockquote>
<p><strong>Result of BackgroundSubtractorMOG2</strong></p>
<p>Gray color region shows shadow region.</p>
<blockquote>
<div><img alt="Result of BackgroundSubtractorMOG2" class="align-center" src="../../../../_images/resmog2.jpg" />
</div></blockquote>
<p><strong>Result of BackgroundSubtractorGMG</strong></p>
<p>Noise is removed with morphological opening.</p>
<blockquote>
<div><img alt="Result of BackgroundSubtractorGMG" class="align-center" src="../../../../_images/resgmg.jpg" />
</div></blockquote>
</div>
<div class="section" id="additional-resources">
<h2>Additional Resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org/">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org/">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py_calib3d/py_table_of_contents_calib3d/py_table_of_contents_calib3d.html" title="Camera Calibration and 3D Reconstruction"
             >next</a> |</li>
        <li class="right" >
          <a href="../py_lucas_kanade/py_lucas_kanade.html" title="Optical Flow"
             >previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../py_tutorials.html" >OpenCV-Python Tutorials</a> &raquo;</li>
          <li><a href="../py_table_of_contents_video/py_table_of_contents_video.html" >Video Analysis</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Dec 30, 2014.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
      <a href="../../../../_sources/doc/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.txt" rel="nofollow">Show this page source.</a>
    </div>
  </body>

<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:36 GMT -->
</html>