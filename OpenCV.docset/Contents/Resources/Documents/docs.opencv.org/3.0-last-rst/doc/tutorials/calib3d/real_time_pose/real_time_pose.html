<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  
<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/tutorials/calib3d/real_time_pose/real_time_pose.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:03 GMT -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Real Time pose estimation of a textured object</title>
    
    <link rel="stylesheet" href="../../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '3.0.0-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../_static/insertIframe.js"></script>
    <link rel="top" title="OpenCV 3.0.0-dev documentation" href="../../../../index.html" />
    <link rel="up" title="calib3d module. Camera calibration and 3D reconstruction" href="../table_of_content_calib3d/table_of_content_calib3d.html" />
    <link rel="next" title="feature2d module. 2D Features framework" href="../../features2d/table_of_content_features2d/table_of_content_features2d.html" />
    <link rel="prev" title="Camera calibration With OpenCV" href="../camera_calibration/camera_calibration.html" />
    <link href='../../../../../../fonts.googleapis.com/css8a7c.css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
    </style>
    <script type="text/javascript">
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../features2d/table_of_content_features2d/table_of_content_features2d.html" title="feature2d module. 2D Features framework"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../camera_calibration/camera_calibration.html" title="Camera calibration With OpenCV"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../tutorials.html" >OpenCV Tutorials</a> &raquo;</li>
          <li><a href="../table_of_content_calib3d/table_of_content_calib3d.html" accesskey="U"><em>calib3d</em> module. Camera calibration and 3D reconstruction</a> &raquo;</li> 
      </ul>
    </div>  
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../index.html">
              <img class="logo" src="../../../../_static/opencv-logo2.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="http://docs.opencv.org/3.0-last-rst/search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Real Time pose estimation of a textured object</a><ul>
<li><a class="reference internal" href="#goal">Goal</a></li>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#source-code">Source code</a></li>
<li><a class="reference internal" href="#explanation">Explanation</a></li>
<li><a class="reference internal" href="#results">Results</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../camera_calibration/camera_calibration.html"
                        title="previous chapter">Camera calibration With OpenCV</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../../features2d/table_of_content_features2d/table_of_content_features2d.html"
                        title="next chapter"><em>feature2d</em> module. 2D Features framework</a></p>
        </div>
      </div>
  <body>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="real-time-pose-estimation-of-a-textured-object">
<span id="realtimeposeestimation"></span><h1>Real Time pose estimation of a textured object<a class="headerlink" href="#real-time-pose-estimation-of-a-textured-object" title="Permalink to this headline">¶</a></h1>
<p>Nowadays, augmented reality is one of the top research topic in computer vision and robotics fields. The most elemental problem in augmented reality is the estimation of the camera pose respect of an object in the case of computer vision area to do later some 3D rendering or in the case of robotics obtain an object pose in order to grasp it and do some manipulation. However, this is not a trivial problem to solve due to the fact that the most common issue in image processing is the computational cost of applying a lot of algorithms or mathematical operations for solving a problem which is basic and immediateley for humans.</p>
<div class="section" id="goal">
<h2>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial is explained how to build a real time application to estimate the camera pose in order to track a textured object with six degrees of freedom given a 2D image and its 3D textured model.</p>
<p>The application will have the followings parts:</p>
<div class="enumeratevisibleitemswithsquare container">
<ul class="simple">
<li>Read 3D textured object model and object mesh.</li>
<li>Take input from Camera or Video.</li>
<li>Extract ORB features and descriptors from the scene.</li>
<li>Match scene descriptors with model descriptors using Flann matcher.</li>
<li>Pose estimation using PnP + Ransac.</li>
<li>Linear Kalman Filter for bad poses rejection.</li>
</ul>
</div>
</div>
<div class="section" id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Permalink to this headline">¶</a></h2>
<p>In computer vision estimate the camera pose from <em>n</em> 3D-to-2D point correspondences is a fundamental and well understood problem. The most general version of the problem requires estimating the six degrees of freedom of the pose and five calibration parameters: focal length, principal point, aspect ratio and skew. It could be established with a minimum of 6 correspondences, using the well known Direct Linear Transform (DLT) algorithm. There are, though, several simplifications to the problem which turn into an extensive list of different algorithms that improve the accuracy of the DLT.</p>
<p>The most common simplification is to assume known calibration parameters which is the so-called Perspective-<em>n</em>-Point problem:</p>
<img alt="Perspective-n-Point problem scheme" class="align-center" src="../../../../_images/pnp.jpg" />
<p><strong>Problem Formulation:</strong> Given a set of correspondences between 3D points <img class="math" src="../../../../_images/math/e726c85891aff38330c54fcbaf3d4244f5ad8395.png" alt="p_i"/> expressed in a world reference frame, and their 2D projections <img class="math" src="../../../../_images/math/ac0b64d5983c19940874291d4fdf019c4e99ad21.png" alt="u_i"/> onto the image, we seek to retrieve the pose (<img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> and <img class="math" src="../../../../_images/math/6f34bae44dd219fa449ea5ceb11b2f3270be2462.png" alt="t"/>) of the camera w.r.t. the world and the focal length <img class="math" src="../../../../_images/math/43f689f93c9323831e76724aedb37ece0f77722a.png" alt="f"/>.</p>
<p>OpenCV provides four different approaches to solve the Perspective-<em>n</em>-Point problem which return <img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> and <img class="math" src="../../../../_images/math/6f34bae44dd219fa449ea5ceb11b2f3270be2462.png" alt="t"/>. Then, using the following formula it&#8217;s possible to project 3D points into the image plane:</p>
<div class="math">
<p><img src="../../../../_images/math/d2cddeef6437dd0cb0b793d381cdd6769da4cff1.png" alt="s\ \left [ \begin{matrix}   u \\   v \\  1 \end{matrix} \right ] = \left [ \begin{matrix}   f_x &amp; 0 &amp; c_x \\  0 &amp; f_y &amp; c_y \\   0 &amp; 0 &amp; 1 \end{matrix} \right ] \left [ \begin{matrix}  r_{11} &amp; r_{12} &amp; r_{13} &amp; t_1 \\ r_{21} &amp; r_{22} &amp; r_{23} &amp; t_2 \\  r_{31} &amp; r_{32} &amp; r_{33} &amp; t_3 \end{matrix} \right ] \left [ \begin{matrix}  X \\  Y \\   Z\\ 1 \end{matrix} \right ]"/></p>
</div><p>The complete documentation of how to manage with this equations is in <a class="reference external" href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#">Camera Calibration and 3D Reconstruction</a>.</p>
</div>
<div class="section" id="source-code">
<h2>Source code<a class="headerlink" href="#source-code" title="Permalink to this headline">¶</a></h2>
<p>You can find the source code of this tutorial in the <tt class="file docutils literal"><span class="pre">samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/</span></tt> folder of the OpenCV source library.</p>
<p>The tutorial consists of two main programs:</p>
<ol class="arabic simple">
<li><strong>Model registration</strong></li>
</ol>
<blockquote>
<div><p>This applicaton is exclusive to whom don&#8217;t have a 3D textured model of the object to be detected. You can use this program to create your own textured 3D model. This program only works for planar objects, then if you want to model an object with complex shape you should use a sophisticated software to create it.</p>
<p>The application needs an input image of the object to be registered and its 3D mesh. We have also to provide the intrinsic parameters of the camera with which the input image was taken. All the files need to be specified using the absolute path or the relative one from your application’s working directory. If none files are specified the program will try to open the provided default parameters.</p>
<p>The application starts up extracting the ORB features and descriptors from the input image and then uses the mesh along with the <a class="reference external" href="http://en.wikipedia.org/wiki/Möller–Trumbore_intersection_algorithm/">Möller–Trumbore intersection algorithm</a> to compute the 3D coordinates of the found features. Finally, the 3D points and the descriptors are stored in different lists in a file with YAML format which each row is a different point. The technical background on how to store the files can be found in the <a class="reference internal" href="../../core/file_input_output_with_xml_yml/file_input_output_with_xml_yml.html#fileinputoutputxmlyaml"><em>File Input and Output using XML and YAML files</em></a> tutorial.</p>
</div></blockquote>
<img alt="Model registration" class="align-center" src="../../../../_images/registration.png" />
<ol class="arabic simple" start="2">
<li><strong>Model detection</strong></li>
</ol>
<blockquote>
<div><p>The aim of this application is estimate in real time the object pose given its 3D textured model.</p>
<p>The application starts up loading the 3D textured model in YAML file format with the same structure explained in the model registration program. From the scene, the ORB features and descriptors are detected and extracted. Then, is used <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html?highlight=flannbasedmatcher#flannbasedmatcher">FlannBasedMatcher</a> with <a class="reference external" href="http://docs.opencv.org/modules/flann/doc/flann_fast_approximate_nearest_neighbor_search.html#flann-index-t-index">LshIndexParams</a> to do the matching between the scene descriptors and the model descriptors. Using the found matches along with <a class="reference external" href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnpransac">solvePnPRansac</a> function the <img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> and <img class="math" src="../../../../_images/math/6f34bae44dd219fa449ea5ceb11b2f3270be2462.png" alt="t"/> of the camera are computed. Finally, a <a class="reference external" href="http://docs.opencv.org/modules/video/doc/motion_analysis_and_object_tracking.html#kalmanfilter">KalmanFilter</a> is applied in order to reject bad poses.</p>
<p>In the case that you compiled OpenCV with the samples, you can find it in <tt class="file docutils literal"><span class="pre">opencv/build/bin/cpp-tutorial-pnp_detection</span></tt>. Then you can run the application and change some parameters:</p>
<div class="highlight-cpp"><div class="highlight"><pre>This program shows how to detect an object given its 3D textured model. You can choose to use a recorded video or the webcam.
Usage:
  ./cpp-tutorial-pnp_detection -help
Keys:
  &#39;esc&#39; - to quit.
--------------------------------------------------------------------------

Usage: cpp-tutorial-pnp_detection [params]

  -c, --confidence (value:0.95)
      RANSAC confidence
  -e, --error (value:2.0)
      RANSAC reprojection errror
  -f, --fast (value:true)
      use of robust fast match
  -h, --help (value:true)
      print this message
  --in, --inliers (value:30)
      minimum inliers for Kalman update
  --it, --iterations (value:500)
      RANSAC maximum iterations count
  -k, --keypoints (value:2000)
      number of keypoints to detect
  --mesh
      path to ply mesh
  --method, --pnp (value:0)
      PnP method: (0) ITERATIVE - (1) EPNP - (2) P3P - (3) DLS
  --model
      path to yml model
  -r, --ratio (value:0.7)
      threshold for ratio test
  -v, --video
      path to recorded video
</pre></div>
</div>
<p>For example, you can run the application changing the pnp method:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">method</span><span class="o">=</span><span class="mi">2</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="explanation">
<h2>Explanation<a class="headerlink" href="#explanation" title="Permalink to this headline">¶</a></h2>
<p>Here is explained in detail the code for the real time application:</p>
<ol class="arabic simple">
<li><strong>Read 3D textured object model and object mesh.</strong></li>
</ol>
<blockquote>
<div><p>In order to load the textured model I implemented the <em>class</em> <strong>Model</strong> which has the function <em>load()</em> that opens a YAML file and take the stored 3D points with its corresponding descriptors. You can find an example of a 3D textured model in <tt class="file docutils literal"><span class="pre">samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/Data/cookies_ORB.yml</span></tt>.</p>
<blockquote>
<div><div class="highlight-cpp"><div class="highlight"><pre><span class="cm">/* Load a YAML file using OpenCV */</span>
<span class="kt">void</span> <span class="n">Model</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">path</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">points3d_mat</span><span class="p">;</span>

    <span class="n">cv</span><span class="o">::</span><span class="n">FileStorage</span> <span class="n">storage</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">FileStorage</span><span class="o">::</span><span class="n">READ</span><span class="p">);</span>
    <span class="n">storage</span><span class="p">[</span><span class="s">&quot;points_3d&quot;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">points3d_mat</span><span class="p">;</span>
    <span class="n">storage</span><span class="p">[</span><span class="s">&quot;descriptors&quot;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">descriptors_</span><span class="p">;</span>

    <span class="n">points3d_mat</span><span class="p">.</span><span class="n">copyTo</span><span class="p">(</span><span class="n">list_points3d_in_</span><span class="p">);</span>

    <span class="n">storage</span><span class="p">.</span><span class="n">release</span><span class="p">();</span>

<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>In the main program the model is loaded as follows:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">Model</span> <span class="n">model</span><span class="p">;</span>               <span class="c1">// instantiate Model object</span>
<span class="n">model</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">yml_read_path</span><span class="p">);</span> <span class="c1">// load a 3D textured object model</span>
</pre></div>
</div>
<p>In order to read the model mesh I implemented a <em>class</em> <strong>Mesh</strong> which has a function <em>load()</em> that opens a <img class="math" src="../../../../_images/math/b8425666859d0ceec02bd0d32cc9428c501a807a.png" alt="*"/>.ply file and store the 3D points of the object and also the composed triangles. You can find an example of a model mesh in <tt class="file docutils literal"><span class="pre">samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/Data/box.ply</span></tt>.</p>
<blockquote>
<div><div class="highlight-cpp"><div class="highlight"><pre><span class="cm">/* Load a CSV with *.ply format */</span>
<span class="kt">void</span> <span class="n">Mesh</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">path</span><span class="p">)</span>
<span class="p">{</span>

    <span class="c1">// Create the reader</span>
    <span class="n">CsvReader</span> <span class="n">csvReader</span><span class="p">(</span><span class="n">path</span><span class="p">);</span>

    <span class="c1">// Clear previous data</span>
    <span class="n">list_vertex_</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
    <span class="n">list_triangles_</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>

    <span class="c1">// Read from .ply file</span>
    <span class="n">csvReader</span><span class="p">.</span><span class="n">readPLY</span><span class="p">(</span><span class="n">list_vertex_</span><span class="p">,</span> <span class="n">list_triangles_</span><span class="p">);</span>

    <span class="c1">// Update mesh attributes</span>
    <span class="n">num_vertexs_</span> <span class="o">=</span> <span class="n">list_vertex_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
    <span class="n">num_triangles_</span> <span class="o">=</span> <span class="n">list_triangles_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>

<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
<p>In the main program the mesh is loaded as follows:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">Mesh</span> <span class="n">mesh</span><span class="p">;</span>                <span class="c1">// instantiate Mesh object</span>
<span class="n">mesh</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">ply_read_path</span><span class="p">);</span> <span class="c1">// load an object mesh</span>
</pre></div>
</div>
<p>You can also load different model and mesh:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">mesh</span><span class="o">=/</span><span class="n">absolute_path_to_your_mesh</span><span class="p">.</span><span class="n">ply</span> <span class="o">--</span><span class="n">model</span><span class="o">=/</span><span class="n">absolute_path_to_your_model</span><span class="p">.</span><span class="n">yml</span>
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><strong>Take input from Camera or Video</strong></li>
</ol>
<blockquote>
<div><p>To detect is necessary capture video. It&#8217;s done loading a recorded video by passing the absolute path where it is located in your machine. In order to test the application you can find a recorded video in <tt class="file docutils literal"><span class="pre">samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/Data/box.mp4</span></tt>.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">cv</span><span class="o">::</span><span class="n">VideoCapture</span> <span class="n">cap</span><span class="p">;</span>                <span class="c1">// instantiate VideoCapture</span>
<span class="n">cap</span><span class="p">.</span><span class="n">open</span><span class="p">(</span><span class="n">video_read_path</span><span class="p">);</span>           <span class="c1">// open a recorded video</span>

<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">cap</span><span class="p">.</span><span class="n">isOpened</span><span class="p">())</span>                  <span class="c1">// check if we succeeded</span>
<span class="p">{</span>
   <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Could not open the camera device&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
   <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Then the algorithm is computed frame per frame:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">frame</span><span class="p">,</span> <span class="n">frame_vis</span><span class="p">;</span>

<span class="k">while</span><span class="p">(</span><span class="n">cap</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">cv</span><span class="o">::</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">27</span><span class="p">)</span>    <span class="c1">// capture frame until ESC is pressed</span>
<span class="p">{</span>

    <span class="n">frame_vis</span> <span class="o">=</span> <span class="n">frame</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span>                     <span class="c1">// refresh visualisation frame</span>

    <span class="c1">// MAIN ALGORITHM</span>

<span class="p">}</span>
</pre></div>
</div>
<p>You can also load different recorded video:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">video</span><span class="o">=/</span><span class="n">absolute_path_to_your_video</span><span class="p">.</span><span class="n">mp4</span>
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><strong>Extract ORB features and descriptors from the scene</strong></li>
</ol>
<blockquote>
<div><p>The next step is to detect the scene features and extract it descriptors. For this task I implemented a <em>class</em> <strong>RobustMatcher</strong> which has a function for keypoints detection and features extraction. You can find it in <tt class="file docutils literal"><span class="pre">samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/src/RobusMatcher.cpp</span></tt>. In your <em>RobusMatch</em> object you can use any of the 2D features detectors of OpenCV. In this case I used <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html#orb">ORB</a> features because is based on <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html#fast">FAST</a> to detect the keypoints and <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_extractors.html?highlight=descriptorextractor#descriptorextractorbriefdescriptorextractor">BRIEF</a> to extract the descriptors which means that is fast and robust to rotations. You can find more detailed information about <em>ORB</em> in the documentation.</p>
<p>The following code is how to instantiate and set the features detector and the descriptors extractor:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">RobustMatcher</span> <span class="n">rmatcher</span><span class="p">;</span>                                                          <span class="c1">// instantiate RobustMatcher</span>

<span class="n">cv</span><span class="o">::</span><span class="n">FeatureDetector</span> <span class="o">*</span> <span class="n">detector</span> <span class="o">=</span> <span class="k">new</span> <span class="n">cv</span><span class="o">::</span><span class="n">OrbFeatureDetector</span><span class="p">(</span><span class="n">numKeyPoints</span><span class="p">);</span>       <span class="c1">// instatiate ORB feature detector</span>
<span class="n">cv</span><span class="o">::</span><span class="n">DescriptorExtractor</span> <span class="o">*</span> <span class="n">extractor</span> <span class="o">=</span> <span class="k">new</span> <span class="n">cv</span><span class="o">::</span><span class="n">OrbDescriptorExtractor</span><span class="p">();</span>          <span class="c1">// instatiate ORB descriptor extractor</span>

<span class="n">rmatcher</span><span class="p">.</span><span class="n">setFeatureDetector</span><span class="p">(</span><span class="n">detector</span><span class="p">);</span>                                           <span class="c1">// set feature detector</span>
<span class="n">rmatcher</span><span class="p">.</span><span class="n">setDescriptorExtractor</span><span class="p">(</span><span class="n">extractor</span><span class="p">);</span>                                      <span class="c1">// set descriptor extractor</span>
</pre></div>
</div>
<p>The features and descriptors will be computed by the <em>RobustMatcher</em> inside the matching function.</p>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><strong>Match scene descriptors with model descriptors using Flann matcher</strong></li>
</ol>
<blockquote>
<div><p>It is the first step in our detection algorithm. The main idea is to match the scene descriptors with our model descriptors in order to know the 3D coordinates of the found features into the current scene.</p>
<p>Firstly, we have to set which matcher we want to use. In this case is used <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html?highlight=flannbasedmatcher#flannbasedmatcher">FlannBasedMatcher</a> matcher which in terms of computational cost is faster than the <a class="reference external" href="http://docs.opencv.org/modules/features2d/doc/common_interfaces_of_descriptor_matchers.html?highlight=bruteforcematcher#bruteforcematcherbfmatcher">BruteForceMatcher</a> matcher as we increase the trained collectction of features. Then, for FlannBased matcher the index created is <em>Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search</em> due to <em>ORB</em> descriptors are binary.</p>
<p>You can tune the <em>LSH</em> and search parameters to improve the matching efficiency:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">cv</span><span class="o">::</span><span class="n">Ptr</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">flann</span><span class="o">::</span><span class="n">IndexParams</span><span class="o">&gt;</span> <span class="n">indexParams</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">makePtr</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">flann</span><span class="o">::</span><span class="n">LshIndexParams</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="c1">// instantiate LSH index parameters</span>
<span class="n">cv</span><span class="o">::</span><span class="n">Ptr</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">flann</span><span class="o">::</span><span class="n">SearchParams</span><span class="o">&gt;</span> <span class="n">searchParams</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">makePtr</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">flann</span><span class="o">::</span><span class="n">SearchParams</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">50</span><span class="p">);</span>       <span class="c1">// instantiate flann search parameters</span>

<span class="n">cv</span><span class="o">::</span><span class="n">DescriptorMatcher</span> <span class="o">*</span> <span class="n">matcher</span> <span class="o">=</span> <span class="k">new</span> <span class="n">cv</span><span class="o">::</span><span class="n">FlannBasedMatcher</span><span class="p">(</span><span class="n">indexParams</span><span class="p">,</span> <span class="n">searchParams</span><span class="p">);</span>         <span class="c1">// instantiate FlannBased matcher</span>
<span class="n">rmatcher</span><span class="p">.</span><span class="n">setDescriptorMatcher</span><span class="p">(</span><span class="n">matcher</span><span class="p">);</span>                                                         <span class="c1">// set matcher</span>
</pre></div>
</div>
<p>Secondly, we have to call the matcher by using <em>robustMatch()</em> or <em>fastRobustMatch()</em> function. The difference of using this two functions is its computational cost. The first method is slower but more robust at filtering good matches because uses two ratio test and a symmetry test. In contrast, the second method is faster but less robust because only applies a single ratio test to the matches.</p>
<p>The following code is to get the model 3D points and its descriptors and then call the matcher in the main program:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Get the MODEL INFO</span>

<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="o">&gt;</span> <span class="n">list_points3d_model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">get_points3d</span><span class="p">();</span>  <span class="c1">// list with model 3D coordinates</span>
<span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">descriptors_model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">get_descriptors</span><span class="p">();</span>                  <span class="c1">// list with descriptors of each 3D coordinate</span>
</pre></div>
</div>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// -- Step 1: Robust matching between model descriptors and scene descriptors</span>

<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">DMatch</span><span class="o">&gt;</span> <span class="n">good_matches</span><span class="p">;</span>       <span class="c1">// to obtain the model 3D points  in the scene</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">KeyPoint</span><span class="o">&gt;</span> <span class="n">keypoints_scene</span><span class="p">;</span>  <span class="c1">// to obtain the 2D points of the scene</span>

<span class="k">if</span><span class="p">(</span><span class="n">fast_match</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">rmatcher</span><span class="p">.</span><span class="n">fastRobustMatch</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">good_matches</span><span class="p">,</span> <span class="n">keypoints_scene</span><span class="p">,</span> <span class="n">descriptors_model</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span>
<span class="p">{</span>
    <span class="n">rmatcher</span><span class="p">.</span><span class="n">robustMatch</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">good_matches</span><span class="p">,</span> <span class="n">keypoints_scene</span><span class="p">,</span> <span class="n">descriptors_model</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following code corresponds to the <em>robustMatch()</em> function which belongs to the <em>RobustMatcher</em> class. This function uses the given image to detect the keypoints and extract the descriptors, match using <em>two Nearest Neighbour</em> the extracted descriptors with the given model descriptors and vice versa. Then, a ratio test is applied to the two direction matches in order to remove these matches which its distance ratio between the first and second best match is larger than a given threshold. Finally, a symmetry test is applied in order the remove non symmetrical matches.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="kt">void</span> <span class="n">RobustMatcher</span><span class="o">::</span><span class="n">robustMatch</span><span class="p">(</span> <span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">&amp;</span> <span class="n">frame</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">DMatch</span><span class="o">&gt;&amp;</span> <span class="n">good_matches</span><span class="p">,</span>
                                 <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">KeyPoint</span><span class="o">&gt;&amp;</span> <span class="n">keypoints_frame</span><span class="p">,</span>
                                 <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">KeyPoint</span><span class="o">&gt;&amp;</span> <span class="n">keypoints_model</span><span class="p">,</span> <span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">&amp;</span> <span class="n">descriptors_model</span> <span class="p">)</span>
<span class="p">{</span>

    <span class="c1">// 1a. Detection of the ORB features</span>
    <span class="k">this</span><span class="o">-&gt;</span><span class="n">computeKeyPoints</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">keypoints_frame</span><span class="p">);</span>

    <span class="c1">// 1b. Extraction of the ORB descriptors</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">descriptors_frame</span><span class="p">;</span>
    <span class="k">this</span><span class="o">-&gt;</span><span class="n">computeDescriptors</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">keypoints_frame</span><span class="p">,</span> <span class="n">descriptors_frame</span><span class="p">);</span>

    <span class="c1">// 2. Match the two image descriptors</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">DMatch</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="n">matches12</span><span class="p">,</span> <span class="n">matches21</span><span class="p">;</span>

    <span class="c1">// 2a. From image 1 to image 2</span>
    <span class="n">matcher_</span><span class="o">-&gt;</span><span class="n">knnMatch</span><span class="p">(</span><span class="n">descriptors_frame</span><span class="p">,</span> <span class="n">descriptors_model</span><span class="p">,</span> <span class="n">matches12</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span> <span class="c1">// return 2 nearest neighbours</span>

    <span class="c1">// 2b. From image 2 to image 1</span>
    <span class="n">matcher_</span><span class="o">-&gt;</span><span class="n">knnMatch</span><span class="p">(</span><span class="n">descriptors_model</span><span class="p">,</span> <span class="n">descriptors_frame</span><span class="p">,</span> <span class="n">matches21</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span> <span class="c1">// return 2 nearest neighbours</span>

    <span class="c1">// 3. Remove matches for which NN ratio is &gt; than threshold</span>
    <span class="c1">// clean image 1 -&gt; image 2 matches</span>
    <span class="kt">int</span> <span class="n">removed1</span> <span class="o">=</span> <span class="n">ratioTest</span><span class="p">(</span><span class="n">matches12</span><span class="p">);</span>
    <span class="c1">// clean image 2 -&gt; image 1 matches</span>
    <span class="kt">int</span> <span class="n">removed2</span> <span class="o">=</span> <span class="n">ratioTest</span><span class="p">(</span><span class="n">matches21</span><span class="p">);</span>

    <span class="c1">// 4. Remove non-symmetrical matches</span>
    <span class="n">symmetryTest</span><span class="p">(</span><span class="n">matches12</span><span class="p">,</span> <span class="n">matches21</span><span class="p">,</span> <span class="n">good_matches</span><span class="p">);</span>

<span class="p">}</span>
</pre></div>
</div>
<p>After the matches filtering we have to subtract the 2D and 3D correspondences from the found scene keypoints and our 3D model using the obtained <em>DMatches</em> vector. For more information about <a class="reference external" href="http://docs.opencv.org/modules/core/doc/basic_structures.html#dmatch">DMatch</a> check the documentation.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// -- Step 2: Find out the 2D/3D correspondences</span>

<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="o">&gt;</span> <span class="n">list_points3d_model_match</span><span class="p">;</span>    <span class="c1">// container for the model 3D coordinates found in the scene</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="o">&gt;</span> <span class="n">list_points2d_scene_match</span><span class="p">;</span>    <span class="c1">// container for the model 2D coordinates found in the scene</span>

<span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">match_index</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">match_index</span> <span class="o">&lt;</span> <span class="n">good_matches</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">match_index</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span> <span class="n">point3d_model</span> <span class="o">=</span> <span class="n">list_points3d_model</span><span class="p">[</span> <span class="n">good_matches</span><span class="p">[</span><span class="n">match_index</span><span class="p">].</span><span class="n">trainIdx</span> <span class="p">];</span>   <span class="c1">// 3D point from model</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span> <span class="n">point2d_scene</span> <span class="o">=</span> <span class="n">keypoints_scene</span><span class="p">[</span> <span class="n">good_matches</span><span class="p">[</span><span class="n">match_index</span><span class="p">].</span><span class="n">queryIdx</span> <span class="p">].</span><span class="n">pt</span><span class="p">;</span>    <span class="c1">// 2D point from the scene</span>
    <span class="n">list_points3d_model_match</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">point3d_model</span><span class="p">);</span>                                      <span class="c1">// add 3D point</span>
    <span class="n">list_points2d_scene_match</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">point2d_scene</span><span class="p">);</span>                                      <span class="c1">// add 2D point</span>
<span class="p">}</span>
</pre></div>
</div>
<p>You can also change the ratio test threshold, the number of keypoints to detect as well as use or not the robust matcher:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">ratio</span><span class="o">=</span><span class="mf">0.8</span> <span class="o">--</span><span class="n">keypoints</span><span class="o">=</span><span class="mi">1000</span> <span class="o">--</span><span class="n">fast</span><span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="5">
<li><strong>Pose estimation using PnP + Ransac</strong></li>
</ol>
<blockquote>
<div><p>Once with the 2D and 3D correspondences we have to apply a PnP algorithm in order to estimate the camera pose. The reason why we have to use <a class="reference external" href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnpransac">solvePnPRansac</a> instead of <a class="reference external" href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnp">solvePnP</a> is due to the fact that after the matching not all the found correspondences are correct and, as like as not, there are false correspondences or also called <em>outliers</em>. The <a class="reference external" href="http://en.wikipedia.org/wiki/RANSAC">Random Sample Consensus</a> or <em>Ransac</em> is a non-deterministic iterative method which estimate parameters of a mathematical model from observed data producing an aproximate result as the number of iterations increase. After appyling <em>Ransac</em> all the <em>outliers</em> will be eliminated to then estimate the camera pose with a certain probability to obtain a good solution.</p>
<p>For the camera pose estimation I have implemented a <em>class</em> <strong>PnPProblem</strong>. This <em>class</em> has 4 atributes: a given calibration matrix, the rotation matrix, the translation matrix and the rotation-translation matrix. The intrinsic calibration parameters of the camera which you are using to estimate the pose are necessary. In order to obtain the parameters you can check <a class="reference internal" href="../camera_calibration_square_chess/camera_calibration_square_chess.html#cameracalibrationsquarechessboardtutorial"><em>Camera calibration with square chessboard</em></a> and <a class="reference internal" href="../camera_calibration/camera_calibration.html#cameracalibrationopencv"><em>Camera calibration With OpenCV</em></a> tutorials.</p>
<p>The following code is how to declare the <em>PnPProblem class</em> in the main program:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Intrinsic camera parameters: UVC WEBCAM</span>

<span class="kt">double</span> <span class="n">f</span> <span class="o">=</span> <span class="mi">55</span><span class="p">;</span>                           <span class="c1">// focal length in mm</span>
<span class="kt">double</span> <span class="n">sx</span> <span class="o">=</span> <span class="mf">22.3</span><span class="p">,</span> <span class="n">sy</span> <span class="o">=</span> <span class="mf">14.9</span><span class="p">;</span>             <span class="c1">// sensor size</span>
<span class="kt">double</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">640</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">480</span><span class="p">;</span>        <span class="c1">// image size</span>

<span class="kt">double</span> <span class="n">params_WEBCAM</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span> <span class="n">width</span><span class="o">*</span><span class="n">f</span><span class="o">/</span><span class="n">sx</span><span class="p">,</span>   <span class="c1">// fx</span>
                           <span class="n">height</span><span class="o">*</span><span class="n">f</span><span class="o">/</span><span class="n">sy</span><span class="p">,</span>  <span class="c1">// fy</span>
                           <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span>      <span class="c1">// cx</span>
                           <span class="n">height</span><span class="o">/</span><span class="mi">2</span><span class="p">};</span>    <span class="c1">// cy</span>

<span class="n">PnPProblem</span> <span class="nf">pnp_detection</span><span class="p">(</span><span class="n">params_WEBCAM</span><span class="p">);</span> <span class="c1">// instantiate PnPProblem class</span>
</pre></div>
</div>
<p>The following code is how the <em>PnPProblem class</em> initialises its atributes:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Custom constructor given the intrinsic camera parameters</span>

<span class="n">PnPProblem</span><span class="o">::</span><span class="n">PnPProblem</span><span class="p">(</span><span class="k">const</span> <span class="kt">double</span> <span class="n">params</span><span class="p">[])</span>
<span class="p">{</span>
  <span class="n">_A_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>   <span class="c1">// intrinsic camera parameters</span>
  <span class="n">_A_matrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>       <span class="c1">//      [ fx   0  cx ]</span>
  <span class="n">_A_matrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>       <span class="c1">//      [  0  fy  cy ]</span>
  <span class="n">_A_matrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>       <span class="c1">//      [  0   0   1 ]</span>
  <span class="n">_A_matrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
  <span class="n">_A_matrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
  <span class="n">_R_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>   <span class="c1">// rotation matrix</span>
  <span class="n">_t_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>   <span class="c1">// translation matrix</span>
  <span class="n">_P_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>   <span class="c1">// rotation-translation matrix</span>

<span class="p">}</span>
</pre></div>
</div>
<p>OpenCV provides four PnP methods: ITERATIVE, EPNP, P3P and DLS. Depending on the application type, the estimation method will be different. In the case that we want to make a real time application, the more suitable methods are EPNP and P3P due to that are faster than ITERATIVE and DLS at finding an optimal solution. However, EPNP and P3P are not especially robust in front of planar surfaces and sometimes the pose estimation seems to have a mirror effect. Therefore, in this this tutorial is used ITERATIVE method due to the object to be detected has planar surfaces.</p>
<p>The OpenCV Ransac implementation wants you to provide three parameters: the maximum number of iterations until stop the algorithm, the maximum allowed distance between the observed and computed point projections to consider it an inlier and the confidence to obtain a good result. You can tune these paramaters in order to improve your algorithm performance. Increasing the number of iterations you will have a more accurate solution, but will take more time to find a solution. Increasing the reprojection error will reduce the computation time, but your solution will be unaccurate. Decreasing the confidence your arlgorithm will be faster, but the obtained solution will be unaccurate.</p>
<p>The following parameters work for this application:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// RANSAC parameters</span>

<span class="kt">int</span> <span class="n">iterationsCount</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span>        <span class="c1">// number of Ransac iterations.</span>
<span class="kt">float</span> <span class="n">reprojectionError</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">;</span>    <span class="c1">// maximum allowed distance to consider it an inlier.</span>
<span class="kt">float</span> <span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">;</span>          <span class="c1">// ransac successful confidence.</span>
</pre></div>
</div>
<p>The following code corresponds to the <em>estimatePoseRANSAC()</em> function which belongs to the <em>PnPProblem class</em>. This function estimates the rotation and translation matrix given a set of 2D/3D correspondences, the desired PnP method to use, the output inliers container and the Ransac parameters:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Estimate the pose given a list of 2D/3D correspondences with RANSAC and the method to use</span>

<span class="kt">void</span> <span class="n">PnPProblem</span><span class="o">::</span><span class="n">estimatePoseRANSAC</span><span class="p">(</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">list_points3d</span><span class="p">,</span>        <span class="c1">// list with model 3D coordinates</span>
                                     <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">list_points2d</span><span class="p">,</span>        <span class="c1">// list with scene 2D coordinates</span>
                                     <span class="kt">int</span> <span class="n">flags</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">inliers</span><span class="p">,</span> <span class="kt">int</span> <span class="n">iterationsCount</span><span class="p">,</span>     <span class="c1">// PnP method; inliers container</span>
                                     <span class="kt">float</span> <span class="n">reprojectionError</span><span class="p">,</span> <span class="kt">float</span> <span class="n">confidence</span> <span class="p">)</span>           <span class="c1">// Ransac parameters</span>
<span class="p">{</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">distCoeffs</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>    <span class="c1">// vector of distortion coefficients</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">rvec</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>          <span class="c1">// output rotation vector</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">tvec</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>          <span class="c1">// output translation vector</span>

    <span class="kt">bool</span> <span class="n">useExtrinsicGuess</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>   <span class="c1">// if true the function uses the provided rvec and tvec values as</span>
                                      <span class="c1">// initial approximations of the rotation and translation vectors</span>

    <span class="n">cv</span><span class="o">::</span><span class="n">solvePnPRansac</span><span class="p">(</span> <span class="n">list_points3d</span><span class="p">,</span> <span class="n">list_points2d</span><span class="p">,</span> <span class="n">_A_matrix</span><span class="p">,</span> <span class="n">distCoeffs</span><span class="p">,</span> <span class="n">rvec</span><span class="p">,</span> <span class="n">tvec</span><span class="p">,</span>
                        <span class="n">useExtrinsicGuess</span><span class="p">,</span> <span class="n">iterationsCount</span><span class="p">,</span> <span class="n">reprojectionError</span><span class="p">,</span> <span class="n">confidence</span><span class="p">,</span>
                        <span class="n">inliers</span><span class="p">,</span> <span class="n">flags</span> <span class="p">);</span>

    <span class="n">Rodrigues</span><span class="p">(</span><span class="n">rvec</span><span class="p">,</span><span class="n">_R_matrix</span><span class="p">);</span>                   <span class="c1">// converts Rotation Vector to Matrix</span>
    <span class="n">_t_matrix</span> <span class="o">=</span> <span class="n">tvec</span><span class="p">;</span>                            <span class="c1">// set translation matrix</span>

    <span class="k">this</span><span class="o">-&gt;</span><span class="n">set_P_matrix</span><span class="p">(</span><span class="n">_R_matrix</span><span class="p">,</span> <span class="n">_t_matrix</span><span class="p">);</span>    <span class="c1">// set rotation-translation matrix</span>

<span class="p">}</span>
</pre></div>
</div>
<p>In the following code are the 3th and 4th steps of the main algorithm. The first, calling the above function and the second taking the output inliers vector from Ransac to get the 2D scene points for drawing purpose. As seen in the code we must be sure to apply Ransac if we have matches, in the other case, the function <a class="reference external" href="http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#solvepnpransac">solvePnPRansac</a> crashes due to any OpenCV <em>bug</em>.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="k">if</span><span class="p">(</span><span class="n">good_matches</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="c1">// None matches, then RANSAC crashes</span>
<span class="p">{</span>

    <span class="c1">// -- Step 3: Estimate the pose using RANSAC approach</span>
    <span class="n">pnp_detection</span><span class="p">.</span><span class="n">estimatePoseRANSAC</span><span class="p">(</span> <span class="n">list_points3d_model_match</span><span class="p">,</span> <span class="n">list_points2d_scene_match</span><span class="p">,</span>
                                      <span class="n">pnpMethod</span><span class="p">,</span> <span class="n">inliers_idx</span><span class="p">,</span> <span class="n">iterationsCount</span><span class="p">,</span> <span class="n">reprojectionError</span><span class="p">,</span> <span class="n">confidence</span> <span class="p">);</span>


    <span class="c1">// -- Step 4: Catch the inliers keypoints to draw</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">inliers_index</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">inliers_index</span> <span class="o">&lt;</span> <span class="n">inliers_idx</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">inliers_index</span><span class="p">)</span>
    <span class="p">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">inliers_idx</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inliers_index</span><span class="p">);</span>         <span class="c1">// i-inlier</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span> <span class="n">point2d</span> <span class="o">=</span> <span class="n">list_points2d_scene_match</span><span class="p">[</span><span class="n">n</span><span class="p">];</span> <span class="c1">// i-inlier point 2D</span>
    <span class="n">list_points2d_inliers</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">point2d</span><span class="p">);</span>           <span class="c1">// add i-inlier to list</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, once the camera pose has been estimated we can use the <img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> and <img class="math" src="../../../../_images/math/6f34bae44dd219fa449ea5ceb11b2f3270be2462.png" alt="t"/> in order to compute the 2D projection onto the image of a given 3D point expressed in a world reference frame using the showed formula on <em>Theory</em>.</p>
<p>The following code corresponds to the <em>backproject3DPoint()</em> function which belongs to the <em>PnPProblem class</em>. The function backproject a given 3D point expressed in a world reference frame onto a 2D image:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Backproject a 3D point to 2D using the estimated pose parameters</span>

<span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span> <span class="n">PnPProblem</span><span class="o">::</span><span class="n">backproject3DPoint</span><span class="p">(</span><span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span> <span class="o">&amp;</span><span class="n">point3d</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// 3D point vector [x y z 1]&#39;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">point3d_vec</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>
    <span class="n">point3d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">point3d</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">point3d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">point3d</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
    <span class="n">point3d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">point3d</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
    <span class="n">point3d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="c1">// 2D point vector [u v 1]&#39;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">point2d_vec</span> <span class="o">=</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64FC1</span><span class="p">);</span>
    <span class="n">point2d_vec</span> <span class="o">=</span> <span class="n">_A_matrix</span> <span class="o">*</span> <span class="n">_P_matrix</span> <span class="o">*</span> <span class="n">point3d_vec</span><span class="p">;</span>

    <span class="c1">// Normalization of [u v]&#39;</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span> <span class="n">point2d</span><span class="p">;</span>
    <span class="n">point2d</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">point2d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">point2d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
    <span class="n">point2d</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">point2d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">point2d_vec</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">point2d</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The above function is used to compute all the 3D points of the object <em>Mesh</em> to show the pose of the object.</p>
<p>You can also change RANSAC parameters and PnP method:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">error</span><span class="o">=</span><span class="mf">0.25</span> <span class="o">--</span><span class="n">confidence</span><span class="o">=</span><span class="mf">0.90</span> <span class="o">--</span><span class="n">iterations</span><span class="o">=</span><span class="mi">250</span> <span class="o">--</span><span class="n">method</span><span class="o">=</span><span class="mi">3</span>
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><strong>Linear Kalman Filter for bad poses rejection</strong></li>
</ol>
<blockquote>
<div><p>Is it common in computer vision or robotics fields that after applying detection or tracking techniques, bad results are obtained due to some sensor errors. In order to avoid these bad detections in this tutorial is explained how to implement a Linear Kalman Filter. The Kalman Filter will be applied after detected a given number of inliers.</p>
<p>You can find more information about what <a class="reference external" href="http://en.wikipedia.org/wiki/Kalman_filter">Kalman Filter</a> is. In this tutorial it&#8217;s used the OpenCV implementation of the <a class="reference external" href="http://docs.opencv.org/modules/video/doc/motion_analysis_and_object_tracking.html#kalmanfilter">Kalman Filter</a> based on <a class="reference external" href="http://campar.in.tum.de/Chair/KalmanFilter">Linear Kalman Filter for position and orientation tracking</a> to set the dynamics and measurement models.</p>
<p>Firstly, we have to define our state vector which will have 18 states: the positional data (x,y,z) with its first and second derivatives (velocity and acceleration), then rotation is added in form of three euler angles (roll, pitch, jaw) together with their first and second derivatives (angular velocity and acceleration)</p>
<blockquote>
<div><div class="math">
<p><img src="../../../../_images/math/1eca31153b2f95a0a8ee991e2ac91cd276a45245.png" alt="X = (x,y,z,\dot x,\dot y,\dot z,\ddot x,\ddot y,\ddot z,\psi,\theta,\phi,\dot \psi,\dot \theta,\dot \phi,\ddot \psi,\ddot \theta,\ddot \phi)^T"/></p>
</div></div></blockquote>
<p>Secondly, we have to define the number of measuremnts which will be 6: from <img class="math" src="../../../../_images/math/8fa391da5431a5d6eaba1325c3e7cb3da22812b5.png" alt="R"/> and <img class="math" src="../../../../_images/math/6f34bae44dd219fa449ea5ceb11b2f3270be2462.png" alt="t"/> we can extract <img class="math" src="../../../../_images/math/541153f6fa7bf1e7435a5fef6fad8f7eae2abf98.png" alt="(x,y,z)"/> and <img class="math" src="../../../../_images/math/02c55bb8b99b46e0a46faec0491d56cbbc0e4330.png" alt="(\psi,\theta,\phi)"/>. In addition, we have to define the number of control actions to apply to the system which in this case will be <em>zero</em>. Finally, we have to define the differential time between measurements which in this case is <img class="math" src="../../../../_images/math/d62c81a90a23ea5ef42c4cbffb35b48d42f89ae5.png" alt="1/T"/>, where <em>T</em> is the frame rate of the video.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="n">cv</span><span class="o">::</span><span class="n">KalmanFilter</span> <span class="n">KF</span><span class="p">;</span>         <span class="c1">// instantiate Kalman Filter</span>

<span class="kt">int</span> <span class="n">nStates</span> <span class="o">=</span> <span class="mi">18</span><span class="p">;</span>            <span class="c1">// the number of states</span>
<span class="kt">int</span> <span class="n">nMeasurements</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>       <span class="c1">// the number of measured states</span>
<span class="kt">int</span> <span class="n">nInputs</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>             <span class="c1">// the number of action control</span>

<span class="kt">double</span> <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.125</span><span class="p">;</span>           <span class="c1">// time between measurements (1/FPS)</span>

<span class="n">initKalmanFilter</span><span class="p">(</span><span class="n">KF</span><span class="p">,</span> <span class="n">nStates</span><span class="p">,</span> <span class="n">nMeasurements</span><span class="p">,</span> <span class="n">nInputs</span><span class="p">,</span> <span class="n">dt</span><span class="p">);</span>    <span class="c1">// init function</span>
</pre></div>
</div>
<p>The following code corresponds to the <em>Kalman Filter</em> initialisation. Firstly, is set the process noise, the measurement noise and the error covariance matrix. Secondly, are set the transition matrix which is the dynamic model and finally the measurement matrix, which is the measurement model.</p>
<p>You can tune the process and measurement noise to improve the <em>Kalman Filter</em> performance. As the measurement noise is reduced the faster will converge doing the algorithm sensitive in front of bad measurements.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="kt">void</span> <span class="nf">initKalmanFilter</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">KalmanFilter</span> <span class="o">&amp;</span><span class="n">KF</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nStates</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nMeasurements</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nInputs</span><span class="p">,</span> <span class="kt">double</span> <span class="n">dt</span><span class="p">)</span>
<span class="p">{</span>

  <span class="n">KF</span><span class="p">.</span><span class="n">init</span><span class="p">(</span><span class="n">nStates</span><span class="p">,</span> <span class="n">nMeasurements</span><span class="p">,</span> <span class="n">nInputs</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>                 <span class="c1">// init Kalman Filter</span>

  <span class="n">cv</span><span class="o">::</span><span class="n">setIdentity</span><span class="p">(</span><span class="n">KF</span><span class="p">.</span><span class="n">processNoiseCov</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Scalar</span><span class="o">::</span><span class="n">all</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">));</span>       <span class="c1">// set process noise</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">setIdentity</span><span class="p">(</span><span class="n">KF</span><span class="p">.</span><span class="n">measurementNoiseCov</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Scalar</span><span class="o">::</span><span class="n">all</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">));</span>   <span class="c1">// set measurement noise</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">setIdentity</span><span class="p">(</span><span class="n">KF</span><span class="p">.</span><span class="n">errorCovPost</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Scalar</span><span class="o">::</span><span class="n">all</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>             <span class="c1">// error covariance</span>


                 <span class="cm">/* DYNAMIC MODEL */</span>

  <span class="c1">//  [1 0 0 dt  0  0 dt2   0   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 1 0  0 dt  0   0 dt2   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 1  0  0 dt   0   0 dt2 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  1  0  0  dt   0   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  1  0   0  dt   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  1   0   0  dt 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   1   0   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   1   0 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   1 0 0 0  0  0  0   0   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 1 0 0 dt  0  0 dt2   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 1 0  0 dt  0   0 dt2   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 1  0  0 dt   0   0 dt2]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  1  0  0  dt   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  0  1  0   0  dt   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  1   0   0  dt]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   1   0   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   0   1   0]</span>
  <span class="c1">//  [0 0 0  0  0  0   0   0   0 0 0 0  0  0  0   0   0   1]</span>

  <span class="c1">// position</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>

  <span class="c1">// orientation</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">13</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">14</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">15</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">17</span><span class="p">)</span> <span class="o">=</span> <span class="n">dt</span><span class="p">;</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">15</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">16</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">transitionMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">17</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>


       <span class="cm">/* MEASUREMENT MODEL */</span>

  <span class="c1">//  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</span>
  <span class="c1">//  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</span>
  <span class="c1">//  [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</span>
  <span class="c1">//  [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]</span>
  <span class="c1">//  [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</span>
  <span class="c1">//  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]</span>

  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// x</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// y</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// z</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>  <span class="c1">// roll</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// pitch</span>
  <span class="n">KF</span><span class="p">.</span><span class="n">measurementMatrix</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// yaw</span>

<span class="p">}</span>
</pre></div>
</div>
<p>In the following code is the 5th step of the main algorithm. When the obtained number of inliers after <em>Ransac</em> is over the threshold, the measurements matrix is filled and then the <em>Kalman Filter</em> is updated:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// -- Step 5: Kalman Filter</span>

<span class="c1">// GOOD MEASUREMENT</span>
<span class="k">if</span><span class="p">(</span> <span class="n">inliers_idx</span><span class="p">.</span><span class="n">rows</span> <span class="o">&gt;=</span> <span class="n">minInliersKalman</span> <span class="p">)</span>
<span class="p">{</span>

    <span class="c1">// Get the measured translation</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">translation_measured</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>
    <span class="n">translation_measured</span> <span class="o">=</span> <span class="n">pnp_detection</span><span class="p">.</span><span class="n">get_t_matrix</span><span class="p">();</span>

    <span class="c1">// Get the measured rotation</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">rotation_measured</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>
    <span class="n">rotation_measured</span> <span class="o">=</span> <span class="n">pnp_detection</span><span class="p">.</span><span class="n">get_R_matrix</span><span class="p">();</span>

    <span class="c1">// fill the measurements vector</span>
    <span class="n">fillMeasurements</span><span class="p">(</span><span class="n">measurements</span><span class="p">,</span> <span class="n">translation_measured</span><span class="p">,</span> <span class="n">rotation_measured</span><span class="p">);</span>

<span class="p">}</span>

<span class="c1">// Instantiate estimated translation and rotation</span>
<span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">translation_estimated</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>
<span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">rotation_estimated</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>

<span class="c1">// update the Kalman filter with good measurements</span>
<span class="n">updateKalmanFilter</span><span class="p">(</span> <span class="n">KF</span><span class="p">,</span> <span class="n">measurements</span><span class="p">,</span>
              <span class="n">translation_estimated</span><span class="p">,</span> <span class="n">rotation_estimated</span><span class="p">);</span>
</pre></div>
</div>
<p>The following code corresponds to the <em>fillMeasurements()</em> function which converts the measured <a class="reference external" href="http://euclideanspace.com/maths/geometry/rotations/conversions/matrixToEuler/index.htm">Rotation Matrix to Eulers angles</a> and fill the measurements matrix along with the measured  translation vector:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="kt">void</span> <span class="nf">fillMeasurements</span><span class="p">(</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">measurements</span><span class="p">,</span>
                   <span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">translation_measured</span><span class="p">,</span> <span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">rotation_measured</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// Convert rotation matrix to euler angles</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">measured_eulers</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>
    <span class="n">measured_eulers</span> <span class="o">=</span> <span class="n">rot2euler</span><span class="p">(</span><span class="n">rotation_measured</span><span class="p">);</span>

    <span class="c1">// Set measurement to predict</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">translation_measured</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> <span class="c1">// x</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">translation_measured</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span> <span class="c1">// y</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">translation_measured</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span> <span class="c1">// z</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">=</span> <span class="n">measured_eulers</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>      <span class="c1">// roll</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">=</span> <span class="n">measured_eulers</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>      <span class="c1">// pitch</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">=</span> <span class="n">measured_eulers</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>      <span class="c1">// yaw</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following code corresponds to the <em>updateKalmanFilter()</em> function which update the Kalman Filter and set the estimated Rotation Matrix and translation vector. The estimated Rotation Matrix comes from the estimated <a class="reference external" href="http://euclideanspace.com/maths/geometry/rotations/conversions/eulerToMatrix/index.htm">Euler angles to Rotation Matrix</a>.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="kt">void</span> <span class="nf">updateKalmanFilter</span><span class="p">(</span> <span class="n">cv</span><span class="o">::</span><span class="n">KalmanFilter</span> <span class="o">&amp;</span><span class="n">KF</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">measurement</span><span class="p">,</span>
                     <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">translation_estimated</span><span class="p">,</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">rotation_estimated</span> <span class="p">)</span>
<span class="p">{</span>

    <span class="c1">// First predict, to update the internal statePre variable</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">prediction</span> <span class="o">=</span> <span class="n">KF</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span>

    <span class="c1">// The &quot;correct&quot; phase that is going to use the predicted value and our measurement</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">estimated</span> <span class="o">=</span> <span class="n">KF</span><span class="p">.</span><span class="n">correct</span><span class="p">(</span><span class="n">measurement</span><span class="p">);</span>

    <span class="c1">// Estimated translation</span>
    <span class="n">translation_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="n">translation_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">translation_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>

    <span class="c1">// Estimated euler angles</span>
    <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">eulers_estimated</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">CV_64F</span><span class="p">);</span>
    <span class="n">eulers_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">9</span><span class="p">);</span>
    <span class="n">eulers_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>
    <span class="n">eulers_estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="n">estimated</span><span class="p">.</span><span class="n">at</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">11</span><span class="p">);</span>

    <span class="c1">// Convert estimated quaternion to rotation matrix</span>
    <span class="n">rotation_estimated</span> <span class="o">=</span> <span class="n">euler2rot</span><span class="p">(</span><span class="n">eulers_estimated</span><span class="p">);</span>

<span class="p">}</span>
</pre></div>
</div>
<p>The 6th step is set the estimated rotation-translation matrix:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// -- Step 6: Set estimated projection matrix</span>
<span class="n">pnp_detection_est</span><span class="p">.</span><span class="n">set_P_matrix</span><span class="p">(</span><span class="n">rotation_estimated</span><span class="p">,</span> <span class="n">translation_estimated</span><span class="p">);</span>
</pre></div>
</div>
<p>The last and optional step is draw the found pose. To do it I implemented a function to draw all the mesh 3D points and an extra reference axis:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// -- Step X: Draw pose</span>

<span class="n">drawObjectMesh</span><span class="p">(</span><span class="n">frame_vis</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">mesh</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">pnp_detection</span><span class="p">,</span> <span class="n">green</span><span class="p">);</span>                <span class="c1">// draw current pose</span>
<span class="n">drawObjectMesh</span><span class="p">(</span><span class="n">frame_vis</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">mesh</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">pnp_detection_est</span><span class="p">,</span> <span class="n">yellow</span><span class="p">);</span>           <span class="c1">// draw estimated pose</span>

<span class="kt">double</span> <span class="n">l</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cv</span><span class="o">::</span><span class="n">Point2f</span><span class="o">&gt;</span> <span class="n">pose_points2d</span><span class="p">;</span>
<span class="n">pose_points2d</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">pnp_detection_est</span><span class="p">.</span><span class="n">backproject3DPoint</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)));</span>    <span class="c1">// axis center</span>
<span class="n">pose_points2d</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">pnp_detection_est</span><span class="p">.</span><span class="n">backproject3DPoint</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)));</span>    <span class="c1">// axis x</span>
<span class="n">pose_points2d</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">pnp_detection_est</span><span class="p">.</span><span class="n">backproject3DPoint</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">)));</span>    <span class="c1">// axis y</span>
<span class="n">pose_points2d</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">pnp_detection_est</span><span class="p">.</span><span class="n">backproject3DPoint</span><span class="p">(</span><span class="n">cv</span><span class="o">::</span><span class="n">Point3f</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">l</span><span class="p">)));</span>    <span class="c1">// axis z</span>
<span class="n">draw3DCoordinateAxes</span><span class="p">(</span><span class="n">frame_vis</span><span class="p">,</span> <span class="n">pose_points2d</span><span class="p">);</span>                                       <span class="c1">// draw axes</span>
</pre></div>
</div>
<p>You can also modify the minimum inliers to update Kalman Filter:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="p">.</span><span class="o">/</span><span class="n">cpp</span><span class="o">-</span><span class="n">tutorial</span><span class="o">-</span><span class="n">pnp_detection</span> <span class="o">--</span><span class="n">inliers</span><span class="o">=</span><span class="mi">20</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p>The following videos are the results of pose estimation in real time using the explained detection algorithm using the following parameters:</p>
<blockquote>
<div><div class="highlight-cpp"><div class="highlight"><pre><span class="c1">// Robust Matcher parameters</span>

<span class="kt">int</span> <span class="n">numKeyPoints</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">;</span>      <span class="c1">// number of detected keypoints</span>
<span class="kt">float</span> <span class="n">ratio</span> <span class="o">=</span> <span class="mf">0.70f</span><span class="p">;</span>          <span class="c1">// ratio test</span>
<span class="kt">bool</span> <span class="n">fast_match</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>       <span class="c1">// fastRobustMatch() or robustMatch()</span>


<span class="c1">// RANSAC parameters</span>

<span class="kt">int</span> <span class="n">iterationsCount</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span>    <span class="c1">// number of Ransac iterations.</span>
<span class="kt">int</span> <span class="n">reprojectionError</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">;</span>  <span class="c1">// maximum allowed distance to consider it an inlier.</span>
<span class="kt">float</span> <span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">;</span>      <span class="c1">// ransac successful confidence.</span>


<span class="c1">// Kalman Filter parameters</span>

<span class="kt">int</span> <span class="n">minInliersKalman</span> <span class="o">=</span> <span class="mi">30</span><span class="p">;</span>    <span class="c1">// Kalman threshold updating</span>
</pre></div>
</div>
</div></blockquote>
<p>You can watch the real time pose estimation on the <a class="reference external" href="http://www.youtube.com/user/opencvdev/videos">YouTube here</a>.</p>
<div align="center">
<iframe title="Pose estimation of textured object using OpenCV" width="560" height="349" src="http://www.youtube.com/embed/XNATklaJlSQ?rel=0&amp;loop=1" frameborder="0" allowfullscreen align="middle"></iframe>
</div>
<div align="center">
<iframe title="Pose estimation of textured object using OpenCV in cluttered background" width="560" height="349" src="http://www.youtube.com/embed/YLS9bWek78k?rel=0&amp;loop=1" frameborder="0" allowfullscreen align="middle"></iframe>
</div></div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org/">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org/">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../features2d/table_of_content_features2d/table_of_content_features2d.html" title="feature2d module. 2D Features framework"
             >next</a> |</li>
        <li class="right" >
          <a href="../camera_calibration/camera_calibration.html" title="Camera calibration With OpenCV"
             >previous</a> |</li>
        <li><a href="../../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../tutorials.html" >OpenCV Tutorials</a> &raquo;</li>
          <li><a href="../table_of_content_calib3d/table_of_content_calib3d.html" ><em>calib3d</em> module. Camera calibration and 3D reconstruction</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Dec 30, 2014.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
      <a href="../../../../_sources/doc/tutorials/calib3d/real_time_pose/real_time_pose.txt" rel="nofollow">Show this page source.</a>
    </div>
  </body>

<!-- Mirrored from docs.opencv.org/3.0-last-rst/doc/tutorials/calib3d/real_time_pose/real_time_pose.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 07:06:04 GMT -->
</html>