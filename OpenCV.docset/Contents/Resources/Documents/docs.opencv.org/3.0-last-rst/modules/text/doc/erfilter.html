<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-33108845-1']);
  _gaq.push(['_setDomainName', 'opencv.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<html xmlns="http://www.w3.org/1999/xhtml">
  
<!-- Mirrored from docs.opencv.org/3.0-last-rst/modules/text/doc/erfilter.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 06:59:18 GMT -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Scene Text Detection</title>
    
    <link rel="stylesheet" href="../../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '3.0.0-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/insertIframe.js"></script>
    <link rel="top" title="OpenCV 3.0.0-dev documentation" href="../../../index.html" />
    <link rel="up" title="text. Scene Text Detection and Recognition" href="text.html" />
    <link rel="next" title="Scene Text Recognition" href="ocr.html" />
    <link rel="prev" title="text. Scene Text Detection and Recognition" href="text.html" />
    <link href='../../../../../fonts.googleapis.com/css8a7c.css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
    <style type="text/css">
      table.right { float: right; margin-left: 20px; }
      table.right td { border: 1px solid #ccc; }
    </style>
    <script type="text/javascript">
      // intelligent scrolling of the sidebar content
      $(window).scroll(function() {
        var sb = $('.sphinxsidebarwrapper');
        var win = $(window);
        var sbh = sb.height();
        var offset = $('.sphinxsidebar').position()['top'];
        var wintop = win.scrollTop();
        var winbot = wintop + win.innerHeight();
        var curtop = sb.position()['top'];
        var curbot = curtop + sbh;
        // does sidebar fit in window?
        if (sbh < win.innerHeight()) {
          // yes: easy case -- always keep at the top
          sb.css('top', $u.min([$u.max([0, wintop - offset - 10]),
                                $(document).height() - sbh - 200]));
        } else {
          // no: only scroll if top/bottom edge of sidebar is at
          // top/bottom edge of window
          if (curtop > wintop && curbot > winbot) {
            sb.css('top', $u.max([wintop - offset - 10, 0]));
          } else if (curtop < wintop && curbot < winbot) {
            sb.css('top', $u.min([winbot - sbh - offset - 20,
                                  $(document).height() - sbh - 200]));
          }
        }
      });
    </script>

  </head>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="ocr.html" title="Scene Text Recognition"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="text.html" title="text. Scene Text Detection and Recognition"
             accesskey="P">previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="text.html" accesskey="U">text. Scene Text Detection and Recognition</a> &raquo;</li> 
      </ul>
    </div>  
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/opencv-logo2.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="http://docs.opencv.org/3.0-last-rst/search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
  <h3><a href="../../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Scene Text Detection</a><ul>
<li><a class="reference internal" href="#class-specific-extremal-regions-for-scene-text-detection">Class-specific Extremal Regions for Scene Text Detection</a></li>
<li><a class="reference internal" href="#erstat">ERStat</a></li>
<li><a class="reference internal" href="#mserstoerstats">MSERsToERStats</a></li>
<li><a class="reference internal" href="#computenmchannels">computeNMChannels</a></li>
<li><a class="reference internal" href="#erfilter">ERFilter</a></li>
<li><a class="reference internal" href="#erfilter-callback">ERFilter::Callback</a></li>
<li><a class="reference internal" href="#erfilter-callback-eval">ERFilter::Callback::eval</a></li>
<li><a class="reference internal" href="#erfilter-run">ERFilter::run</a></li>
<li><a class="reference internal" href="#createerfilternm1">createERFilterNM1</a></li>
<li><a class="reference internal" href="#createerfilternm2">createERFilterNM2</a></li>
<li><a class="reference internal" href="#loadclassifiernm1">loadClassifierNM1</a></li>
<li><a class="reference internal" href="#loadclassifiernm2">loadClassifierNM2</a></li>
<li><a class="reference internal" href="#ergrouping">erGrouping</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="text.html"
                        title="previous chapter">text. Scene Text Detection and Recognition</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="ocr.html"
                        title="next chapter">Scene Text Recognition</a></p>
        </div>
      </div>
  <body>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="scene-text-detection">
<h1>Scene Text Detection<a class="headerlink" href="#scene-text-detection" title="Permalink to this headline">¶</a></h1>
<div class="section" id="class-specific-extremal-regions-for-scene-text-detection">
<h2>Class-specific Extremal Regions for Scene Text Detection<a class="headerlink" href="#class-specific-extremal-regions-for-scene-text-detection" title="Permalink to this headline">¶</a></h2>
<p>The scene text detection algorithm described below has been initially proposed by Lukás Neumann &amp; Jiri Matas [Neumann12]. The main idea behind Class-specific Extremal Regions is similar to the MSER in that suitable Extremal Regions (ERs) are selected from the whole component tree of the image. However, this technique differs from MSER in that selection of suitable ERs is done by a sequential classifier trained for character detection, i.e. dropping the stability requirement of MSERs and selecting class-specific (not necessarily stable) regions.</p>
<p>The component tree of an image is constructed by thresholding by an increasing value step-by-step from 0 to 255 and then linking the obtained connected components from successive levels in a hierarchy by their inclusion relation:</p>
<a class="reference internal image-reference" href="../../../_images/component_tree.png"><img alt="../../../_images/component_tree.png" src="../../../_images/component_tree.png" style="width: 100%;" /></a>
<p>The component tree may conatain a huge number of regions even for a very simple image as shown in the previous image. This number can easily reach the order of 1 x 10^6 regions for an average 1 Megapixel image. In order to efficiently select suitable regions among all the ERs the algorithm make use of a sequential classifier with two differentiated stages.</p>
<p>In the first stage incrementally computable descriptors (area, perimeter, bounding box, and euler number) are computed (in O(1)) for each region r and used as features for a classifier which estimates the class-conditional probability p(r|character). Only the ERs which correspond to local maximum of the probability p(r|character) are selected (if their probability is above a global limit p_min and the difference between local maximum and local minimum is greater than a delta_min value).</p>
<p>In the second stage, the ERs that passed the first stage are classified into character and non-character classes using more informative but also more computationally expensive features. (Hole area ratio, convex hull ratio, and the number of outer boundary inflexion points).</p>
<p>This ER filtering process is done in different single-channel projections of the input image in order to increase the character localization recall.</p>
<p>After the ER filtering is done on each input channel, character candidates must be grouped in high-level text blocks (i.e. words, text lines, paragraphs, ...). The opencv_text module implements two different grouping algorithms: the Exhaustive Search algorithm proposed in [Neumann11] for grouping horizontally aligned text, and the method proposed by Lluis Gomez and Dimosthenis Karatzas in [Gomez13][Gomez14] for grouping arbitrary oriented text (see <a class="reference internal" href="#void erGrouping(InputArray img, InputArrayOfArrays channels, std::vector&lt;std::vector&lt;ERStat&gt; &gt; &amp;regions, std::vector&lt;std::vector&lt;Vec2i&gt; &gt; &amp;groups, std::vector&lt;Rect&gt; &amp;groups_rects, int method , const std::string&amp; filename , float minProbablity)" title="void erGrouping(InputArray img, InputArrayOfArrays channels, std::vector&lt;std::vector&lt;ERStat&gt; &gt; &amp;regions, std::vector&lt;std::vector&lt;Vec2i&gt; &gt; &amp;groups, std::vector&lt;Rect&gt; &amp;groups_rects, int method , const std::string&amp; filename , float minProbablity)"><tt class="xref ocv ocv-func docutils literal"><span class="pre">erGrouping()</span></tt></a>).</p>
<p>To see the text detector at work, have a look at the textdetection demo: <a class="reference external" href="https://github.com/Itseez/opencv_contrib/blob/master/modules/text/samples/textdetection.cpp">https://github.com/Itseez/opencv_contrib/blob/master/modules/text/samples/textdetection.cpp</a></p>
<table class="docutils citation" frame="void" id="neumann12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Neumann12]</td><td>Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012. The paper is available online at <a class="reference external" href="http://cmp.felk.cvut.cz/~neumalu1/neumann-cvpr2012.pdf">http://cmp.felk.cvut.cz/~neumalu1/neumann-cvpr2012.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="neumann11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Neumann11]</td><td>Neumann L., Matas J.: Text Localization in Real-world Images using Efficiently Pruned Exhaustive Search, ICDAR 2011. The paper is available online at <a class="reference external" href="http://cmp.felk.cvut.cz/~neumalu1/icdar2011_article.pdf">http://cmp.felk.cvut.cz/~neumalu1/icdar2011_article.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="gomez13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Gomez13]</td><td>Gomez L. and Karatzas D.: Multi-script Text Extraction from Natural Scenes, ICDAR 2013. The paper is available online at <a class="reference external" href="http://158.109.8.37/files/GoK2013.pdf">http://158.109.8.37/files/GoK2013.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="gomez14" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Gomez14]</td><td>Gomez L. and Karatzas D.: A Fast Hierarchical Method for Multi-script and Arbitrary Oriented Scene Text Extraction, arXiv:1407.7504 [cs.CV]. The paper is available online at http://arxiv.org/abs/1407.7504</td></tr>
</tbody>
</table>
</div>
<div class="section" id="erstat">
<h2>ERStat<a class="headerlink" href="#erstat" title="Permalink to this headline">¶</a></h2>
<dl class="struct">
<dt id="ERStat">
<em class="property">struct </em><tt class="descname">ERStat</tt><a class="headerlink" href="#ERStat" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>The ERStat structure represents a class-specific Extremal Region (ER).</p>
<p>An ER is a 4-connected set of pixels with all its grey-level values smaller than the values in its outer boundary. A class-specific ER is selected (using a classifier) from all the ER&#8217;s in the component tree of the image.</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="k">struct</span> <span class="n">CV_EXPORTS</span> <span class="n">ERStat</span>
<span class="p">{</span>
<span class="nl">public:</span>
    <span class="c1">//! Constructor</span>
    <span class="k">explicit</span> <span class="n">ERStat</span><span class="p">(</span><span class="kt">int</span> <span class="n">level</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="kt">int</span> <span class="n">pixel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">);</span>
    <span class="c1">//! Destructor</span>
    <span class="o">~</span><span class="n">ERStat</span><span class="p">()</span> <span class="p">{</span> <span class="p">}</span>

    <span class="c1">//! seed point and threshold (max grey-level value)</span>
    <span class="kt">int</span> <span class="n">pixel</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">level</span><span class="p">;</span>

    <span class="c1">//! incrementally computable features</span>
    <span class="kt">int</span> <span class="n">area</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">perimeter</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">euler</span><span class="p">;</span>                 <span class="c1">//!&lt; euler number</span>
    <span class="n">Rect</span> <span class="n">rect</span><span class="p">;</span>                 <span class="c1">//!&lt; bounding box</span>
    <span class="kt">double</span> <span class="n">raw_moments</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>     <span class="c1">//!&lt; order 1 raw moments to derive the centroid</span>
    <span class="kt">double</span> <span class="n">central_moments</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span> <span class="c1">//!&lt; order 2 central moments to construct the covariance matrix</span>
    <span class="n">std</span><span class="o">::</span><span class="n">deque</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="o">*</span><span class="n">crossings</span><span class="p">;</span><span class="c1">//!&lt; horizontal crossings</span>
    <span class="kt">float</span> <span class="n">med_crossings</span><span class="p">;</span>       <span class="c1">//!&lt; median of the crossings at three different height levels</span>

    <span class="c1">//! 2nd stage features</span>
    <span class="kt">float</span> <span class="n">hole_area_ratio</span><span class="p">;</span>
    <span class="kt">float</span> <span class="n">convex_hull_ratio</span><span class="p">;</span>
    <span class="kt">float</span> <span class="n">num_inflexion_points</span><span class="p">;</span>

    <span class="c1">//! probability that the ER belongs to the class we are looking for</span>
    <span class="kt">double</span> <span class="n">probability</span><span class="p">;</span>

    <span class="c1">//! pointers preserving the tree structure of the component tree</span>
    <span class="n">ERStat</span><span class="o">*</span> <span class="n">parent</span><span class="p">;</span>
    <span class="n">ERStat</span><span class="o">*</span> <span class="n">child</span><span class="p">;</span>
    <span class="n">ERStat</span><span class="o">*</span> <span class="n">next</span><span class="p">;</span>
    <span class="n">ERStat</span><span class="o">*</span> <span class="n">prev</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
</div>
<div class="section" id="mserstoerstats">
<h2>MSERsToERStats<a class="headerlink" href="#mserstoerstats" title="Permalink to this headline">¶</a></h2>
<p>Converts MSER contours (vector&lt;Point&gt;) to ERStat regions.</p>
<dl class="function">
<dt id="void MSERsToERStats(InputArray image, vector&lt; vector&lt;Point&gt; &gt; &amp;contours, vector&lt; vector&lt;ERStat&gt; &gt; &amp;regions)">
<strong>C++:</strong><tt class="descname"> </tt>void <tt class="descname">MSERsToERStats</tt><big>(</big>InputArray <strong>image</strong>, vector&lt;vector&lt;Point&gt;&gt;&amp; <strong>contours</strong>, vector&lt;vector&lt;ERStat&gt;&gt;&amp; <strong>regions</strong><big>)</big><a class="headerlink" href="#void MSERsToERStats(InputArray image, vector< vector<Point> > &contours, vector< vector<ERStat> > &regions)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> &#8211; Source image <tt class="docutils literal"><span class="pre">CV_8UC1</span></tt> from which the MSERs where extracted.</li>
<li><strong>contours</strong> &#8211; Intput vector with all the contours (vector&lt;Point&gt;).</li>
<li><strong>regions</strong> &#8211; Output where the ERStat regions are stored.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>It takes as input the contours provided by the OpenCV MSER feature detector and returns as output two vectors of ERStats. This is because MSER() output contains both MSER+ and MSER- regions in a single vector&lt;Point&gt;, the function separates them in two different vectors (this is as if the ERStats where extracted from two different channels).</p>
<p>An example of MSERsToERStats in use can be found in the text detection webcam_demo: <a class="reference external" href="https://github.com/Itseez/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp">https://github.com/Itseez/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp</a></p>
</div>
<div class="section" id="computenmchannels">
<h2>computeNMChannels<a class="headerlink" href="#computenmchannels" title="Permalink to this headline">¶</a></h2>
<p>Compute the different channels to be processed independently in the N&amp;M algorithm [Neumann12].</p>
<dl class="function">
<dt id="void computeNMChannels(InputArray _src, OutputArrayOfArrays _channels, int _mode)">
<strong>C++:</strong><tt class="descname"> </tt>void <tt class="descname">computeNMChannels</tt><big>(</big>InputArray <strong>_src</strong>, OutputArrayOfArrays <strong>_channels</strong>, int <strong>_mode</strong>=ERFILTER_NM_RGBLGrad<big>)</big><a class="headerlink" href="#void computeNMChannels(InputArray _src, OutputArrayOfArrays _channels, int _mode)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>_src</strong> &#8211; Source image. Must be RGB <tt class="docutils literal"><span class="pre">CV_8UC3</span></tt>.</li>
<li><strong>_channels</strong> &#8211; Output vector&lt;Mat&gt; where computed channels are stored.</li>
<li><strong>_mode</strong> &#8211; Mode of operation. Currently the only available options are: <strong>ERFILTER_NM_RGBLGrad</strong> (used by default) and <strong>ERFILTER_NM_IHSGrad</strong>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>In N&amp;M algorithm, the combination of intensity (I), hue (H), saturation (S), and gradient magnitude channels (Grad) are used in order to obtain high localization recall. This implementation also provides an alternative combination of red (R), green (G), blue (B), lightness (L), and gradient magnitude (Grad).</p>
</div>
<div class="section" id="erfilter">
<h2>ERFilter<a class="headerlink" href="#erfilter" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ERFilter : public Algorithm">
<em class="property">class </em><tt class="descname">ERFilter</tt> : <em class="property">public</em> <tt class="descname">Algorithm</tt><a class="headerlink" href="#ERFilter : public Algorithm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>Base class for 1st and 2nd stages of Neumann and Matas scene text detection algorithm [Neumann12].</p>
<div class="highlight-cpp"><div class="highlight"><pre><span class="k">class</span> <span class="nc">CV_EXPORTS</span> <span class="n">ERFilter</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Algorithm</span>
<span class="p">{</span>
<span class="nl">public:</span>

    <span class="c1">//! callback with the classifier is made a class.</span>
    <span class="c1">//! By doing it we hide SVM, Boost etc. Developers can provide their own classifiers</span>
    <span class="k">class</span> <span class="nc">CV_EXPORTS</span> <span class="n">Callback</span>
    <span class="p">{</span>
    <span class="nl">public:</span>
        <span class="k">virtual</span> <span class="o">~</span><span class="n">Callback</span><span class="p">()</span> <span class="p">{</span> <span class="p">}</span>
        <span class="c1">//! The classifier must return probability measure for the region.</span>
        <span class="k">virtual</span> <span class="kt">double</span> <span class="n">eval</span><span class="p">(</span><span class="k">const</span> <span class="n">ERStat</span><span class="o">&amp;</span> <span class="n">stat</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">};</span>

    <span class="cm">/*!</span>
<span class="cm">    the key method. Takes image on input and returns the selected regions in a vector of ERStat</span>
<span class="cm">    only distinctive ERs which correspond to characters are selected by a sequential classifier</span>
<span class="cm">    */</span>
    <span class="k">virtual</span> <span class="kt">void</span> <span class="n">run</span><span class="p">(</span> <span class="n">InputArray</span> <span class="n">image</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">ERStat</span><span class="o">&gt;&amp;</span> <span class="n">regions</span> <span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="p">(...)</span>

<span class="p">};</span>
</pre></div>
</div>
</div>
<div class="section" id="erfilter-callback">
<h2>ERFilter::Callback<a class="headerlink" href="#erfilter-callback" title="Permalink to this headline">¶</a></h2>
<p>Callback with the classifier is made a class. By doing it we hide SVM, Boost etc. Developers can provide their own classifiers to the ERFilter algorithm.</p>
<dl class="class">
<dt id="ERFilter::Callback">
<em class="property">class </em><tt class="descclassname">ERFilter::</tt><tt class="descname">Callback</tt><a class="headerlink" href="#ERFilter::Callback" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="erfilter-callback-eval">
<h2>ERFilter::Callback::eval<a class="headerlink" href="#erfilter-callback-eval" title="Permalink to this headline">¶</a></h2>
<p>The classifier must return probability measure for the region.</p>
<dl class="function">
<dt id="double ERFilter::Callback::eval(const ERStat&amp; stat)">
<strong>C++:</strong><tt class="descname"> </tt>double <tt class="descclassname">ERFilter::Callback::</tt><tt class="descname">eval</tt><big>(</big>const ERStat&amp; <strong>stat</strong><big>)</big><a class="headerlink" href="#double ERFilter::Callback::eval(const ERStat& stat)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>stat</strong> &#8211; The region to be classified</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="erfilter-run">
<h2>ERFilter::run<a class="headerlink" href="#erfilter-run" title="Permalink to this headline">¶</a></h2>
<p>The key method of ERFilter algorithm. Takes image on input and returns the selected regions in a vector of ERStat only distinctive ERs which correspond to characters are selected by a sequential classifier</p>
<dl class="function">
<dt id="void ERFilter::run(InputArray image, std::vector&lt;ERStat&gt;&amp; regions)">
<strong>C++:</strong><tt class="descname"> </tt>void <tt class="descclassname">ERFilter::</tt><tt class="descname">run</tt><big>(</big>InputArray <strong>image</strong>, std::vector&lt;ERStat&gt;&amp; <strong>regions</strong><big>)</big><a class="headerlink" href="#void ERFilter::run(InputArray image, std::vector<ERStat>& regions)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> &#8211; Sinle channel image <tt class="docutils literal"><span class="pre">CV_8UC1</span></tt></li>
<li><strong>regions</strong> &#8211; Output for the 1st stage and Input/Output for the 2nd. The selected Extremal Regions are stored here.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>Extracts the component tree (if needed) and filter the extremal regions (ER&#8217;s) by using a given classifier.</p>
</div>
<div class="section" id="createerfilternm1">
<h2>createERFilterNM1<a class="headerlink" href="#createerfilternm1" title="Permalink to this headline">¶</a></h2>
<p>Create an Extremal Region Filter for the 1st stage classifier of N&amp;M algorithm [Neumann12].</p>
<dl class="function">
<dt id="Ptr&lt;ERFilter&gt; createERFilterNM1(const Ptr&lt;ERFilter::Callback&gt;&amp; cb, int thresholdDelta , float minArea , float maxArea , float minProbability , bool nonMaxSuppression , float minProbabilityDiff)">
<strong>C++:</strong><tt class="descname"> </tt>Ptr&lt;ERFilter&gt; <tt class="descname">createERFilterNM1</tt><big>(</big>const Ptr&lt;ERFilter::Callback&gt;&amp; <strong>cb</strong>, int <strong>thresholdDelta</strong>=1, float <strong>minArea</strong>=0.00025, float <strong>maxArea</strong>=0.13, float <strong>minProbability</strong>=0.4, bool <strong>nonMaxSuppression</strong>=true, float <strong>minProbabilityDiff</strong>=0.1 <big>)</big><a class="headerlink" href="#Ptr<ERFilter> createERFilterNM1(const Ptr<ERFilter::Callback>& cb, int thresholdDelta , float minArea , float maxArea , float minProbability , bool nonMaxSuppression , float minProbabilityDiff)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>cb</strong> &#8211; Callback with the classifier. Default classifier can be implicitly load with function <a class="reference internal" href="#Ptr&lt;ERFilter::Callback&gt; loadClassifierNM1(const std::string&amp; filename)" title="Ptr&lt;ERFilter::Callback&gt; loadClassifierNM1(const std::string&amp; filename)"><tt class="xref ocv ocv-func docutils literal"><span class="pre">loadClassifierNM1()</span></tt></a>, e.g. from file in samples/cpp/trained_classifierNM1.xml</li>
<li><strong>thresholdDelta</strong> &#8211; Threshold step in subsequent thresholds when extracting the component tree</li>
<li><strong>minArea</strong> &#8211; The minimum area (% of image size) allowed for retreived ER&#8217;s</li>
<li><strong>minArea</strong> &#8211; The maximum area (% of image size) allowed for retreived ER&#8217;s</li>
<li><strong>minProbability</strong> &#8211; The minimum probability P(er|character) allowed for retreived ER&#8217;s</li>
<li><strong>nonMaxSuppression</strong> &#8211; Whenever non-maximum suppression is done over the branch probabilities</li>
<li><strong>minProbability</strong> &#8211; The minimum probability difference between local maxima and local minima ERs</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>The component tree of the image is extracted by a threshold increased step by step from 0 to 255, incrementally computable descriptors (aspect_ratio, compactness, number of holes, and number of horizontal crossings) are computed for each ER and used as features for a classifier which estimates the class-conditional probability P(er|character). The value of P(er|character) is tracked using the inclusion relation of ER across all thresholds and only the ERs which correspond to local maximum of the probability P(er|character) are selected (if the local maximum of the probability is above a global limit pmin and the difference between local maximum and local minimum is greater than minProbabilityDiff).</p>
</div>
<div class="section" id="createerfilternm2">
<h2>createERFilterNM2<a class="headerlink" href="#createerfilternm2" title="Permalink to this headline">¶</a></h2>
<p>Create an Extremal Region Filter for the 2nd stage classifier of N&amp;M algorithm [Neumann12].</p>
<dl class="function">
<dt id="Ptr&lt;ERFilter&gt; createERFilterNM2(const Ptr&lt;ERFilter::Callback&gt;&amp; cb, float minProbability)">
<strong>C++:</strong><tt class="descname"> </tt>Ptr&lt;ERFilter&gt; <tt class="descname">createERFilterNM2</tt><big>(</big>const Ptr&lt;ERFilter::Callback&gt;&amp; <strong>cb</strong>, float <strong>minProbability</strong>=0.3 <big>)</big><a class="headerlink" href="#Ptr<ERFilter> createERFilterNM2(const Ptr<ERFilter::Callback>& cb, float minProbability)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>cb</strong> &#8211; Callback with the classifier. Default classifier can be implicitly load with function <a class="reference internal" href="#Ptr&lt;ERFilter::Callback&gt; loadClassifierNM2(const std::string&amp; filename)" title="Ptr&lt;ERFilter::Callback&gt; loadClassifierNM2(const std::string&amp; filename)"><tt class="xref ocv ocv-func docutils literal"><span class="pre">loadClassifierNM2()</span></tt></a>, e.g. from file in samples/cpp/trained_classifierNM2.xml</li>
<li><strong>minProbability</strong> &#8211; The minimum probability P(er|character) allowed for retreived ER&#8217;s</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>In the second stage, the ERs that passed the first stage are classified into character and non-character classes using more informative but also more computationally expensive features. The classifier uses all the features calculated in the first stage and the following additional features: hole area ratio, convex hull ratio, and number of outer inflexion points.</p>
</div>
<div class="section" id="loadclassifiernm1">
<h2>loadClassifierNM1<a class="headerlink" href="#loadclassifiernm1" title="Permalink to this headline">¶</a></h2>
<p>Allow to implicitly load the default classifier when creating an ERFilter object.</p>
<dl class="function">
<dt id="Ptr&lt;ERFilter::Callback&gt; loadClassifierNM1(const std::string&amp; filename)">
<strong>C++:</strong><tt class="descname"> </tt>Ptr&lt;ERFilter::Callback&gt; <tt class="descname">loadClassifierNM1</tt><big>(</big>const std::string&amp; <strong>filename</strong><big>)</big><a class="headerlink" href="#Ptr<ERFilter::Callback> loadClassifierNM1(const std::string& filename)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>filename</strong> &#8211; The XML or YAML file with the classifier model (e.g. trained_classifierNM1.xml)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>returns a pointer to ERFilter::Callback.</p>
</div>
<div class="section" id="loadclassifiernm2">
<h2>loadClassifierNM2<a class="headerlink" href="#loadclassifiernm2" title="Permalink to this headline">¶</a></h2>
<p>Allow to implicitly load the default classifier when creating an ERFilter object.</p>
<dl class="function">
<dt id="Ptr&lt;ERFilter::Callback&gt; loadClassifierNM2(const std::string&amp; filename)">
<strong>C++:</strong><tt class="descname"> </tt>Ptr&lt;ERFilter::Callback&gt; <tt class="descname">loadClassifierNM2</tt><big>(</big>const std::string&amp; <strong>filename</strong><big>)</big><a class="headerlink" href="#Ptr<ERFilter::Callback> loadClassifierNM2(const std::string& filename)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>filename</strong> &#8211; The XML or YAML file with the classifier model (e.g. trained_classifierNM2.xml)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>returns a pointer to ERFilter::Callback.</p>
</div>
<div class="section" id="ergrouping">
<h2>erGrouping<a class="headerlink" href="#ergrouping" title="Permalink to this headline">¶</a></h2>
<p>Find groups of Extremal Regions that are organized as text blocks.</p>
<dl class="function">
<dt id="void erGrouping(InputArray img, InputArrayOfArrays channels, std::vector&lt;std::vector&lt;ERStat&gt; &gt; &amp;regions, std::vector&lt;std::vector&lt;Vec2i&gt; &gt; &amp;groups, std::vector&lt;Rect&gt; &amp;groups_rects, int method , const std::string&amp; filename , float minProbablity)">
<strong>C++:</strong><tt class="descname"> </tt>void <tt class="descname">erGrouping</tt><big>(</big>InputArray <strong>img</strong>, InputArrayOfArrays <strong>channels</strong>, std::vector&lt;std::vector&lt;ERStat&gt;&gt;&amp; <strong>regions</strong>, std::vector&lt;std::vector&lt;Vec2i&gt;&gt;&amp; <strong>groups</strong>, std::vector&lt;Rect&gt;&amp; <strong>groups_rects</strong>, int <strong>method</strong>=ERGROUPING_ORIENTATION_HORIZ, const std::string&amp; <strong>filename</strong>=std::string(), float <strong>minProbablity</strong>=0.5<big>)</big><a class="headerlink" href="#void erGrouping(InputArray img, InputArrayOfArrays channels, std::vector<std::vector<ERStat> > &regions, std::vector<std::vector<Vec2i> > &groups, std::vector<Rect> &groups_rects, int method , const std::string& filename , float minProbablity)" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> &#8211; Original RGB or Greyscale image from wich the regions were extracted.</li>
<li><strong>src</strong> &#8211; Vector of single channel images CV_8UC1 from wich the regions were extracted.</li>
<li><strong>regions</strong> &#8211; Vector of ER&#8217;s retreived from the ERFilter algorithm from each channel.</li>
<li><strong>groups</strong> &#8211; The output of the algorithm is stored in this parameter as set of lists of indexes to provided regions.</li>
<li><strong>groups_rects</strong> &#8211; The output of the algorithm are stored in this parameter as list of rectangles.</li>
<li><strong>method</strong> &#8211; Grouping method (see the details below). Can be one of <tt class="docutils literal"><span class="pre">ERGROUPING_ORIENTATION_HORIZ</span></tt>, <tt class="docutils literal"><span class="pre">ERGROUPING_ORIENTATION_ANY</span></tt>.</li>
<li><strong>filename</strong> &#8211; The XML or YAML file with the classifier model (e.g. samples/trained_classifier_erGrouping.xml). Only to use when grouping method is <tt class="docutils literal"><span class="pre">ERGROUPING_ORIENTATION_ANY</span></tt>.</li>
<li><strong>minProbability</strong> &#8211; The minimum probability for accepting a group. Only to use when grouping method is <tt class="docutils literal"><span class="pre">ERGROUPING_ORIENTATION_ANY</span></tt>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>This function implements two different grouping algorithms:</p>
<blockquote>
<div><ul class="simple">
<li><strong>ERGROUPING_ORIENTATION_HORIZ</strong></li>
</ul>
<p>Exhaustive Search algorithm proposed in [Neumann11] for grouping horizontally aligned text. The algorithm models a verification function for all the possible ER sequences. The verification fuction for ER pairs consists in a set of threshold-based pairwise rules which compare measurements of two regions (height ratio, centroid angle, and region distance). The verification function for ER triplets creates a word text line estimate using Least Median-Squares fitting for a given triplet and then verifies that the estimate is valid (based on thresholds created during training). Verification functions for sequences larger than 3 are approximated by verifying that the text line parameters of all (sub)sequences of length 3 are consistent.</p>
<ul class="simple">
<li><strong>ERGROUPING_ORIENTATION_ANY</strong></li>
</ul>
<p>Text grouping method proposed in [Gomez13][Gomez14] for grouping arbitrary oriented text. Regions are agglomerated by Single Linkage Clustering in a weighted feature space that combines proximity (x,y coordinates) and similarity measures (color, size, gradient magnitude, stroke width, etc.). SLC provides a dendrogram where each node represents a text group hypothesis. Then the algorithm finds the branches corresponding to text groups by traversing this dendrogram with a stopping rule that combines the output of a rotation invariant text group classifier and a probabilistic measure for hierarchical clustering validity assessment.</p>
</div></blockquote>
</div>
</div>


          </div>
          <div class="feedback">
              <h2>Help and Feedback</h2>
              You did not find what you were looking for?
              <ul>
                  
                  
                  
                  <li>Ask a question on the <a href="http://answers.opencv.org/">Q&A forum</a>.</li>
                  <li>If you think something is missing or wrong in the documentation,
                  please file a <a href="http://code.opencv.org/">bug report</a>.</li>
              </ul>
          </div>
        </div>
      </div>

      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="ocr.html" title="Scene Text Recognition"
             >next</a> |</li>
        <li class="right" >
          <a href="text.html" title="text. Scene Text Detection and Recognition"
             >previous</a> |</li>
        <li><a href="../../../index.html">OpenCV 3.0.0-dev documentation</a> &raquo;</li>
          <li><a href="../../refman.html" >OpenCV API Reference</a> &raquo;</li>
          <li><a href="text.html" >text. Scene Text Detection and Recognition</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2014, opencv dev team.
      Last updated on Dec 30, 2014.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
      <a href="../../../_sources/modules/text/doc/erfilter.txt" rel="nofollow">Show this page source.</a>
    </div>
  </body>

<!-- Mirrored from docs.opencv.org/3.0-last-rst/modules/text/doc/erfilter.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2015 06:59:18 GMT -->
</html>