pyspark.SparkContext
====================

.. currentmodule:: pyspark

.. autoclass:: SparkContext

   
   .. automethod:: __init__

   
   .. rubric:: Methods

   .. autosummary::
   
      ~SparkContext.__init__
      ~SparkContext.accumulator
      ~SparkContext.addFile
      ~SparkContext.addPyFile
      ~SparkContext.binaryFiles
      ~SparkContext.binaryRecords
      ~SparkContext.broadcast
      ~SparkContext.cancelAllJobs
      ~SparkContext.cancelJobGroup
      ~SparkContext.dump_profiles
      ~SparkContext.emptyRDD
      ~SparkContext.getConf
      ~SparkContext.getLocalProperty
      ~SparkContext.getOrCreate
      ~SparkContext.hadoopFile
      ~SparkContext.hadoopRDD
      ~SparkContext.newAPIHadoopFile
      ~SparkContext.newAPIHadoopRDD
      ~SparkContext.parallelize
      ~SparkContext.pickleFile
      ~SparkContext.range
      ~SparkContext.runJob
      ~SparkContext.sequenceFile
      ~SparkContext.setCheckpointDir
      ~SparkContext.setJobDescription
      ~SparkContext.setJobGroup
      ~SparkContext.setLocalProperty
      ~SparkContext.setLogLevel
      ~SparkContext.setSystemProperty
      ~SparkContext.show_profiles
      ~SparkContext.sparkUser
      ~SparkContext.statusTracker
      ~SparkContext.stop
      ~SparkContext.textFile
      ~SparkContext.union
      ~SparkContext.wholeTextFiles
   
   

   
   
   .. rubric:: Attributes

   .. autosummary::
   
      ~SparkContext.PACKAGE_EXTENSIONS
      ~SparkContext.applicationId
      ~SparkContext.defaultMinPartitions
      ~SparkContext.defaultParallelism
      ~SparkContext.resources
      ~SparkContext.startTime
      ~SparkContext.uiWebUrl
      ~SparkContext.version
   
   