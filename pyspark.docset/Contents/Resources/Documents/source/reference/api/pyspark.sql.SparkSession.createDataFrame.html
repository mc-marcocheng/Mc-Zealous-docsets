
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title>pyspark.sql.SparkSession.createDataFrame — PySpark master documentation</title>
<link href="../../../_static/nature.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pyspark.css" rel="stylesheet" type="text/css"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/language_data.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../../../_static/pyspark.js"></script>
<link href="../../../search.html" rel="search" title="Search"/>
</head><body>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="document">
<div class="documentwrapper">
<div class="body" role="main">
<div class="section" id="pyspark-sql-sparksession-createdataframe">
<h1>pyspark.sql.SparkSession.createDataFrame<a class="headerlink" href="#pyspark-sql-sparksession-createdataframe" title="Permalink to this headline">¶</a></h1>
<dl class="py method">
<dt id="pyspark.sql.SparkSession.createDataFrame"><a name="//apple_ref/cpp/Method/pyspark.sql.SparkSession.createDataFrame"></a>
<code class="sig-prename descclassname">SparkSession.</code><code class="sig-name descname">createDataFrame</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">schema</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">samplingRatio</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verifySchema</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/pyspark/sql/session.html#SparkSession.createDataFrame"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.sql.SparkSession.createDataFrame" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a <a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a> from an <code class="xref py py-class docutils literal notranslate"><span class="pre">RDD</span></code>, a list or a <code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">schema</span></code> is a list of column names, the type of each column
will be inferred from <code class="docutils literal notranslate"><span class="pre">data</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">schema</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will try to infer the schema (column names and types)
from <code class="docutils literal notranslate"><span class="pre">data</span></code>, which should be an RDD of either <a class="reference internal" href="pyspark.sql.Row.html#pyspark.sql.Row" title="pyspark.sql.Row"><code class="xref py py-class docutils literal notranslate"><span class="pre">Row</span></code></a>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">namedtuple</span></code>, or <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">schema</span></code> is <a class="reference internal" href="pyspark.sql.types.DataType.html#pyspark.sql.types.DataType" title="pyspark.sql.types.DataType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.DataType</span></code></a> or a datatype string, it must match
the real data, or an exception will be thrown at runtime. If the given schema is not
<a class="reference internal" href="pyspark.sql.types.StructType.html#pyspark.sql.types.StructType" title="pyspark.sql.types.StructType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.StructType</span></code></a>, it will be wrapped into a
<a class="reference internal" href="pyspark.sql.types.StructType.html#pyspark.sql.types.StructType" title="pyspark.sql.types.StructType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.StructType</span></code></a> as its only field, and the field name will be “value”.
Each record will also be wrapped into a tuple, which can be converted to row later.</p>
<p>If schema inference is needed, <code class="docutils literal notranslate"><span class="pre">samplingRatio</span></code> is used to determined the ratio of
rows used for schema inference. The first row will be used if <code class="docutils literal notranslate"><span class="pre">samplingRatio</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – an RDD of any kind of SQL data representation (e.g. row, tuple, int, boolean,
etc.), <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>, or <code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>.</p></li>
<li><p><strong>schema</strong> – a <a class="reference internal" href="pyspark.sql.types.DataType.html#pyspark.sql.types.DataType" title="pyspark.sql.types.DataType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.DataType</span></code></a> or a datatype string or a list of
column names, default is <code class="docutils literal notranslate"><span class="pre">None</span></code>.  The data type string format equals to
<a class="reference internal" href="pyspark.sql.types.DataType.html#pyspark.sql.types.DataType.simpleString" title="pyspark.sql.types.DataType.simpleString"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.DataType.simpleString</span></code></a>, except that top level struct type can
omit the <code class="docutils literal notranslate"><span class="pre">struct&lt;&gt;</span></code> and atomic types use <code class="docutils literal notranslate"><span class="pre">typeName()</span></code> as their format, e.g. use
<code class="docutils literal notranslate"><span class="pre">byte</span></code> instead of <code class="docutils literal notranslate"><span class="pre">tinyint</span></code> for <a class="reference internal" href="pyspark.sql.types.ByteType.html#pyspark.sql.types.ByteType" title="pyspark.sql.types.ByteType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.ByteType</span></code></a>. We can also use
<code class="docutils literal notranslate"><span class="pre">int</span></code> as a short name for <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code>.</p></li>
<li><p><strong>samplingRatio</strong> – the sample ratio of rows used for inferring</p></li>
<li><p><strong>verifySchema</strong> – verify data types of every row against schema.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a></p>
</dd>
</dl>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 2.1: </span>Added verifySchema.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Usage with spark.sql.execution.arrow.pyspark.enabled=True is experimental.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When Arrow optimization is enabled, strings inside Pandas DataFrame in Python
2 are converted into bytes as they are bytes in Python 2 whereas regular strings are
left as strings. When using strings in Python 2, use unicode <cite>u””</cite> as Python standard
practice.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">'Alice'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(_1='Alice', _2=1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="p">[</span><span class="s1">'name'</span><span class="p">,</span> <span class="s1">'age'</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(name='Alice', age=1)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">'name'</span><span class="p">:</span> <span class="s1">'Alice'</span><span class="p">,</span> <span class="s1">'age'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(age=1, name='Alice')]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(_1='Alice', _2=1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">,</span> <span class="p">[</span><span class="s1">'name'</span><span class="p">,</span> <span class="s1">'age'</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(name='Alice', age=1)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Person</span> <span class="o">=</span> <span class="n">Row</span><span class="p">(</span><span class="s1">'name'</span><span class="p">,</span> <span class="s1">'age'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">person</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">Person</span><span class="p">(</span><span class="o">*</span><span class="n">r</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">person</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df2</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(name='Alice', age=1)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="gp">... </span>   <span class="n">StructField</span><span class="p">(</span><span class="s2">"name"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
<span class="gp">... </span>   <span class="n">StructField</span><span class="p">(</span><span class="s2">"age"</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df3</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df3</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(name='Alice', age=1)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">toPandas</span><span class="p">())</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  
<span class="go">[Row(name='Alice', age=1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  
<span class="go">[Row(0=1, 1=2)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">,</span> <span class="s2">"a: string, b: int"</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(a='Alice', b=1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rdd</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">,</span> <span class="s2">"int"</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[Row(value=1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">rdd</span><span class="p">,</span> <span class="s2">"boolean"</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span> 
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">Py4JJavaError</span>: <span class="n">...</span>
</pre></div>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.</span></p>
</div>
</dd></dl>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="footer" role="contentinfo">
        © Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.
    </div>
</body>
</html>