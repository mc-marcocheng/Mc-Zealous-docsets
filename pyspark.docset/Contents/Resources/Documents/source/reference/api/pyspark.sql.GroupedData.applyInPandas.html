
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title>pyspark.sql.GroupedData.applyInPandas — PySpark master documentation</title>
<link href="../../../_static/nature.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pyspark.css" rel="stylesheet" type="text/css"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/language_data.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../../../_static/pyspark.js"></script>
<link href="../../../search.html" rel="search" title="Search"/>
</head><body>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="document">
<div class="documentwrapper">
<div class="body" role="main">
<div class="section" id="pyspark-sql-groupeddata-applyinpandas">
<h1>pyspark.sql.GroupedData.applyInPandas<a class="headerlink" href="#pyspark-sql-groupeddata-applyinpandas" title="Permalink to this headline">¶</a></h1>
<dl class="py method">
<dt id="pyspark.sql.GroupedData.applyInPandas"><a name="//apple_ref/cpp/Method/pyspark.sql.GroupedData.applyInPandas"></a>
<code class="sig-prename descclassname">GroupedData.</code><code class="sig-name descname">applyInPandas</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">func</span></em>, <em class="sig-param"><span class="n">schema</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.sql.GroupedData.applyInPandas" title="Permalink to this definition">¶</a></dt>
<dd><p>Maps each group of the current <a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a> using a pandas udf and returns the result
as a <cite>DataFrame</cite>.</p>
<p>The function should take a <cite>pandas.DataFrame</cite> and return another
<cite>pandas.DataFrame</cite>. For each group, all columns are passed together as a <cite>pandas.DataFrame</cite>
to the user-function and the returned <cite>pandas.DataFrame</cite> are combined as a
<a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a>.</p>
<p>The <cite>schema</cite> should be a <code class="xref py py-class docutils literal notranslate"><span class="pre">StructType</span></code> describing the schema of the returned
<cite>pandas.DataFrame</cite>. The column labels of the returned <cite>pandas.DataFrame</cite> must either match
the field names in the defined schema if specified as strings, or match the
field data types by position if not strings, e.g. integer indices.
The length of the returned <cite>pandas.DataFrame</cite> can be arbitrary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> – a Python native function that takes a <cite>pandas.DataFrame</cite>, and outputs a
<cite>pandas.DataFrame</cite>.</p></li>
<li><p><strong>schema</strong> – the return type of the <cite>func</cite> in PySpark. The value can be either a
<a class="reference internal" href="pyspark.sql.types.DataType.html#pyspark.sql.types.DataType" title="pyspark.sql.types.DataType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.DataType</span></code></a> object or a DDL-formatted type string.</p></li>
</ul>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">pandas_udf</span><span class="p">,</span> <span class="n">ceil</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">"id"</span><span class="p">,</span> <span class="s2">"v"</span><span class="p">))</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">pdf</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">v</span> <span class="o">=</span> <span class="n">pdf</span><span class="o">.</span><span class="n">v</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">pdf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">v</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"id"</span><span class="p">)</span><span class="o">.</span><span class="n">applyInPandas</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">normalize</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="s2">"id long, v double"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  
<span class="go">+---+-------------------+</span>
<span class="go">| id|                  v|</span>
<span class="go">+---+-------------------+</span>
<span class="go">|  1|-0.7071067811865475|</span>
<span class="go">|  1| 0.7071067811865475|</span>
<span class="go">|  2|-0.8320502943378437|</span>
<span class="go">|  2|-0.2773500981126146|</span>
<span class="go">|  2| 1.1094003924504583|</span>
<span class="go">+---+-------------------+</span>
</pre></div>
</div>
<p>Alternatively, the user can pass a function that takes two arguments.
In this case, the grouping key(s) will be passed as the first argument and the data will
be passed as the second argument. The grouping key(s) will be passed as a tuple of numpy
data types, e.g., <cite>numpy.int32</cite> and <cite>numpy.float64</cite>. The data will still be passed in
as a <cite>pandas.DataFrame</cite> containing all columns from the original Spark DataFrame.
This is useful when the user does not want to hardcode grouping key(s) in the function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="p">(</span><span class="s2">"id"</span><span class="p">,</span> <span class="s2">"v"</span><span class="p">))</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">mean_func</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">pdf</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># key is a tuple of one numpy.int64, which is the value</span>
<span class="gp">... </span>    <span class="c1"># of 'id' for the current group</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">key</span> <span class="o">+</span> <span class="p">(</span><span class="n">pdf</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">mean</span><span class="p">(),)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">'id'</span><span class="p">)</span><span class="o">.</span><span class="n">applyInPandas</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">mean_func</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="s2">"id long, v double"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  
<span class="go">+---+---+</span>
<span class="go">| id|  v|</span>
<span class="go">+---+---+</span>
<span class="go">|  1|1.5|</span>
<span class="go">|  2|6.0|</span>
<span class="go">+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">sum_func</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">pdf</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># key is a tuple of two numpy.int64s, which is the values</span>
<span class="gp">... </span>    <span class="c1"># of 'id' and 'ceil(df.v / 2)' for the current group</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">key</span> <span class="o">+</span> <span class="p">(</span><span class="n">pdf</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">(),)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">ceil</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">v</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">applyInPandas</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">sum_func</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="s2">"id long, `ceil(v / 2)` long, v double"</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  
<span class="go">+---+-----------+----+</span>
<span class="go">| id|ceil(v / 2)|   v|</span>
<span class="go">+---+-----------+----+</span>
<span class="go">|  2|          5|10.0|</span>
<span class="go">|  1|          1| 3.0|</span>
<span class="go">|  2|          3| 5.0|</span>
<span class="go">|  2|          2| 3.0|</span>
<span class="go">+---+-----------+----+</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function requires a full shuffle. All the data of a group will be loaded
into memory, so the user should be aware of the potential OOM risk if data is skewed
and certain groups are too large to fit in memory.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If returning a new <cite>pandas.DataFrame</cite> constructed with a dictionary, it is
recommended to explicitly index the columns by name to ensure the positions are correct,
or alternatively use an <cite>OrderedDict</cite>.
For example, <cite>pd.DataFrame({‘id’: ids, ‘a’: data}, columns=[‘id’, ‘a’])</cite> or
<cite>pd.DataFrame(OrderedDict([(‘id’, ids), (‘a’, data)]))</cite>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Experimental</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="pyspark.sql.functions.pandas_udf.html#pyspark.sql.functions.pandas_udf" title="pyspark.sql.functions.pandas_udf"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pyspark.sql.functions.pandas_udf()</span></code></a></p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 3.0.</span></p>
</div>
</dd></dl>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="footer" role="contentinfo">
        © Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.
    </div>
</body>
</html>