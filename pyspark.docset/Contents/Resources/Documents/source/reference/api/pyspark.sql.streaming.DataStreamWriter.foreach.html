
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title>pyspark.sql.streaming.DataStreamWriter.foreach — PySpark master documentation</title>
<link href="../../../_static/nature.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pyspark.css" rel="stylesheet" type="text/css"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/language_data.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../../../_static/pyspark.js"></script>
<link href="../../../search.html" rel="search" title="Search"/>
</head><body>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="document">
<div class="documentwrapper">
<div class="body" role="main">
<div class="section" id="pyspark-sql-streaming-datastreamwriter-foreach">
<h1>pyspark.sql.streaming.DataStreamWriter.foreach<a class="headerlink" href="#pyspark-sql-streaming-datastreamwriter-foreach" title="Permalink to this headline">¶</a></h1>
<dl class="py method">
<dt id="pyspark.sql.streaming.DataStreamWriter.foreach"><a name="//apple_ref/cpp/Method/pyspark.sql.streaming.DataStreamWriter.foreach"></a>
<code class="sig-prename descclassname">DataStreamWriter.</code><code class="sig-name descname">foreach</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/pyspark/sql/streaming.html#DataStreamWriter.foreach"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.sql.streaming.DataStreamWriter.foreach" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the output of the streaming query to be processed using the provided writer <code class="docutils literal notranslate"><span class="pre">f</span></code>.
This is often used to write the output of a streaming query to arbitrary storage systems.
The processing logic can be specified in two ways.</p>
<ol class="arabic">
<li><dl class="simple">
<dt>A <strong>function</strong> that takes a row as input.</dt><dd><p>This is a simple way to express your processing logic. Note that this does
not allow you to deduplicate generated data when failures cause reprocessing of
some input data. That would require you to specify the processing logic in the next
way.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>An <strong>object</strong> with a <code class="docutils literal notranslate"><span class="pre">process</span></code> method and optional <code class="docutils literal notranslate"><span class="pre">open</span></code> and <code class="docutils literal notranslate"><span class="pre">close</span></code> methods.</dt><dd><p>The object can have the following methods.</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">open(partition_id,</span> <span class="pre">epoch_id)</span></code>: <em>Optional</em> method that initializes the processing</dt><dd><p>(for example, open a connection, start a transaction, etc). Additionally, you can
use the <cite>partition_id</cite> and <cite>epoch_id</cite> to deduplicate regenerated data
(discussed later).</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">process(row)</span></code>: <em>Non-optional</em> method that processes each <code class="xref py py-class docutils literal notranslate"><span class="pre">Row</span></code>.</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">close(error)</span></code>: <em>Optional</em> method that finalizes and cleans up (for example,</dt><dd><p>close connection, commit transaction, etc.) after all rows have been processed.</p>
</dd>
</dl>
</li>
</ul>
<p>The object will be used by Spark in the following way.</p>
<ul>
<li><dl class="simple">
<dt>A single copy of this object is responsible of all the data generated by a</dt><dd><p>single task in a query. In other words, one instance is responsible for
processing one partition of the data generated in a distributed manner.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>This object must be serializable because each task will get a fresh</dt><dd><p>serialized-deserialized copy of the provided object. Hence, it is strongly
recommended that any initialization for writing data (e.g. opening a
connection or starting a transaction) is done after the <cite>open(…)</cite>
method has been called, which signifies that the task is ready to generate data.</p>
</dd>
</dl>
</li>
<li><p>The lifecycle of the methods are as follows.</p>
<blockquote>
<div><p>For each partition with <code class="docutils literal notranslate"><span class="pre">partition_id</span></code>:</p>
<p>… For each batch/epoch of streaming data with <code class="docutils literal notranslate"><span class="pre">epoch_id</span></code>:</p>
<p>……. Method <code class="docutils literal notranslate"><span class="pre">open(partitionId,</span> <span class="pre">epochId)</span></code> is called.</p>
<dl class="simple">
<dt>……. If <code class="docutils literal notranslate"><span class="pre">open(...)</span></code> returns true, for each row in the partition and</dt><dd><p>batch/epoch, method <code class="docutils literal notranslate"><span class="pre">process(row)</span></code> is called.</p>
</dd>
<dt>……. Method <code class="docutils literal notranslate"><span class="pre">close(errorOrNull)</span></code> is called with error (if any) seen while</dt><dd><p>processing rows.</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
<p>Important points to note:</p>
<ul class="simple">
<li><dl class="simple">
<dt>The <cite>partitionId</cite> and <cite>epochId</cite> can be used to deduplicate generated data when</dt><dd><p>failures cause reprocessing of some input data. This depends on the execution
mode of the query. If the streaming query is being executed in the micro-batch
mode, then every partition represented by a unique tuple (partition_id, epoch_id)
is guaranteed to have the same data. Hence, (partition_id, epoch_id) can be used
to deduplicate and/or transactionally commit data and achieve exactly-once
guarantees. However, if the streaming query is being executed in the continuous
mode, then this guarantee does not hold and therefore should not be used for
deduplication.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>The <code class="docutils literal notranslate"><span class="pre">close()</span></code> method (if exists) will be called if <cite>open()</cite> method exists and</dt><dd><p>returns successfully (irrespective of the return value), except if the Python
crashes in the middle.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Evolving.</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print every row using a function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">print_row</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">writer</span> <span class="o">=</span> <span class="n">sdf</span><span class="o">.</span><span class="n">writeStream</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">print_row</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print every row using a object with process() method</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">RowPrinter</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">partition_id</span><span class="p">,</span> <span class="n">epoch_id</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">"Opened </span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">partition_id</span><span class="p">,</span> <span class="n">epoch_id</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="kc">True</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">"Closed with error: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">writer</span> <span class="o">=</span> <span class="n">sdf</span><span class="o">.</span><span class="n">writeStream</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="n">RowPrinter</span><span class="p">())</span>
</pre></div>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.4.</span></p>
</div>
</dd></dl>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="footer" role="contentinfo">
        © Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.
    </div>
</body>
</html>