
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title>pyspark.RDD.saveAsHadoopFile — PySpark master documentation</title>
<link href="../../../_static/nature.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/pyspark.css" rel="stylesheet" type="text/css"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/language_data.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../../../_static/pyspark.js"></script>
<link href="../../../search.html" rel="search" title="Search"/>
</head><body>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="document">
<div class="documentwrapper">
<div class="body" role="main">
<div class="section" id="pyspark-rdd-saveashadoopfile">
<h1>pyspark.RDD.saveAsHadoopFile<a class="headerlink" href="#pyspark-rdd-saveashadoopfile" title="Permalink to this headline">¶</a></h1>
<dl class="py method">
<dt id="pyspark.RDD.saveAsHadoopFile"><a name="//apple_ref/cpp/Method/pyspark.RDD.saveAsHadoopFile"></a>
<code class="sig-prename descclassname">RDD.</code><code class="sig-name descname">saveAsHadoopFile</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em>, <em class="sig-param"><span class="n">outputFormatClass</span></em>, <em class="sig-param"><span class="n">keyClass</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">valueClass</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keyConverter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">valueConverter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">conf</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">compressionCodecClass</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/pyspark/rdd.html#RDD.saveAsHadoopFile"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.RDD.saveAsHadoopFile" title="Permalink to this definition">¶</a></dt>
<dd><p>Output a Python RDD of key-value pairs (of form <code class="docutils literal notranslate"><span class="pre">RDD[(K,</span> <span class="pre">V)]</span></code>) to any Hadoop file
system, using the old Hadoop OutputFormat API (mapred package). Key and value types
will be inferred if not specified. Keys and values are converted for output using either
user specified converters or “org.apache.spark.api.python.JavaToWritableConverter”. The
<cite>conf</cite> is applied on top of the base Hadoop conf associated with the SparkContext
of this RDD to create a merged Hadoop MapReduce job configuration for saving the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – path to Hadoop file</p></li>
<li><p><strong>outputFormatClass</strong> – fully qualified classname of Hadoop OutputFormat
(e.g. “org.apache.hadoop.mapred.SequenceFileOutputFormat”)</p></li>
<li><p><strong>keyClass</strong> – fully qualified classname of key Writable class
(e.g. “org.apache.hadoop.io.IntWritable”, None by default)</p></li>
<li><p><strong>valueClass</strong> – fully qualified classname of value Writable class
(e.g. “org.apache.hadoop.io.Text”, None by default)</p></li>
<li><p><strong>keyConverter</strong> – (None by default)</p></li>
<li><p><strong>valueConverter</strong> – (None by default)</p></li>
<li><p><strong>conf</strong> – (None by default)</p></li>
<li><p><strong>compressionCodecClass</strong> – (None by default)</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
<div aria-label="related navigation" class="related" role="navigation">
<h3>Navigation</h3>
<ul>
<li class="nav-item nav-item-0"><a href="../../../index.html">PySpark master documentation</a> »</li>
</ul>
</div>
<div class="footer" role="contentinfo">
        © Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.
    </div>
</body>
</html>