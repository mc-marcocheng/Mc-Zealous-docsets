<!DOCTYPE html><html dir="ltr" lang="en"><head>
<meta content="157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com" name="google-signin-client-id"/>
<meta content="profile email" name="google-signin-scope"/>
<meta content="TensorFlow" property="og:site_name"/>
<meta content="website" property="og:type"/>
<meta content="#ff6f00" name="theme-color"/>
<meta charset="utf-8"/>
<meta content="IE=Edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link crossorigin="use-credentials" href="_pwa/tensorflow/manifest.json" rel="manifest"/>
<link crossorigin="" href="/www.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.googleapis.com" rel="preconnect"/>
<link href="../../../main.css" rel="stylesheet"/>

<noscript>

</noscript>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/favicon.png" rel="shortcut icon"/>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/apple-touch-icon-180x180.png" rel="apple-touch-icon"/><link href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor" rel="canonical"/><link href="https://www.tensorflow.org/s/opensearch.xml" rel="search" title="TensorFlow" type="application/opensearchdescription+xml"/>
<title>tf.RaggedTensor &nbsp;|&nbsp; TensorFlow Core v2.1.0</title>
<meta content="tf.RaggedTensor &nbsp;|&nbsp; TensorFlow Core v2.1.0" property="og:title"/>
<meta content="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor" property="og:url"/>
<meta content="en" property="og:locale"/>

</head>
<body class="" layout="docs" pending="" theme="tensorflow-theme" type="reference">
<devsite-progress id="app-progress" type="indeterminate"></devsite-progress>
<section class="devsite-wrapper"> <devsite-book-nav scrollbars="">

</devsite-book-nav>
<section id="gc-wrapper">
<main class="devsite-main-content" has-book-nav="" has-toc="" role="main">
<devsite-toc class="devsite-nav"></devsite-toc>
<devsite-content>
<article class="devsite-article">
<article class="devsite-article-inner"><style>
        /* Styles inlined from /site-assets/css/style.css */
/* override theme */
table img {
  max-width: 100%;
}

/* override var element to differentiate color from comment */
var, var code, var span, .prettyprint var span {
  color: #039be5;
}

/* .devsite-terminal virtualenv prompt */
.tfo-terminal-venv::before {
  content: "(venv) $ " !important;
}

/* .devsite-terminal root prompt */
.tfo-terminal-root::before {
  content: "# " !important;
}

/* .devsite-terminal Windows prompt */
.tfo-terminal-windows::before {
  content: "C:\\> " !important;
}

/* .devsite-terminal Windows prompt w/ virtualenv */
.tfo-terminal-windows-venv::before {
  content: "(venv) C:\\> " !important;
}

.tfo-diff-green-one-level + * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green + * > * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green-list + ul > li:first-of-type {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-red-one-level + * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red + * > * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red-list + ul > li:first-of-type {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

devsite-code .tfo-notebook-code-cell-output {
  max-height: 300px;
  overflow: auto;
  background: rgba(255, 247, 237, 1);  /* orange bg to distinguish from input code cells */
}

devsite-code .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(255, 247, 237, .7);  /* orange bg to distinguish from input code cells */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output {
  background: rgba(64, 78, 103, 1);  /* medium slate */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(64, 78, 103, .7);  /* medium slate */
}

/* override default table styles for notebook buttons */
.devsite-table-wrapper .tfo-notebook-buttons {
  display: inline-block;
  margin-left: 3px;
  width: auto;
}

.tfo-notebook-buttons td {
  padding-left: 0;
  padding-right: 20px;
}

.tfo-notebook-buttons a,
.tfo-notebook-buttons :link,
.tfo-notebook-buttons :visited {
  border-radius: 8px;
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 1px 3px 1px rgba(60, 64, 67, .15);
  color: #202124;
  padding: 12px 24px;
  transition: box-shadow 0.2s;
}

.tfo-notebook-buttons a:hover,
.tfo-notebook-buttons a:focus {
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 2px 6px 2px rgba(60, 64, 67, .15);
}

.tfo-notebook-buttons tr {
  background: 0;
  border: 0;
}

/* on rendered notebook page,
   remove link to webpage since we're already here */
.tfo-notebook-buttons:not(.tfo-api) td:first-child {
  display: none;
}

.tfo-notebook-buttons td > a {
  -webkit-box-align: center;
  -ms-flex-align: center;
  align-items: center;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
}

.tfo-notebook-buttons td > a > img {
  margin-right: 8px;
}

/* landing pages */

.tfo-landing-row-item-inset-white {
  background-color: #fff;
  padding: 32px;
}

.tfo-landing-row-item-inset-white ol,
.tfo-landing-row-item-inset-white ul {
  padding-left: 20px;
}

/* colab callout button */
.colab-callout-row devsite-code {
  border-radius: 8px 8px 0 0;
  box-shadow: none;
}

.colab-callout-footer {
  background: #e3e4e7;
  border-radius: 0 0 8px 8px;
  color: #37474f;
  padding: 20px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer {
  background: #3f4f66;
}


.colab-callout-footer > .button {
  margin-top: 4px;
  color: #ff5c00;
}

.colab-callout-footer > a > span {
  padding-top: 10px;
  vertical-align: middle;
  color: #37474f;
  padding-left: 10px;
  padding-right: 10px;
  font-size: 14px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer > a > span {
  color: #fff;
}

a.colab-button {
  background: rgba(255, 255, 255, .75);
  border: solid 1px rgba(0, 0, 0, .08);
  border-bottom-color: rgba(0, 0, 0, .15);
  border-radius: 4px;
  color: #aaa;
  display: inline-block;
  font-size: 11px !important;
  font-weight: 300;
  line-height: 16px;
  padding: 4px 8px;
  text-decoration: none;
  text-transform: uppercase;
}

a.colab-button:hover {
  background: white;
  border-color: rgba(0, 0, 0, .2);
  color: #666;
}

a.colab-button span {
  background: url(/images/colab_logo_button.svg) no-repeat 1px 1px / 20px;
  border-radius: 4px;
  display: inline-block;
  padding-left: 24px;
  text-decoration: none;
}

@media screen and (max-width: 600px) {
  .tfo-notebook-buttons td {
    display: block;
  }
}

/* guide and tutorials landing page cards and sections */

.tfo-landing-page-card {
  padding: 16px;
  box-shadow: 0 0 36px rgba(0,0,0,0.1);
  border-radius: 10px;
}

/* Page section headings */
.tfo-landing-page-heading h2, h2.tfo-landing-page-heading {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 30px;
  font-weight: 700;
  line-height: 40px;
}

/* Item title headings */
.tfo-landing-page-heading h3, h3.tfo-landing-page-heading,
.tfo-landing-page-card h3, h3.tfo-landing-page-card {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 20px;
  font-weight: 500;
  line-height: 26px;
}

/* List of tutorials notebooks for subsites */
.tfo-landing-page-resources-ul {
  padding-left: 15px
}

.tfo-landing-page-resources-ul > li {
  margin: 6px 0;
}

/* Temporary fix to hide product description in header on landing pages */
devsite-header .devsite-product-description {
  display: none;
}

        </style> <div class="devsite-banner devsite-banner-announcement">
<div class="devsite-banner-message">
<div class="devsite-banner-message-text">
            Missed TensorFlow Dev Summit? Check out the video playlist. <a class="button button-primary button-tfo-announcement" href="https://goo.gle/TFDS20AllSessions">Watch recordings</a>
</div>
</div>
</div>
<div class="devsite-article-meta">
<ul class="devsite-breadcrumb-list">
<li class="devsite-breadcrumb-item">
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="1" href="">
            TensorFlow
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="2" href="api">
            API
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="3" href="api_docs">
            TensorFlow Core v2.1.0
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="4" href="api_docs/python/tf">
            Python
      
  </a>
</li>
</ul>
<devsite-page-rating hover-rating-star="0" position="header" selected-rating="0">
</devsite-page-rating>
</div>
<a class="dashingAutolink" name="autolink-12"></a><a class="dashAnchor" name="//apple_ref/cpp/Function/tf.RaggedTensor"></a><h1 class="dash-function">tf.RaggedTensor</h1>
<devsite-toc class="devsite-nav" devsite-toc-embedded="">
</devsite-toc>
<div class="devsite-article-body clearfix">
<p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax>
</p>
<!-- DO NOT EDIT! Automatically generated file. -->
<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<meta content="tf.RaggedTensor" itemprop="name"/>
<meta content="Stable" itemprop="path"/>
<meta content="__abs__" itemprop="property"/>
<meta content="__add__" itemprop="property"/>
<meta content="__and__" itemprop="property"/>
<meta content="__bool__" itemprop="property"/>
<meta content="__div__" itemprop="property"/>
<meta content="__floordiv__" itemprop="property"/>
<meta content="__ge__" itemprop="property"/>
<meta content="__getitem__" itemprop="property"/>
<meta content="__gt__" itemprop="property"/>
<meta content="__init__" itemprop="property"/>
<meta content="__invert__" itemprop="property"/>
<meta content="__le__" itemprop="property"/>
<meta content="__lt__" itemprop="property"/>
<meta content="__mod__" itemprop="property"/>
<meta content="__mul__" itemprop="property"/>
<meta content="__neg__" itemprop="property"/>
<meta content="__nonzero__" itemprop="property"/>
<meta content="__or__" itemprop="property"/>
<meta content="__pow__" itemprop="property"/>
<meta content="__radd__" itemprop="property"/>
<meta content="__rand__" itemprop="property"/>
<meta content="__rdiv__" itemprop="property"/>
<meta content="__rfloordiv__" itemprop="property"/>
<meta content="__rmod__" itemprop="property"/>
<meta content="__rmul__" itemprop="property"/>
<meta content="__ror__" itemprop="property"/>
<meta content="__rpow__" itemprop="property"/>
<meta content="__rsub__" itemprop="property"/>
<meta content="__rtruediv__" itemprop="property"/>
<meta content="__rxor__" itemprop="property"/>
<meta content="__sub__" itemprop="property"/>
<meta content="__truediv__" itemprop="property"/>
<meta content="__xor__" itemprop="property"/>
<meta content="bounding_shape" itemprop="property"/>
<meta content="consumers" itemprop="property"/>
<meta content="from_nested_row_lengths" itemprop="property"/>
<meta content="from_nested_row_splits" itemprop="property"/>
<meta content="from_nested_value_rowids" itemprop="property"/>
<meta content="from_row_lengths" itemprop="property"/>
<meta content="from_row_limits" itemprop="property"/>
<meta content="from_row_splits" itemprop="property"/>
<meta content="from_row_starts" itemprop="property"/>
<meta content="from_sparse" itemprop="property"/>
<meta content="from_tensor" itemprop="property"/>
<meta content="from_uniform_row_length" itemprop="property"/>
<meta content="from_value_rowids" itemprop="property"/>
<meta content="merge_dims" itemprop="property"/>
<meta content="nested_row_lengths" itemprop="property"/>
<meta content="nested_value_rowids" itemprop="property"/>
<meta content="nrows" itemprop="property"/>
<meta content="row_lengths" itemprop="property"/>
<meta content="row_limits" itemprop="property"/>
<meta content="row_starts" itemprop="property"/>
<meta content="to_list" itemprop="property"/>
<meta content="to_sparse" itemprop="property"/>
<meta content="to_tensor" itemprop="property"/>
<meta content="value_rowids" itemprop="property"/>
<meta content="with_flat_values" itemprop="property"/>
<meta content="with_row_splits_dtype" itemprop="property"/>
<meta content="with_values" itemprop="property"/>
</div>
<p><devsite-nav-buttons name="version" param="reset">
<button default="" value="stable">See Stable</button>
<button value="nightly">See Nightly</button>
</devsite-nav-buttons></p>
<!-- Stable -->
<table align="left" class="tfo-notebook-buttons tfo-api">
<tbody><tr><td>
<a href="versions/r1.15/api_docs/python/tf/RaggedTensor" target="_blank">
<img src="https://www.tensorflow.org/images/tf_logo_32px.png"/>
  TensorFlow 1 version</a>
</td>
<td>
<a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L57-L2073" target="_blank">
<img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png"/>
    View source on GitHub
  </a>
</td></tr></tbody></table>
<p>Represents a ragged tensor.</p>
<section class="expandable">
<h4 class="showalways">View aliases</h4>
<p>
<b>Compat aliases for migration</b>
</p><p>See
<a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for
more details.</p>
<p><a href="api_docs/python/tf/RaggedTensor"><code dir="ltr" translate="no">tf.compat.v1.RaggedTensor</code></a></p>
</section>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">tf.RaggedTensor(
    values, row_splits, cached_row_lengths=None, cached_value_rowids=None,
    cached_nrows=None, internal=False, uniform_row_length=None
)
</code></pre>
<h3>Used in the notebooks</h3>
<table class="vertical-rules">
<thead>
<tr>
<th>Used in the guide</th>
<th>Used in the tutorials</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<ul>
<li><a href="https://www.tensorflow.org/guide/ragged_tensor">Ragged tensors</a></li>
</ul>
</td>
<td>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/load_data/unicode">Unicode strings</a></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> is a tensor with one or more <em>ragged dimensions</em>, which are
dimensions whose slices may have different lengths.  For example, the inner
(column) dimension of <code dir="ltr" translate="no">rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is ragged,
since the column slices (<code dir="ltr" translate="no">rt[0, :]</code>, ..., <code dir="ltr" translate="no">rt[4, :]</code>) have different lengths.
Dimensions whose slices all have the same length are called <em>uniform
dimensions</em>.  The outermost dimension of a <code dir="ltr" translate="no">RaggedTensor</code> is always uniform,
since it consists of a single slice (and so there is no possibility for
differing slice lengths).</p>
<p>The total number of dimensions in a <code dir="ltr" translate="no">RaggedTensor</code> is called its <em>rank</em>,
and the number of ragged dimensions in a <code dir="ltr" translate="no">RaggedTensor</code> is called its
<em>ragged-rank</em>.  A <code dir="ltr" translate="no">RaggedTensor</code>&#39;s ragged-rank is fixed at graph creation
time: it can&#39;t depend on the runtime values of <code dir="ltr" translate="no">Tensor</code>s, and can&#39;t vary
dynamically for different session runs.</p>
<h3 id="potentially_ragged_tensors_2">Potentially Ragged Tensors</h3>
<p>Many ops support both <code dir="ltr" translate="no">Tensor</code>s and <code dir="ltr" translate="no">RaggedTensor</code>s.  The term &#34;potentially
ragged tensor&#34; may be used to refer to a tensor that might be either a
<code dir="ltr" translate="no">Tensor</code> or a <code dir="ltr" translate="no">RaggedTensor</code>.  The ragged-rank of a <code dir="ltr" translate="no">Tensor</code> is zero.</p>
<h3 id="documenting_raggedtensor_shapes_2">Documenting RaggedTensor Shapes</h3>
<p>When documenting the shape of a RaggedTensor, ragged dimensions can be
indicated by enclosing them in parentheses.  For example, the shape of
a 3-D <code dir="ltr" translate="no">RaggedTensor</code> that stores the fixed-size word embedding for each
word in a sentence, for each sentence in a batch, could be written as
<code dir="ltr" translate="no">[num_sentences, (num_words), embedding_size]</code>.  The parentheses around
<code dir="ltr" translate="no">(num_words)</code> indicate that dimension is ragged, and that the length
of each element list in that dimension may vary for each item.</p>
<h3 id="component_tensors_2">Component Tensors</h3>
<p>Internally, a <code dir="ltr" translate="no">RaggedTensor</code> consists of a concatenated list of values that
are partitioned into variable-length rows.  In particular, each <code dir="ltr" translate="no">RaggedTensor</code>
consists of:</p>
<ul>
<li><p>A <code dir="ltr" translate="no">values</code> tensor, which concatenates the variable-length rows into a
flattened list.  For example, the <code dir="ltr" translate="no">values</code> tensor for
<code dir="ltr" translate="no">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is <code dir="ltr" translate="no">[3, 1, 4, 1, 5, 9, 2, 6]</code>.</p></li>
<li><p>A <code dir="ltr" translate="no">row_splits</code> vector, which indicates how those flattened values are
divided into rows.  In particular, the values for row <code dir="ltr" translate="no">rt[i]</code> are stored
in the slice <code dir="ltr" translate="no">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p></li>
</ul>
<h4 id="example_25">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_row_splits( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">      values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">      row_splits=[0, 4, 4, 7, 8, 8])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="alternative_row-partitioning_schemes_2">Alternative Row-Partitioning Schemes</h3>
<p>In addition to <code dir="ltr" translate="no">row_splits</code>, ragged tensors provide support for four other
row-partitioning schemes:</p>
<ul>
<li><p><code dir="ltr" translate="no">row_lengths</code>: a vector with shape <code dir="ltr" translate="no">[nrows]</code>, which specifies the length
of each row.</p></li>
<li><p><code dir="ltr" translate="no">value_rowids</code> and <code dir="ltr" translate="no">nrows</code>: <code dir="ltr" translate="no">value_rowids</code> is a vector with shape
<code dir="ltr" translate="no">[nvals]</code>, corresponding one-to-one with <code dir="ltr" translate="no">values</code>, which specifies
each value&#39;s row index.  In particular, the row <code dir="ltr" translate="no">rt[row]</code> consists of the
values <code dir="ltr" translate="no">rt.values[j]</code> where <code dir="ltr" translate="no">value_rowids[j]==row</code>.  <code dir="ltr" translate="no">nrows</code> is an
integer scalar that specifies the number of rows in the
<code dir="ltr" translate="no">RaggedTensor</code>. (<code dir="ltr" translate="no">nrows</code> is used to indicate trailing empty rows.)</p></li>
<li><p><code dir="ltr" translate="no">row_starts</code>: a vector with shape <code dir="ltr" translate="no">[nrows]</code>, which specifies the start
offset of each row.  Equivalent to <code dir="ltr" translate="no">row_splits[:-1]</code>.</p></li>
<li><p><code dir="ltr" translate="no">row_limits</code>: a vector with shape <code dir="ltr" translate="no">[nrows]</code>, which specifies the stop
offset of each row.  Equivalent to <code dir="ltr" translate="no">row_splits[1:]</code>.</p></li>
<li><p><code dir="ltr" translate="no">uniform_row_length</code>: A scalar tensor, specifying the length of every
row.  This row-partitioning scheme may only be used if all rows have
the same length.</p></li>
</ul>
<p>Example: The following ragged tensors are equivalent, and all represent the
nested list <code dir="ltr" translate="no">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code>.</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">values = [3, 1, 4, 1, 5, 9, 2, 6] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt1 = RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt2 = RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt3 = RaggedTensor.from_value_rowids( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt4 = RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt5 = RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8]) </code>
</pre>
<h3 id="multiple_ragged_dimensions_2">Multiple Ragged Dimensions</h3>
<p><code dir="ltr" translate="no">RaggedTensor</code>s with multiple ragged dimensions can be defined by using
a nested <code dir="ltr" translate="no">RaggedTensor</code> for the <code dir="ltr" translate="no">values</code> tensor.  Each nested <code dir="ltr" translate="no">RaggedTensor</code>
adds a single ragged dimension.</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">outer_rt = RaggedTensor.from_row_splits( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=inner_rt, row_splits=[0, 3, 3, 5]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(outer_rt.to_list()) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(outer_rt.ragged_rank) </code>
<code class="no-select nocode" dir="ltr" translate="no">2 </code>
</pre>
<p>The factory function <a href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#from_nested_row_splits"><code dir="ltr" translate="no">RaggedTensor.from_nested_row_splits</code></a> may be used to
construct a <code dir="ltr" translate="no">RaggedTensor</code> with multiple ragged dimensions directly, by
providing a list of <code dir="ltr" translate="no">row_splits</code> tensors:</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">RaggedTensor.from_nested_row_splits( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    flat_values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list() </code>
<code class="no-select nocode" dir="ltr" translate="no">[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]] </code>
</pre>
<h3 id="uniform_inner_dimensions_2">Uniform Inner Dimensions</h3>
<p><code dir="ltr" translate="no">RaggedTensor</code>s with uniform inner dimensions can be defined
by using a multidimensional <code dir="ltr" translate="no">Tensor</code> for <code dir="ltr" translate="no">values</code>.</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32), </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                                  row_splits=[0, 2, 5]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.to_list()) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[[1, 1, 1], [1, 1, 1]], </code>
<code class="no-select nocode" dir="ltr" translate="no"> [[1, 1, 1], [1, 1, 1], [1, 1, 1]]] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(2, None, 3) </code>
</pre>
<h3 id="uniform_outer_dimensions_2">Uniform Outer Dimensions</h3>
<p><code dir="ltr" translate="no">RaggedTensor</code>s with uniform outer dimensions can be defined by using
one or more <code dir="ltr" translate="no">RaggedTensor</code> with a <code dir="ltr" translate="no">uniform_row_length</code> row-partitioning
tensor.  For example, a <code dir="ltr" translate="no">RaggedTensor</code> with shape <code dir="ltr" translate="no">[2, 2, None]</code> can be
constructed with this method from a <code dir="ltr" translate="no">RaggedTensor</code> values with shape
<code dir="ltr" translate="no">[4, None]</code>:</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(values.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(4, None) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt6) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt; </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt6.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(2, 2, None) </code>
</pre>
<p>Note that <code dir="ltr" translate="no">rt6</code> only contains one ragged dimension (the innermost
dimension). In contrast, if <code dir="ltr" translate="no">from_row_splits</code> is used to construct a similar
<code dir="ltr" translate="no">RaggedTensor</code>, then that <code dir="ltr" translate="no">RaggedTensor</code> will have two ragged dimensions:</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt7.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(2, None, None) </code>
</pre>
<p>Uniform and ragged outer dimensions may be interleaved, meaning that a
tensor with any combination of ragged and uniform dimensions may be created.
For example, a RaggedTensor <code dir="ltr" translate="no">t4</code> with shape <code dir="ltr" translate="no">[3, None, 4, 8, None, 2]</code> could
be constructed as follows:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]
t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]
t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]
t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]
t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]
</code></pre>
<h4 id="args_57">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor of any dtype and shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">row_splits</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows+1]</code>.</li>
<li><b><code dir="ltr" translate="no">cached_row_lengths</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows]</code></li>
<li><b><code dir="ltr" translate="no">cached_value_rowids</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nvals]</code>.</li>
<li><b><code dir="ltr" translate="no">cached_nrows</code></b>: A 1-D integer scalar tensor.</li>
<li><b><code dir="ltr" translate="no">internal</code></b>: True if the constructor is being called by one of the factory
methods.  If false, an exception will be raised.</li>
<li><b><code dir="ltr" translate="no">uniform_row_length</code></b>: A scalar tensor.</li>
</ul>
<h4 id="attributes_2">Attributes:</h4>
<ul>
<li><b><code dir="ltr" translate="no">dtype</code></b>:   The <code dir="ltr" translate="no">DType</code> of values in this tensor.</li>
<li><p><b><code dir="ltr" translate="no">flat_values</code></b>:   The innermost <code dir="ltr" translate="no">values</code> tensor for this ragged tensor.</p>
<p>Concretely, if <code dir="ltr" translate="no">rt.values</code> is a <code dir="ltr" translate="no">Tensor</code>, then <code dir="ltr" translate="no">rt.flat_values</code> is
<code dir="ltr" translate="no">rt.values</code>; otherwise, <code dir="ltr" translate="no">rt.flat_values</code> is <code dir="ltr" translate="no">rt.values.flat_values</code>.</p>
<p>Conceptually, <code dir="ltr" translate="no">flat_values</code> is the tensor formed by flattening the
outermost dimension and all of the ragged dimensions into a single
dimension.</p>
<p><code dir="ltr" translate="no">rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]</code>
(where <code dir="ltr" translate="no">nvals</code> is the number of items in the flattened dimensions).</p>
<h4 id="example_26">Example:</h4></li>
</ul>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]) </code>
  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.flat_values) </code>
  <code class="no-select nocode" dir="ltr" translate="no">  tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<ul>
<li><p><b><code dir="ltr" translate="no">nested_row_splits</code></b>:   A tuple containing the row_splits for all ragged dimensions.</p>
<p><code dir="ltr" translate="no">rt.nested_row_splits</code> is a tuple containing the <code dir="ltr" translate="no">row_splits</code> tensors for
all ragged dimensions in <code dir="ltr" translate="no">rt</code>, ordered from outermost to innermost.  In
particular, <code dir="ltr" translate="no">rt.nested_row_splits = (rt.row_splits,) + value_splits</code> where:</p>
<ul>
<li><code dir="ltr" translate="no">value_splits = ()</code> if <code dir="ltr" translate="no">rt.values</code> is a <code dir="ltr" translate="no">Tensor</code>.</li>
<li><code dir="ltr" translate="no">value_splits = rt.values.nested_row_splits</code> otherwise.</li>
</ul>
<h4 id="example_27">Example:</h4></li>
</ul>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant( </code>
  <code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]]) </code>
  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">for i, splits in enumerate(rt.nested_row_splits): </code>
  <code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">  print(&#39;Splits for dimension %d: %s&#39; % (i+1, splits.numpy())) </code>
  <code class="no-select nocode" dir="ltr" translate="no">  Splits for dimension 1: [0 3] </code>
  <code class="no-select nocode" dir="ltr" translate="no">  Splits for dimension 2: [0 3 3 5] </code>
  <code class="no-select nocode" dir="ltr" translate="no">  Splits for dimension 3: [0 4 4 7 8 8] </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<ul>
<li><p><b><code dir="ltr" translate="no">ragged_rank</code></b>:   The number of ragged dimensions in this ragged tensor.</p></li>
<li><p><b><code dir="ltr" translate="no">row_splits</code></b>:   The row-split indices for this ragged tensor&#39;s <code dir="ltr" translate="no">values</code>.</p>
<p><code dir="ltr" translate="no">rt.row_splits</code> specifies where the values for each row begin and end in
<code dir="ltr" translate="no">rt.values</code>.  In particular, the values for row <code dir="ltr" translate="no">rt[i]</code> are stored in
the slice <code dir="ltr" translate="no">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p>
<h4 id="example_28">Example:</h4></li>
</ul>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.row_splits)  # indices of row splits in rt.values </code>
  <code class="no-select nocode" dir="ltr" translate="no">  tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64) </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<ul>
<li><b><code dir="ltr" translate="no">shape</code></b>:   The statically known shape of this ragged tensor.</li>
</ul>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.ragged.constant([[0], [1, 2]]).shape </code>
  <code class="no-select nocode" dir="ltr" translate="no">  TensorShape([2, None]) </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape </code>
  <code class="no-select nocode" dir="ltr" translate="no">  TensorShape([2, None, 2]) </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<ul>
<li><p><b><code dir="ltr" translate="no">values</code></b>:   The concatenated rows for this ragged tensor.</p>
<p><code dir="ltr" translate="no">rt.values</code> is a potentially ragged tensor formed by flattening the two
outermost dimensions of <code dir="ltr" translate="no">rt</code> into a single dimension.</p>
<p><code dir="ltr" translate="no">rt.values.shape = [nvals] + rt.shape[2:]</code> (where <code dir="ltr" translate="no">nvals</code> is the
number of items in the outer two dimensions of <code dir="ltr" translate="no">rt</code>).</p>
<p><code dir="ltr" translate="no">rt.ragged_rank = self.ragged_rank - 1</code></p>
<h4 id="example_29">Example:</h4></li>
</ul>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no">  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
  <code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.values) </code>
  <code class="no-select nocode" dir="ltr" translate="no">  tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) </code>
  <code class="no-select nocode" dir="ltr" translate="no">   </code>
</pre>
<h4 id="raises_15">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If a row partitioning tensor has an inappropriate dtype.</li>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If exactly one row partitioning argument was not specified.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If a row partitioning tensor has an inappropriate shape.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If multiple partitioning arguments are specified.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If nrows is specified but value_rowids is not None.</li>
</ul>
<h2 id="methods_2">Methods</h2>
<h3 id="__abs__"><code dir="ltr" translate="no">__abs__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L248-L281" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__abs__(
    x, name=None
)
</code></pre>
<p>Computes the absolute value of a tensor.</p>
<p>Given a tensor of integer or floating-point values, this operation returns a
tensor of the same type, where each element contains the absolute value of the
corresponding element in the input.</p>
<p>Given a tensor <code dir="ltr" translate="no">x</code> of complex numbers, this operation returns a tensor of type
<code dir="ltr" translate="no">float32</code> or <code dir="ltr" translate="no">float64</code> that is the absolute value of each element in <code dir="ltr" translate="no">x</code>. All
elements in <code dir="ltr" translate="no">x</code> must be complex numbers of the form \(a + bj\). The
absolute value is computed as \( \sqrt{a^2 + b^2}\).  For example:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)  # [5.25594902, 6.60492229]
</code></pre>
<h4 id="args_58">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> or <code dir="ltr" translate="no">SparseTensor</code> of type <code dir="ltr" translate="no">float16</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>,
<code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code> or <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_58">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> or <code dir="ltr" translate="no">SparseTensor</code> the same size, type, and sparsity as <code dir="ltr" translate="no">x</code> with
  absolute values.
Note, for <code dir="ltr" translate="no">complex64</code> or <code dir="ltr" translate="no">complex128</code> input, the returned <code dir="ltr" translate="no">Tensor</code> will be
  of type <code dir="ltr" translate="no">float32</code> or <code dir="ltr" translate="no">float64</code>, respectively.</p>
<p>If <code dir="ltr" translate="no">x</code> is a <code dir="ltr" translate="no">SparseTensor</code>, returns
<code dir="ltr" translate="no">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code></p>
<h3 id="__add__"><code dir="ltr" translate="no">__add__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__add__(
    x, y, name=None
)
</code></pre>
<p>Returns x + y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/add"><code dir="ltr" translate="no">math.add</code></a> supports broadcasting. <code dir="ltr" translate="no">AddN</code> does not. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_59">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>, <code dir="ltr" translate="no">string</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_59">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__and__"><code dir="ltr" translate="no">__and__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__and__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of x AND y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/logical_and"><code dir="ltr" translate="no">math.logical_and</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_60">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_60">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__bool__"><code dir="ltr" translate="no">__bool__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_operators.py#L72-L74" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__bool__(
    _
)
</code></pre>
<p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p>
<h3 id="__div__"><code dir="ltr" translate="no">__div__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1072-L1095" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__div__(
    x, y, name=None
)
</code></pre>
<p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p>
<aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.</span></aside>
<p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
3 division operator semantics.</p>
<p>This function divides <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code>, forcing Python 2 semantics. That is, if <code dir="ltr" translate="no">x</code>
and <code dir="ltr" translate="no">y</code> are both integers then the result will be an integer. This is in
contrast to Python 3, where division with <code dir="ltr" translate="no">/</code> is always a float while division
with <code dir="ltr" translate="no">//</code> is always an integer.</p>
<h4 id="args_61">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_61">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> returns the quotient of x and y.</p>
<h3 id="__floordiv__"><code dir="ltr" translate="no">__floordiv__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1150-L1178" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__floordiv__(
    x, y, name=None
)
</code></pre>
<p>Divides <code dir="ltr" translate="no">x / y</code> elementwise, rounding toward the most negative integer.</p>
<p>The same as <a href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#__div__"><code dir="ltr" translate="no">tf.compat.v1.div(x,y)</code></a> for integers, but uses
<code dir="ltr" translate="no">tf.floor(tf.compat.v1.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code dir="ltr" translate="no">x // y</code> floor division in Python 3 and in Python 2.7 with
<code dir="ltr" translate="no">from __future__ import division</code>.</p>
<p><code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> must have the same type, and the result will have the same type
as well.</p>
<h4 id="args_62">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_62">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> rounded down.</p>
<h4 id="raises_16">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If the inputs are complex.</li>
</ul>
<h3 id="__ge__"><code dir="ltr" translate="no">__ge__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__ge__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of (x &gt;= y) element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/greater_equal"><code dir="ltr" translate="no">math.greater_equal</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="example_30">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([5, 4, 6, 7])
y = tf.constant([5, 2, 5, 10])
tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]

x = tf.constant([5, 4, 6, 7])
y = tf.constant([5])
tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]
</code></pre>
<h4 id="args_63">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">uint32</code>, <code dir="ltr" translate="no">uint64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_63">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__getitem__"><code dir="ltr" translate="no">__getitem__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_getitem.py#L32-L103" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__getitem__(
    key
)
</code></pre>
<p>Returns the specified piece of this RaggedTensor.</p>
<p>Supports multidimensional indexing and slicing, with one restriction:
indexing into a ragged inner dimension is not allowed.  This case is
problematic because the indicated value may exist in some rows but not
others.  In such cases, it&#39;s not obvious whether we should (1) report an
IndexError; (2) use a default value; or (3) skip that value and return a
tensor with fewer rows than we started with.  Following the guiding
principles of Python (&#34;In the face of ambiguity, refuse the temptation to
guess&#34;), we simply disallow this operation.</p>
<p>Any dimensions added by <code dir="ltr" translate="no">array_ops.newaxis</code> will be ragged if the following
dimension is ragged.</p>
<h4 id="args_64">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">self</code></b>: The RaggedTensor to slice.</li>
<li><p><b><code dir="ltr" translate="no">key</code></b>: Indicates which piece of the RaggedTensor to return, using standard
Python semantics (e.g., negative values index from the end).  <code dir="ltr" translate="no">key</code>
may have any of the following types:</p>
<ul>
<li><code dir="ltr" translate="no">int</code> constant</li>
<li>Scalar integer <code dir="ltr" translate="no">Tensor</code></li>
<li><p><code dir="ltr" translate="no">slice</code> containing integer constants and/or scalar integer
<code dir="ltr" translate="no">Tensor</code>s</p></li>
<li><p><code dir="ltr" translate="no">Ellipsis</code></p></li>
<li><p><code dir="ltr" translate="no">tf.newaxis</code></p></li>
<li><p><code dir="ltr" translate="no">tuple</code> containing any of the above (for multidimentional indexing)</p></li>
</ul></li>
</ul>
<h4 id="returns_64">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> or <code dir="ltr" translate="no">RaggedTensor</code> object.  Values that include at least one
ragged dimension are returned as <code dir="ltr" translate="no">RaggedTensor</code>.  Values that include no
ragged dimensions are returned as <code dir="ltr" translate="no">Tensor</code>.  See above for examples of
expressions that return <code dir="ltr" translate="no">Tensor</code>s vs <code dir="ltr" translate="no">RaggedTensor</code>s.</p>
<h4 id="raises_17">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">key</code> is out of bounds.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">key</code> is not supported.</li>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If the indices in <code dir="ltr" translate="no">key</code> have an unsupported type.</li>
</ul>
<h4 id="examples_5">Examples:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no"># A 2-D ragged tensor with 1 ragged dimension. </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;d&#39;, &#39;e&#39;], [&#39;f&#39;], [&#39;g&#39;]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[0].numpy()                 # First row (1-D `Tensor`) </code>
<code class="no-select nocode" dir="ltr" translate="no">array([b&#39;a&#39;, b&#39;b&#39;, b&#39;c&#39;], dtype=object) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[:3].to_list()              # First three rows (2-D RaggedTensor) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[b&#39;a&#39;, b&#39;b&#39;, b&#39;c&#39;], [b&#39;d&#39;, b&#39;e&#39;], [b&#39;f&#39;]] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[3, 0].numpy()              # 1st element of 4th row (scalar) </code>
<code class="no-select nocode" dir="ltr" translate="no">b&#39;g&#39; </code>
</pre>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no"># A 3-D ragged tensor with 2 ragged dimensions. </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[[1, 2, 3], [4]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                         [[5], [], [6]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                         [[7]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                         [[8, 9], [10]]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[1].to_list()               # Second row (2-D RaggedTensor) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[5], [], [6]] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[3, 0].numpy()              # First element of fourth row (1-D Tensor) </code>
<code class="no-select nocode" dir="ltr" translate="no">array([8, 9], dtype=int32) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[[4]], [[], [6]], [], [[10]]] </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor) </code>
<code class="no-select nocode" dir="ltr" translate="no">[[[4]], [[6]], [[7]], [[10]]] </code>
</pre>
<h3 id="__gt__"><code dir="ltr" translate="no">__gt__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__gt__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of (x &gt; y) element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/greater"><code dir="ltr" translate="no">math.greater</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="example_31">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([5, 4, 6])
y = tf.constant([5, 2, 5])
tf.math.greater(x, y) ==&gt; [False, True, True]

x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.greater(x, y) ==&gt; [False, False, True]
</code></pre>
<h4 id="args_65">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">uint32</code>, <code dir="ltr" translate="no">uint64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_65">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__invert__"><code dir="ltr" translate="no">__invert__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__invert__(
    x, name=None
)
</code></pre>
<p>Returns the truth value of NOT x element-wise.</p>
<h4 id="args_66">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_66">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__le__"><code dir="ltr" translate="no">__le__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__le__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of (x &lt;= y) element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/less_equal"><code dir="ltr" translate="no">math.less_equal</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="example_32">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less_equal(x, y) ==&gt; [True, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 6])
tf.math.less_equal(x, y) ==&gt; [True, True, True]
</code></pre>
<h4 id="args_67">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">uint32</code>, <code dir="ltr" translate="no">uint64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_67">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__lt__"><code dir="ltr" translate="no">__lt__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__lt__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of (x &lt; y) element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/less"><code dir="ltr" translate="no">math.less</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="example_33">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less(x, y) ==&gt; [False, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 7])
tf.math.less(x, y) ==&gt; [False, True, True]
</code></pre>
<h4 id="args_68">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">uint32</code>, <code dir="ltr" translate="no">uint64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_68">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__mod__"><code dir="ltr" translate="no">__mod__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__mod__(
    x, y, name=None
)
</code></pre>
<p>Returns element-wise remainder of division. When <code dir="ltr" translate="no">x &lt; 0</code> xor <code dir="ltr" translate="no">y &lt; 0</code> is</p>
<p>true, this follows Python semantics in that the result here is consistent
with a flooring divide. E.g. <code dir="ltr" translate="no">floor(x / y) * y + mod(x, y) = x</code>.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/floormod"><code dir="ltr" translate="no">math.floormod</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_69">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_69">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__mul__"><code dir="ltr" translate="no">__mul__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L331-L334" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__mul__(
    x, y, name=None
)
</code></pre>
<p>Returns x * y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/multiply"><code dir="ltr" translate="no">tf.multiply</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_70">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_70">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__neg__"><code dir="ltr" translate="no">__neg__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__neg__(
    x, name=None
)
</code></pre>
<p>Computes numerical negative value element-wise.</p>
<p>I.e., \(y = -x\).</p>
<h4 id="args_71">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_71">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<p>If <code dir="ltr" translate="no">x</code> is a <code dir="ltr" translate="no">SparseTensor</code>, returns
<code dir="ltr" translate="no">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code></p>
<h3 id="__nonzero__"><code dir="ltr" translate="no">__nonzero__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_operators.py#L72-L74" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__nonzero__(
    _
)
</code></pre>
<p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p>
<h3 id="__or__"><code dir="ltr" translate="no">__or__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__or__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of x OR y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/logical_or"><code dir="ltr" translate="no">math.logical_or</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_72">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_72">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__pow__"><code dir="ltr" translate="no">__pow__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L437-L462" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__pow__(
    x, y, name=None
)
</code></pre>
<p>Computes the power of one value to another.</p>
<p>Given a tensor <code dir="ltr" translate="no">x</code> and a tensor <code dir="ltr" translate="no">y</code>, this operation computes \(x^y\) for
corresponding elements in <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code>. For example:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</code></pre>
<h4 id="args_73">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">float16</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>,
<code dir="ltr" translate="no">complex64</code>, or <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">float16</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>,
<code dir="ltr" translate="no">complex64</code>, or <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_73">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>.</p>
<h3 id="__radd__"><code dir="ltr" translate="no">__radd__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__radd__(
    x, y, name=None
)
</code></pre>
<p>Returns x + y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/add"><code dir="ltr" translate="no">math.add</code></a> supports broadcasting. <code dir="ltr" translate="no">AddN</code> does not. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_74">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>, <code dir="ltr" translate="no">string</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_74">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__rand__"><code dir="ltr" translate="no">__rand__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rand__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of x AND y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/logical_and"><code dir="ltr" translate="no">math.logical_and</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_75">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_75">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__rdiv__"><code dir="ltr" translate="no">__rdiv__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1072-L1095" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rdiv__(
    x, y, name=None
)
</code></pre>
<p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p>
<aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.</span></aside>
<p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
3 division operator semantics.</p>
<p>This function divides <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code>, forcing Python 2 semantics. That is, if <code dir="ltr" translate="no">x</code>
and <code dir="ltr" translate="no">y</code> are both integers then the result will be an integer. This is in
contrast to Python 3, where division with <code dir="ltr" translate="no">/</code> is always a float while division
with <code dir="ltr" translate="no">//</code> is always an integer.</p>
<h4 id="args_76">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_76">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> returns the quotient of x and y.</p>
<h3 id="__rfloordiv__"><code dir="ltr" translate="no">__rfloordiv__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1150-L1178" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rfloordiv__(
    x, y, name=None
)
</code></pre>
<p>Divides <code dir="ltr" translate="no">x / y</code> elementwise, rounding toward the most negative integer.</p>
<p>The same as <a href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#__div__"><code dir="ltr" translate="no">tf.compat.v1.div(x,y)</code></a> for integers, but uses
<code dir="ltr" translate="no">tf.floor(tf.compat.v1.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code dir="ltr" translate="no">x // y</code> floor division in Python 3 and in Python 2.7 with
<code dir="ltr" translate="no">from __future__ import division</code>.</p>
<p><code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> must have the same type, and the result will have the same type
as well.</p>
<h4 id="args_77">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of real numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_77">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> rounded down.</p>
<h4 id="raises_18">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If the inputs are complex.</li>
</ul>
<h3 id="__rmod__"><code dir="ltr" translate="no">__rmod__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rmod__(
    x, y, name=None
)
</code></pre>
<p>Returns element-wise remainder of division. When <code dir="ltr" translate="no">x &lt; 0</code> xor <code dir="ltr" translate="no">y &lt; 0</code> is</p>
<p>true, this follows Python semantics in that the result here is consistent
with a flooring divide. E.g. <code dir="ltr" translate="no">floor(x / y) * y + mod(x, y) = x</code>.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/floormod"><code dir="ltr" translate="no">math.floormod</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_78">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_78">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__rmul__"><code dir="ltr" translate="no">__rmul__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L331-L334" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rmul__(
    x, y, name=None
)
</code></pre>
<p>Returns x * y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/multiply"><code dir="ltr" translate="no">tf.multiply</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_79">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_79">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__ror__"><code dir="ltr" translate="no">__ror__</code></h3>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__ror__(
    x, y, name=None
)
</code></pre>
<p>Returns the truth value of x OR y element-wise.</p>
<p><em>NOTE</em>: <a href="https://www.tensorflow.org/api_docs/python/tf/math/logical_or"><code dir="ltr" translate="no">math.logical_or</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_80">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_80">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">bool</code>.</p>
<h3 id="__rpow__"><code dir="ltr" translate="no">__rpow__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L437-L462" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rpow__(
    x, y, name=None
)
</code></pre>
<p>Computes the power of one value to another.</p>
<p>Given a tensor <code dir="ltr" translate="no">x</code> and a tensor <code dir="ltr" translate="no">y</code>, this operation computes \(x^y\) for
corresponding elements in <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code>. For example:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</code></pre>
<h4 id="args_81">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">float16</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>,
<code dir="ltr" translate="no">complex64</code>, or <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type <code dir="ltr" translate="no">float16</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>,
<code dir="ltr" translate="no">complex64</code>, or <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_81">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>.</p>
<h3 id="__rsub__"><code dir="ltr" translate="no">__rsub__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L352-L355" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rsub__(
    x, y, name=None
)
</code></pre>
<p>Returns x - y element-wise.</p>
<p><em>NOTE</em>: <code dir="ltr" translate="no">Subtract</code> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_82">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_82">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__rtruediv__"><code dir="ltr" translate="no">__rtruediv__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1039-L1069" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rtruediv__(
    x, y, name=None
)
</code></pre>
<p>Divides x / y elementwise (using Python 3 division operator semantics).</p>
<p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python
division operator semantics.</p>
<p>This function forces Python 3 division operator semantics where all integer
arguments are cast to floating types first.   This op is generated by normal
<code dir="ltr" translate="no">x / y</code> division in Python 3 and in Python 2.7 with
<code dir="ltr" translate="no">from __future__ import division</code>.  If you want integer division that rounds
down, use <code dir="ltr" translate="no">x // y</code> or <code dir="ltr" translate="no">tf.math.floordiv</code>.</p>
<p><code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code dir="ltr" translate="no">float32</code> for <code dir="ltr" translate="no">int8</code> and <code dir="ltr" translate="no">int16</code> and <code dir="ltr" translate="no">float64</code> for <code dir="ltr" translate="no">int32</code>
and <code dir="ltr" translate="no">int64</code> (matching the behavior of Numpy).</p>
<h4 id="args_83">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_83">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> evaluated in floating point.</p>
<h4 id="raises_19">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> have different dtypes.</li>
</ul>
<h3 id="__rxor__"><code dir="ltr" translate="no">__rxor__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1229-L1260" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__rxor__(
    x, y, name=&#39;LogicalXor&#39;
)
</code></pre>
<p>Logical XOR function.</p>
<p>x ^ y = (x | y) &amp; ~(x &amp; y)</p>
<p>Inputs are tensor and if the tensors contains more than one element, an
element-wise logical XOR is computed.</p>
<h4 id="usage_5">Usage:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name=&#34;LogicalXor&#34;)
#  here z = [False  True  True False]
</code></pre>
<h4 id="args_84">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> type bool.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type bool.</li>
</ul>
<h4 id="returns_84">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type bool with the same size as that of x or y.</p>
<h3 id="__sub__"><code dir="ltr" translate="no">__sub__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L352-L355" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__sub__(
    x, y, name=None
)
</code></pre>
<p>Returns x - y element-wise.</p>
<p><em>NOTE</em>: <code dir="ltr" translate="no">Subtract</code> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>
<h4 id="args_85">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must be one of the following types: <code dir="ltr" translate="no">bfloat16</code>, <code dir="ltr" translate="no">half</code>, <code dir="ltr" translate="no">float32</code>, <code dir="ltr" translate="no">float64</code>, <code dir="ltr" translate="no">uint8</code>, <code dir="ltr" translate="no">int8</code>, <code dir="ltr" translate="no">uint16</code>, <code dir="ltr" translate="no">int16</code>, <code dir="ltr" translate="no">int32</code>, <code dir="ltr" translate="no">int64</code>, <code dir="ltr" translate="no">complex64</code>, <code dir="ltr" translate="no">complex128</code>.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code>. Must have the same type as <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_85">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code>. Has the same type as <code dir="ltr" translate="no">x</code>.</p>
<h3 id="__truediv__"><code dir="ltr" translate="no">__truediv__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1039-L1069" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__truediv__(
    x, y, name=None
)
</code></pre>
<p>Divides x / y elementwise (using Python 3 division operator semantics).</p>
<p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python
division operator semantics.</p>
<p>This function forces Python 3 division operator semantics where all integer
arguments are cast to floating types first.   This op is generated by normal
<code dir="ltr" translate="no">x / y</code> division in Python 3 and in Python 2.7 with
<code dir="ltr" translate="no">from __future__ import division</code>.  If you want integer division that rounds
down, use <code dir="ltr" translate="no">x // y</code> or <code dir="ltr" translate="no">tf.math.floordiv</code>.</p>
<p><code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code dir="ltr" translate="no">float32</code> for <code dir="ltr" translate="no">int8</code> and <code dir="ltr" translate="no">int16</code> and <code dir="ltr" translate="no">float64</code> for <code dir="ltr" translate="no">int32</code>
and <code dir="ltr" translate="no">int64</code> (matching the behavior of Numpy).</p>
<h4 id="args_86">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: <code dir="ltr" translate="no">Tensor</code> numerator of numeric type.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: <code dir="ltr" translate="no">Tensor</code> denominator of numeric type.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns_86">Returns:</h4>
<p><code dir="ltr" translate="no">x / y</code> evaluated in floating point.</p>
<h4 id="raises_20">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> have different dtypes.</li>
</ul>
<h3 id="__xor__"><code dir="ltr" translate="no">__xor__</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L1229-L1260" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">__xor__(
    x, y, name=&#39;LogicalXor&#39;
)
</code></pre>
<p>Logical XOR function.</p>
<p>x ^ y = (x | y) &amp; ~(x &amp; y)</p>
<p>Inputs are tensor and if the tensors contains more than one element, an
element-wise logical XOR is computed.</p>
<h4 id="usage_6">Usage:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name=&#34;LogicalXor&#34;)
#  here z = [False  True  True False]
</code></pre>
<h4 id="args_87">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: A <code dir="ltr" translate="no">Tensor</code> type bool.</li>
<li><b><code dir="ltr" translate="no">y</code></b>: A <code dir="ltr" translate="no">Tensor</code> of type bool.</li>
</ul>
<h4 id="returns_87">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> of type bool with the same size as that of x or y.</p>
<h3 id="bounding_shape"><code dir="ltr" translate="no">bounding_shape</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1344-L1394" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">bounding_shape(
    axis=None, name=None, out_type=None
)
</code></pre>
<p>Returns the tight bounding box shape for this <code dir="ltr" translate="no">RaggedTensor</code>.</p>
<h4 id="args_88">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">axis</code></b>: An integer scalar or vector indicating which axes to return the
bounding box for.  If not specified, then the full bounding box is
returned.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
<li><b><code dir="ltr" translate="no">out_type</code></b>: <code dir="ltr" translate="no">dtype</code> for the returned tensor.  Defaults to
<code dir="ltr" translate="no">self.row_splits.dtype</code>.</li>
</ul>
<h4 id="returns_88">Returns:</h4>
<p>An integer <code dir="ltr" translate="no">Tensor</code> (<code dir="ltr" translate="no">dtype=self.row_splits.dtype</code>).  If <code dir="ltr" translate="no">axis</code> is not
specified, then <code dir="ltr" translate="no">output</code> is a vector with
<code dir="ltr" translate="no">output.shape=[self.shape.ndims]</code>.  If <code dir="ltr" translate="no">axis</code> is a scalar, then the
<code dir="ltr" translate="no">output</code> is a scalar.  If <code dir="ltr" translate="no">axis</code> is a vector, then <code dir="ltr" translate="no">output</code> is a vector,
where <code dir="ltr" translate="no">output[i]</code> is the bounding size for dimension <code dir="ltr" translate="no">axis[i]</code>.</p>
<h4 id="example_34">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt.bounding_shape().numpy() </code>
<code class="no-select nocode" dir="ltr" translate="no">array([5, 4]) </code>
</pre>
<h3 id="consumers"><code dir="ltr" translate="no">consumers</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L2072-L2073" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">consumers()
</code></pre>
<h3 id="from_nested_row_lengths"><code dir="ltr" translate="no">from_nested_row_lengths</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L890-L926" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_nested_row_lengths(
    cls, flat_values, nested_row_lengths, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> from a nested list of <code dir="ltr" translate="no">row_lengths</code> tensors.</p>
<h4 id="equivalent_to_4">Equivalent to:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = flat_values
for row_lengths in reversed(nested_row_lengths):
  result = from_row_lengths(result, row_lengths)
</code></pre>
<h4 id="args_89">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code dir="ltr" translate="no">nested_row_lengths</code></b>: A list of 1-D integer tensors.  The <code dir="ltr" translate="no">i</code>th tensor is
used as the <code dir="ltr" translate="no">row_lengths</code> for the <code dir="ltr" translate="no">i</code>th ragged dimension.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_89">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> (or <code dir="ltr" translate="no">flat_values</code> if <code dir="ltr" translate="no">nested_row_lengths</code> is empty).</p>
<h3 id="from_nested_row_splits"><code dir="ltr" translate="no">from_nested_row_splits</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L852-L888" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_nested_row_splits(
    cls, flat_values, nested_row_splits, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> from a nested list of <code dir="ltr" translate="no">row_splits</code> tensors.</p>
<h4 id="equivalent_to_5">Equivalent to:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = flat_values
for row_splits in reversed(nested_row_splits):
  result = from_row_splits(result, row_splits)
</code></pre>
<h4 id="args_90">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code dir="ltr" translate="no">nested_row_splits</code></b>: A list of 1-D integer tensors.  The <code dir="ltr" translate="no">i</code>th tensor is
used as the <code dir="ltr" translate="no">row_splits</code> for the <code dir="ltr" translate="no">i</code>th ragged dimension.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form a
valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_90">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> (or <code dir="ltr" translate="no">flat_values</code> if <code dir="ltr" translate="no">nested_row_splits</code> is empty).</p>
<h3 id="from_nested_value_rowids"><code dir="ltr" translate="no">from_nested_value_rowids</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L795-L850" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_nested_value_rowids(
    cls, flat_values, nested_value_rowids, nested_nrows=None, name=None,
    validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> from a nested list of <code dir="ltr" translate="no">value_rowids</code> tensors.</p>
<h4 id="equivalent_to_6">Equivalent to:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = flat_values
for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):
  result = from_value_rowids(result, rowids, nrows)
</code></pre>
<h4 id="args_91">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code dir="ltr" translate="no">nested_value_rowids</code></b>: A list of 1-D integer tensors.  The <code dir="ltr" translate="no">i</code>th tensor is
used as the <code dir="ltr" translate="no">value_rowids</code> for the <code dir="ltr" translate="no">i</code>th ragged dimension.</li>
<li><b><code dir="ltr" translate="no">nested_nrows</code></b>: A list of integer scalars.  The <code dir="ltr" translate="no">i</code>th scalar is used as the
<code dir="ltr" translate="no">nrows</code> for the <code dir="ltr" translate="no">i</code>th ragged dimension.</li>
<li><p><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</p></li>
<li><p><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</p></li>
</ul>
<h4 id="returns_91">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> (or <code dir="ltr" translate="no">flat_values</code> if <code dir="ltr" translate="no">nested_value_rowids</code> is empty).</p>
<h4 id="raises_21">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">len(nested_values_rowids) != len(nested_nrows)</code>.</li>
</ul>
<h3 id="from_row_lengths"><code dir="ltr" translate="no">from_row_lengths</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L496-L553" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_row_lengths(
    cls, values, row_lengths, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">row_lengths</code>.</p>
<p>The returned <code dir="ltr" translate="no">RaggedTensor</code> corresponds with the python list defined by:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = [[values.pop(0) for i in range(length)]
          for length in row_lengths]
</code></pre>
<h4 id="args_92">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">row_lengths</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows]</code>.  Must be
nonnegative.  <code dir="ltr" translate="no">sum(row_lengths)</code> must be <code dir="ltr" translate="no">nvals</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_92">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h4 id="example_35">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_row_lengths( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    row_lengths=[4, 0, 3, 1, 0])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="from_row_limits"><code dir="ltr" translate="no">from_row_limits</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L605-L653" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_row_limits(
    cls, values, row_limits, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">row_limits</code>.</p>
<p>Equivalent to: <code dir="ltr" translate="no">from_row_splits(values, concat([0, row_limits]))</code>.</p>
<h4 id="args_93">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">row_limits</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows]</code>.  Must be sorted in
ascending order.  If <code dir="ltr" translate="no">nrows&gt;0</code>, then <code dir="ltr" translate="no">row_limits[-1]</code> must be <code dir="ltr" translate="no">nvals</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_93">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h4 id="example_36">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_row_limits( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    row_limits=[4, 4, 7, 8, 8])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="from_row_splits"><code dir="ltr" translate="no">from_row_splits</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L434-L494" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_row_splits(
    cls, values, row_splits, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">row_splits</code>.</p>
<p>The returned <code dir="ltr" translate="no">RaggedTensor</code> corresponds with the python list defined by:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = [values[row_splits[i]:row_splits[i + 1]]
          for i in range(len(row_splits) - 1)]
</code></pre>
<h4 id="args_94">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">row_splits</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows+1]</code>.  Must not be
empty, and must be sorted in ascending order.  <code dir="ltr" translate="no">row_splits[0]</code> must be
zero and <code dir="ltr" translate="no">row_splits[-1]</code> must be <code dir="ltr" translate="no">nvals</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_94">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h4 id="raises_22">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">row_splits</code> is an empty list.</li>
</ul>
<h4 id="example_37">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_row_splits( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    row_splits=[0, 4, 4, 7, 8, 8])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="from_row_starts"><code dir="ltr" translate="no">from_row_starts</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L555-L603" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_row_starts(
    cls, values, row_starts, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">row_starts</code>.</p>
<p>Equivalent to: <code dir="ltr" translate="no">from_row_splits(values, concat([row_starts, nvals]))</code>.</p>
<h4 id="args_95">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">row_starts</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nrows]</code>.  Must be
nonnegative and sorted in ascending order.  If <code dir="ltr" translate="no">nrows&gt;0</code>, then
<code dir="ltr" translate="no">row_starts[0]</code> must be zero.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_95">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h4 id="example_38">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_row_starts( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    row_starts=[0, 4, 4, 7, 8])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="from_sparse"><code dir="ltr" translate="no">from_sparse</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1797-L1857" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_sparse(
    cls, st_input, name=None, row_splits_dtype=tf.dtypes.int64
)
</code></pre>
<p>Converts a 2D <a href="https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor"><code dir="ltr" translate="no">tf.SparseTensor</code></a> to a <code dir="ltr" translate="no">RaggedTensor</code>.</p>
<p>Each row of the <code dir="ltr" translate="no">output</code> <code dir="ltr" translate="no">RaggedTensor</code> will contain the explicit values
from the same row in <code dir="ltr" translate="no">st_input</code>.  <code dir="ltr" translate="no">st_input</code> must be ragged-right.  If not
it is not ragged-right, then an error will be generated.</p>
<h4 id="example_39">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">st = tf.SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                     values=[1, 2, 3, 4, 5], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                     dense_shape=[4, 3]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.RaggedTensor.from_sparse(st).to_list() </code>
<code class="no-select nocode" dir="ltr" translate="no">[[1, 2, 3], [4], [], [5]] </code>
</pre>
<p>Currently, only two-dimensional <code dir="ltr" translate="no">SparseTensors</code> are supported.</p>
<h4 id="args_96">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">st_input</code></b>: The sparse tensor to convert.  Must have rank 2.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
<li><b><code dir="ltr" translate="no">row_splits_dtype</code></b>: <code dir="ltr" translate="no">dtype</code> for the returned <code dir="ltr" translate="no">RaggedTensor</code>&#39;s <code dir="ltr" translate="no">row_splits</code>
tensor.  One of <a href="https://www.tensorflow.org/api_docs/python/tf#int32"><code dir="ltr" translate="no">tf.int32</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf#int64"><code dir="ltr" translate="no">tf.int64</code></a>.</li>
</ul>
<h4 id="returns_96">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> with the same values as <code dir="ltr" translate="no">st_input</code>.
<code dir="ltr" translate="no">output.ragged_rank = rank(st_input) - 1</code>.
<code dir="ltr" translate="no">output.shape = [st_input.dense_shape[0], None]</code>.</p>
<h4 id="raises_23">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If the number of dimensions in <code dir="ltr" translate="no">st_input</code> is not known
statically, or is not two.</li>
</ul>
<h3 id="from_tensor"><code dir="ltr" translate="no">from_tensor</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1541-L1746" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_tensor(
    cls, tensor, lengths=None, padding=None, ragged_rank=1, name=None,
    row_splits_dtype=tf.dtypes.int64
)
</code></pre>
<p>Converts a <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code dir="ltr" translate="no">tf.Tensor</code></a> into a <code dir="ltr" translate="no">RaggedTensor</code>.</p>
<p>The set of absent/default values may be specified using a vector of lengths
or a padding value (but not both).  If <code dir="ltr" translate="no">lengths</code> is specified, then the
output tensor will satisfy <code dir="ltr" translate="no">output[row] = tensor[row][:lengths[row]]</code>. If
&#39;lengths&#39; is a list of lists or tuple of lists, those lists will be used
as nested row lengths. If <code dir="ltr" translate="no">padding</code> is specified, then any row <em>suffix</em>
consisting entirely of <code dir="ltr" translate="no">padding</code> will be excluded from the returned
<code dir="ltr" translate="no">RaggedTensor</code>.  If neither <code dir="ltr" translate="no">lengths</code> nor <code dir="ltr" translate="no">padding</code> is specified, then the
returned <code dir="ltr" translate="no">RaggedTensor</code> will have no absent/default values.</p>
<h4 id="examples_6">Examples:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.RaggedTensor.from_tensor(dt) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]&gt; </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3]) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[5], [], [6, 0, 0]]&gt; </code>
</pre>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.RaggedTensor.from_tensor(dt, padding=0) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[5, 7], [0, 3], [6]]&gt; </code>
</pre>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">dt = tf.constant([[[5, 0], [7, 0], [0, 0]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                  [[0, 0], [3, 0], [0, 0]], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">                  [[6, 0], [0, 0], [0, 0]]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1])) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]&gt; </code>
</pre>
<h4 id="args_97">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">tensor</code></b>: The <code dir="ltr" translate="no">Tensor</code> to convert.  Must have rank <code dir="ltr" translate="no">ragged_rank + 1</code> or
higher.</li>
<li><b><code dir="ltr" translate="no">lengths</code></b>: An optional set of row lengths, specified using a 1-D integer
<code dir="ltr" translate="no">Tensor</code> whose length is equal to <code dir="ltr" translate="no">tensor.shape[0]</code> (the number of rows
in <code dir="ltr" translate="no">tensor</code>).  If specified, then <code dir="ltr" translate="no">output[row]</code> will contain
<code dir="ltr" translate="no">tensor[row][:lengths[row]]</code>.  Negative lengths are treated as zero. You
may optionally pass a list or tuple of lengths to this argument, which
will be used as nested row lengths to construct a ragged tensor with
multiple ragged dimensions.</li>
<li><b><code dir="ltr" translate="no">padding</code></b>: An optional padding value.  If specified, then any row suffix
consisting entirely of <code dir="ltr" translate="no">padding</code> will be excluded from the returned
RaggedTensor.  <code dir="ltr" translate="no">padding</code> is a <code dir="ltr" translate="no">Tensor</code> with the same dtype as <code dir="ltr" translate="no">tensor</code>
and with <code dir="ltr" translate="no">shape=tensor.shape[ragged_rank + 1:]</code>.</li>
<li><b><code dir="ltr" translate="no">ragged_rank</code></b>: Integer specifying the ragged rank for the returned
<code dir="ltr" translate="no">RaggedTensor</code>.  Must be greater than zero.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
<li><b><code dir="ltr" translate="no">row_splits_dtype</code></b>: <code dir="ltr" translate="no">dtype</code> for the returned <code dir="ltr" translate="no">RaggedTensor</code>&#39;s <code dir="ltr" translate="no">row_splits</code>
tensor.  One of <a href="https://www.tensorflow.org/api_docs/python/tf#int32"><code dir="ltr" translate="no">tf.int32</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf#int64"><code dir="ltr" translate="no">tf.int64</code></a>.</li>
</ul>
<h4 id="returns_97">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> with the specified <code dir="ltr" translate="no">ragged_rank</code>.  The shape of the
returned ragged tensor is compatible with the shape of <code dir="ltr" translate="no">tensor</code>.</p>
<h4 id="raises_24">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If both <code dir="ltr" translate="no">lengths</code> and <code dir="ltr" translate="no">padding</code> are specified.</li>
</ul>
<h3 id="from_uniform_row_length"><code dir="ltr" translate="no">from_uniform_row_length</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L655-L793" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_uniform_row_length(
    cls, values, uniform_row_length, nrows=None, validate=True, name=None
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">uniform_row_length</code>.</p>
<p>This method can be used to create <code dir="ltr" translate="no">RaggedTensor</code>s with multiple uniform
outer dimensions.  For example, a <code dir="ltr" translate="no">RaggedTensor</code> with shape <code dir="ltr" translate="no">[2, 2, None]</code>
can be constructed with this method from a <code dir="ltr" translate="no">RaggedTensor</code> values with shape
<code dir="ltr" translate="no">[4, None]</code>:</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(values.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(4, None) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt1) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt; </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt1.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(2, 2, None) </code>
</pre>
<p>Note that <code dir="ltr" translate="no">rt1</code> only contains one ragged dimension (the innermost
dimension). In contrast, if <code dir="ltr" translate="no">from_row_splits</code> is used to construct a similar
<code dir="ltr" translate="no">RaggedTensor</code>, then that <code dir="ltr" translate="no">RaggedTensor</code> will have two ragged dimensions:</p>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt2.shape) </code>
<code class="no-select nocode" dir="ltr" translate="no">(2, None, None) </code>
</pre>
<h4 id="args_98">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">uniform_row_length</code></b>: A scalar integer tensor.  Must be nonnegative.
The size of the outer axis of <code dir="ltr" translate="no">values</code> must be evenly divisible by
<code dir="ltr" translate="no">uniform_row_length</code>.</li>
<li><b><code dir="ltr" translate="no">nrows</code></b>: The number of rows in the constructed RaggedTensor.  If not
specified, then it defaults to <code dir="ltr" translate="no">nvals/uniform_row_length</code> (or <code dir="ltr" translate="no">0</code> if
<code dir="ltr" translate="no">uniform_row_length==0</code>).  <code dir="ltr" translate="no">nrows</code> only needs to be specified if
<code dir="ltr" translate="no">uniform_row_length</code> might be zero.  <code dir="ltr" translate="no">uniform_row_length*nrows</code> must
be <code dir="ltr" translate="no">nvals</code>.</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
</ul>
<h4 id="returns_98">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code> that corresponds with the python list defined by:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = [[values.pop(0) for i in range(uniform_row_length)]
          for _ in range(nrows)]
</code></pre>
<p><code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h3 id="from_value_rowids"><code dir="ltr" translate="no">from_value_rowids</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L316-L432" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">@classmethod
from_value_rowids(
    cls, values, value_rowids, nrows=None, name=None, validate=True
)
</code></pre>
<p>Creates a <code dir="ltr" translate="no">RaggedTensor</code> with rows partitioned by <code dir="ltr" translate="no">value_rowids</code>.</p>
<p>The returned <code dir="ltr" translate="no">RaggedTensor</code> corresponds with the python list defined by:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]
          for row in range(nrows)]
</code></pre>
<h4 id="args_99">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">values</code></b>: A potentially ragged tensor with shape <code dir="ltr" translate="no">[nvals, ...]</code>.</li>
<li><b><code dir="ltr" translate="no">value_rowids</code></b>: A 1-D integer tensor with shape <code dir="ltr" translate="no">[nvals]</code>, which corresponds
one-to-one with <code dir="ltr" translate="no">values</code>, and specifies each value&#39;s row index.  Must be
nonnegative, and must be sorted in ascending order.</li>
<li><b><code dir="ltr" translate="no">nrows</code></b>: An integer scalar specifying the number of rows.  This should be
specified if the <code dir="ltr" translate="no">RaggedTensor</code> may containing empty training rows. Must
be greater than <code dir="ltr" translate="no">value_rowids[-1]</code> (or zero if <code dir="ltr" translate="no">value_rowids</code> is empty).
Defaults to <code dir="ltr" translate="no">value_rowids[-1]</code> (or zero if <code dir="ltr" translate="no">value_rowids</code> is empty).</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code dir="ltr" translate="no">validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code dir="ltr" translate="no">RaggedTensor</code>.</li>
</ul>
<h4 id="returns_99">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = values.rank + 1</code>.
<code dir="ltr" translate="no">result.ragged_rank = values.ragged_rank + 1</code>.</p>
<h4 id="raises_25">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">nrows</code> is incompatible with <code dir="ltr" translate="no">value_rowids</code>.</li>
</ul>
<h4 id="example_40">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(tf.RaggedTensor.from_value_rowids( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    values=[3, 1, 4, 1, 5, 9, 2, 6], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    nrows=5)) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; </code>
</pre>
<h3 id="merge_dims"><code dir="ltr" translate="no">merge_dims</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1496-L1534" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">merge_dims(
    outer_axis, inner_axis
)
</code></pre>
<p>Merges outer_axis...inner_axis into a single dimension.</p>
<p>Returns a copy of this RaggedTensor with the specified range of dimensions
flattened into a single dimension, with elements in row-major order.</p>
<h4 id="examples_7">Examples:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.merge_dims(0, 1)) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]&gt; </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.merge_dims(1, 2)) </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]&gt; </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.merge_dims(0, 2)) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32) </code>
</pre>
<p>To mimic the behavior of <code dir="ltr" translate="no">np.flatten</code> (which flattens all dimensions), use
<code dir="ltr" translate="no">rt.merge_dims(0, -1).  To mimic the behavior of</code>tf.layers.Flatten<code dir="ltr" translate="no">(which
flattens all dimensions except the outermost batch dimension), use</code>rt.merge_dims(1, -1)`.</p>
<h4 id="args_100">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">outer_axis</code></b>: <code dir="ltr" translate="no">int</code>: The first dimension in the range of dimensions to
merge. May be negative if <code dir="ltr" translate="no">self.shape.rank</code> is statically known.</li>
<li><b><code dir="ltr" translate="no">inner_axis</code></b>: <code dir="ltr" translate="no">int</code>: The last dimension in the range of dimensions to
merge. May be negative if <code dir="ltr" translate="no">self.shape.rank</code> is statically known.</li>
</ul>
<h4 id="returns_100">Returns:</h4>
<p>A copy of this tensor, with the specified dimensions merged into a
single dimension.  The shape of the returned tensor will be
<code dir="ltr" translate="no">self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]</code>, where <code dir="ltr" translate="no">N</code>
is the total number of slices in the merged dimensions.</p>
<h3 id="nested_row_lengths"><code dir="ltr" translate="no">nested_row_lengths</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1323-L1342" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">nested_row_lengths(
    name=None
)
</code></pre>
<p>Returns a tuple containing the row_lengths for all ragged dimensions.</p>
<p><code dir="ltr" translate="no">rt.nested_row_lengths()</code> is a tuple containing the <code dir="ltr" translate="no">row_lengths</code> tensors
for all ragged dimensions in <code dir="ltr" translate="no">rt</code>, ordered from outermost to innermost.</p>
<h4 id="args_101">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>
<h4 id="returns_101">Returns:</h4>
<p>A <code dir="ltr" translate="no">tuple</code> of 1-D integer <code dir="ltr" translate="no">Tensors</code>.  The length of the tuple is equal to
<code dir="ltr" translate="no">self.ragged_rank</code>.</p>
<h3 id="nested_value_rowids"><code dir="ltr" translate="no">nested_value_rowids</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1162-L1197" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">nested_value_rowids(
    name=None
)
</code></pre>
<p>Returns a tuple containing the value_rowids for all ragged dimensions.</p>
<p><code dir="ltr" translate="no">rt.nested_value_rowids</code> is a tuple containing the <code dir="ltr" translate="no">value_rowids</code> tensors
for
all ragged dimensions in <code dir="ltr" translate="no">rt</code>, ordered from outermost to innermost.  In
particular, <code dir="ltr" translate="no">rt.nested_value_rowids = (rt.value_rowids(),) + value_ids</code>
where:</p>
<pre class="prettyprint" dir="ltr" translate="no"><code dir="ltr" translate="no">* `value_ids = ()` if `rt.values` is a `Tensor`.
* `value_ids = rt.values.nested_value_rowids` otherwise.
</code></pre>
<h4 id="args_102">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>
<h4 id="returns_102">Returns:</h4>
<p>A <code dir="ltr" translate="no">tuple</code> of 1-D integer <code dir="ltr" translate="no">Tensor</code>s.</p>
<h4 id="example_41">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">for i, ids in enumerate(rt.nested_value_rowids()): </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">  print(&#39;row ids for dimension %d: %s&#39; % (i+1, ids.numpy())) </code>
<code class="no-select nocode" dir="ltr" translate="no">row ids for dimension 1: [0 0 0] </code>
<code class="no-select nocode" dir="ltr" translate="no">row ids for dimension 2: [0 0 0 2 2] </code>
<code class="no-select nocode" dir="ltr" translate="no">row ids for dimension 3: [0 0 0 0 2 2 2 3] </code>
</pre>
<h3 id="nrows"><code dir="ltr" translate="no">nrows</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1199-L1226" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">nrows(
    out_type=None, name=None
)
</code></pre>
<p>Returns the number of rows in this ragged tensor.</p>
<p>I.e., the size of the outermost dimension of the tensor.</p>
<h4 id="args_103">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">out_type</code></b>: <code dir="ltr" translate="no">dtype</code> for the returned tensor.  Defaults to
<code dir="ltr" translate="no">self.row_splits.dtype</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>
<h4 id="returns_103">Returns:</h4>
<p>A scalar <code dir="ltr" translate="no">Tensor</code> with dtype <code dir="ltr" translate="no">out_type</code>.</p>
<h4 id="example_42">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.nrows())  # rt has 5 rows. </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor(5, shape=(), dtype=int64) </code>
</pre>
<h3 id="row_lengths"><code dir="ltr" translate="no">row_lengths</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1278-L1321" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">row_lengths(
    axis=1, name=None
)
</code></pre>
<p>Returns the lengths of the rows in this ragged tensor.</p>
<p><code dir="ltr" translate="no">rt.row_lengths()[i]</code> indicates the number of values in the
<code dir="ltr" translate="no">i</code>th row of <code dir="ltr" translate="no">rt</code>.</p>
<h4 id="args_104">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">axis</code></b>: An integer constant indicating the axis whose row lengths should be
returned.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>
<h4 id="returns_104">Returns:</h4>
<p>A potentially ragged integer Tensor with shape <code dir="ltr" translate="no">self.shape[:axis]</code>.</p>
<h4 id="raises_26">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">axis</code> is out of bounds.</li>
</ul>
<h4 id="example_43">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant( </code>
<code class="devsite-terminal" data-terminal-prefix="..." dir="ltr" translate="no">    [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.row_lengths())  # lengths of rows in rt </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.row_lengths(axis=2))  # lengths of axis=2 rows. </code>
<code class="no-select nocode" dir="ltr" translate="no">&lt;tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]&gt; </code>
</pre>
<h3 id="row_limits"><code dir="ltr" translate="no">row_limits</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1253-L1276" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">row_limits(
    name=None
)
</code></pre>
<p>Returns the limit indices for rows in this ragged tensor.</p>
<p>These indices specify where the values for each row end in
<code dir="ltr" translate="no">self.values</code>.  <code dir="ltr" translate="no">rt.row_limits(self)</code> is equal to <code dir="ltr" translate="no">rt.row_splits[:-1]</code>.</p>
<h4 id="args_105">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>
<h4 id="returns_105">Returns:</h4>
<p>A 1-D integer Tensor with shape <code dir="ltr" translate="no">[nrows]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>
<h4 id="example_44">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.values) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.row_limits())  # indices of row limits in rt.values </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64) </code>
</pre>
<h3 id="row_starts"><code dir="ltr" translate="no">row_starts</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1228-L1251" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">row_starts(
    name=None
)
</code></pre>
<p>Returns the start indices for rows in this ragged tensor.</p>
<p>These indices specify where the values for each row begin in
<code dir="ltr" translate="no">self.values</code>.  <code dir="ltr" translate="no">rt.row_starts()</code> is equal to <code dir="ltr" translate="no">rt.row_splits[:-1]</code>.</p>
<h4 id="args_106">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>
<h4 id="returns_106">Returns:</h4>
<p>A 1-D integer Tensor with shape <code dir="ltr" translate="no">[nrows]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>
<h4 id="example_45">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.values) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.row_starts())  # indices of row starts in rt.values </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64) </code>
</pre>
<h3 id="to_list"><code dir="ltr" translate="no">to_list</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1999-L2012" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">to_list()
</code></pre>
<p>Returns a nested Python <code dir="ltr" translate="no">list</code> with the values for this <code dir="ltr" translate="no">RaggedTensor</code>.</p>
<p>Requires that <code dir="ltr" translate="no">rt</code> was constructed in eager execution mode.</p>
<h4 id="returns_107">Returns:</h4>
<p>A nested Python <code dir="ltr" translate="no">list</code>.</p>
<h3 id="to_sparse"><code dir="ltr" translate="no">to_sparse</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1859-L1883" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">to_sparse(
    name=None
)
</code></pre>
<p>Converts this <code dir="ltr" translate="no">RaggedTensor</code> into a <a href="https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor"><code dir="ltr" translate="no">tf.SparseTensor</code></a>.</p>
<h4 id="example_46">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.to_sparse()) </code>
<code class="no-select nocode" dir="ltr" translate="no">SparseTensor(indices=tf.Tensor( </code>
<code class="no-select nocode" dir="ltr" translate="no">                 [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]], </code>
<code class="no-select nocode" dir="ltr" translate="no">                 shape=(6, 2), dtype=int64), </code>
<code class="no-select nocode" dir="ltr" translate="no">             values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32), </code>
<code class="no-select nocode" dir="ltr" translate="no">             dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64)) </code>
</pre>
<h4 id="args_107">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>
<h4 id="returns_108">Returns:</h4>
<p>A SparseTensor with the same values as <code dir="ltr" translate="no">self</code>.</p>
<h3 id="to_tensor"><code dir="ltr" translate="no">to_tensor</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1748-L1795" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">to_tensor(
    default_value=None, name=None, shape=None
)
</code></pre>
<p>Converts this <code dir="ltr" translate="no">RaggedTensor</code> into a <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor"><code dir="ltr" translate="no">tf.Tensor</code></a>.</p>
<p>If <code dir="ltr" translate="no">shape</code> is specified, then the result is padded and/or truncated to
the specified shape.</p>
<h4 id="examples_8">Examples:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.to_tensor()) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor( </code>
<code class="no-select nocode" dir="ltr" translate="no">    [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.to_tensor(shape=[5, 2])) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor( </code>
<code class="no-select nocode" dir="ltr" translate="no">    [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32) </code>
</pre>
<h4 id="args_108">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">default_value</code></b>: Value to set for indices not specified in <code dir="ltr" translate="no">self</code>. Defaults
to zero.  <code dir="ltr" translate="no">default_value</code> must be broadcastable to
<code dir="ltr" translate="no">self.shape[self.ragged_rank + 1:]</code>.</li>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensors (optional).</li>
<li><b><code dir="ltr" translate="no">shape</code></b>: The shape of the resulting dense tensor.  In particular,
<code dir="ltr" translate="no">result.shape[i]</code> is <code dir="ltr" translate="no">shape[i]</code> (if <code dir="ltr" translate="no">shape[i]</code> is not None), or
<code dir="ltr" translate="no">self.bounding_shape(i)</code> (otherwise).<code dir="ltr" translate="no">shape.rank</code> must be <code dir="ltr" translate="no">None</code> or
equal to <code dir="ltr" translate="no">self.rank</code>.</li>
</ul>
<h4 id="returns_109">Returns:</h4>
<p>A <code dir="ltr" translate="no">Tensor</code> with shape <code dir="ltr" translate="no">ragged.bounding_shape(self)</code> and the
values specified by the non-empty values in <code dir="ltr" translate="no">self</code>.  Empty values are
assigned <code dir="ltr" translate="no">default_value</code>.</p>
<h3 id="value_rowids"><code dir="ltr" translate="no">value_rowids</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1132-L1160" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">value_rowids(
    name=None
)
</code></pre>
<p>Returns the row indices for the <code dir="ltr" translate="no">values</code> in this ragged tensor.</p>
<p><code dir="ltr" translate="no">rt.value_rowids()</code> corresponds one-to-one with the outermost dimension of
<code dir="ltr" translate="no">rt.values</code>, and specifies the row containing each value.  In particular,
the row <code dir="ltr" translate="no">rt[row]</code> consists of the values <code dir="ltr" translate="no">rt.values[j]</code> where
<code dir="ltr" translate="no">rt.value_rowids()[j] == row</code>.</p>
<h4 id="args_109">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>
<h4 id="returns_110">Returns:</h4>
<p>A 1-D integer <code dir="ltr" translate="no">Tensor</code> with shape <code dir="ltr" translate="no">self.values.shape[:1]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>
<h4 id="example_47">Example:</h4>
<pre class="devsite-click-to-copy prettyprint lang-py" dir="ltr" translate="no"><code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.values) </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) </code>
<code class="devsite-terminal" data-terminal-prefix="&gt;&gt;&gt;" dir="ltr" translate="no">print(rt.value_rowids())  # corresponds 1:1 with rt.values </code>
<code class="no-select nocode" dir="ltr" translate="no">tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64) </code>
</pre>
<h3 id="with_flat_values"><code dir="ltr" translate="no">with_flat_values</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1434-L1453" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">with_flat_values(
    new_values
)
</code></pre>
<p>Returns a copy of <code dir="ltr" translate="no">self</code> with <code dir="ltr" translate="no">flat_values</code> replaced by <code dir="ltr" translate="no">new_value</code>.</p>
<p>Preserves cached row-partitioning tensors such as <code dir="ltr" translate="no">self.cached_nrows</code> and
<code dir="ltr" translate="no">self.cached_value_rowids</code> if they have values.</p>
<h4 id="args_110">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">new_values</code></b>: Potentially ragged tensor that should replace
<code dir="ltr" translate="no">self.flat_values</code>.  Must have <code dir="ltr" translate="no">rank &gt; 0</code>, and must have the same
number of rows as <code dir="ltr" translate="no">self.flat_values</code>.</li>
</ul>
<h4 id="returns_111">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.
<code dir="ltr" translate="no">result.rank = self.ragged_rank + new_values.rank</code>.
<code dir="ltr" translate="no">result.ragged_rank = self.ragged_rank + new_values.ragged_rank</code>.</p>
<h3 id="with_row_splits_dtype"><code dir="ltr" translate="no">with_row_splits_dtype</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1455-L1494" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">with_row_splits_dtype(
    dtype
)
</code></pre>
<p>Returns a copy of this RaggedTensor with the given <code dir="ltr" translate="no">row_splits</code> dtype.</p>
<p>For RaggedTensors with multiple ragged dimensions, the <code dir="ltr" translate="no">row_splits</code> for all
nested <code dir="ltr" translate="no">RaggedTensor</code> objects are cast to the given dtype.</p>
<h4 id="args_111">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">dtype</code></b>: The dtype for <code dir="ltr" translate="no">row_splits</code>.  One of <a href="https://www.tensorflow.org/api_docs/python/tf#int32"><code dir="ltr" translate="no">tf.int32</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf#int64"><code dir="ltr" translate="no">tf.int64</code></a>.</li>
</ul>
<h4 id="returns_112">Returns:</h4>
<p>A copy of this RaggedTensor, with the <code dir="ltr" translate="no">row_splits</code> cast to the given
type.</p>
<h3 id="with_values"><code dir="ltr" translate="no">with_values</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/ragged/ragged_tensor.py#L1400-L1432" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">with_values(
    new_values
)
</code></pre>
<p>Returns a copy of <code dir="ltr" translate="no">self</code> with <code dir="ltr" translate="no">values</code> replaced by <code dir="ltr" translate="no">new_value</code>.</p>
<p>Preserves cached row-partitioning tensors such as <code dir="ltr" translate="no">self.cached_nrows</code> and
<code dir="ltr" translate="no">self.cached_value_rowids</code> if they have values.</p>
<h4 id="args_112">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">new_values</code></b>: Potentially ragged tensor to use as the <code dir="ltr" translate="no">values</code> for the
returned <code dir="ltr" translate="no">RaggedTensor</code>.  Must have <code dir="ltr" translate="no">rank &gt; 0</code>, and must have the same
number of rows as <code dir="ltr" translate="no">self.values</code>.</li>
</ul>
<h4 id="returns_113">Returns:</h4>
<p>A <code dir="ltr" translate="no">RaggedTensor</code>.  <code dir="ltr" translate="no">result.rank = 1 + new_values.rank</code>.
<code dir="ltr" translate="no">result.ragged_rank = 1 + new_values.ragged_rank</code></p>
</div>
<devsite-page-rating hover-rating-star="0" position="footer" selected-rating="0">
</devsite-page-rating>
</article>
</article>

</devsite-content>
</main>
<devsite-footer-promos class="devsite-footer">
</devsite-footer-promos>
<devsite-footer-linkboxes class="devsite-footer">

</devsite-footer-linkboxes>
<devsite-footer-utility class="devsite-footer">
<div class="devsite-footer-utility nocontent">

</div>
</devsite-footer-utility>
</section></section>
<devsite-sitemask></devsite-sitemask>
<devsite-snackbar></devsite-snackbar> <devsite-tooltip></devsite-tooltip>
<devsite-heading-link></devsite-heading-link>
<devsite-analytics>


</devsite-analytics>
 
</body></html>