<!DOCTYPE html><html dir="ltr" lang="en"><head>
<meta content="157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com" name="google-signin-client-id"/>
<meta content="profile email" name="google-signin-scope"/>
<meta content="TensorFlow" property="og:site_name"/>
<meta content="website" property="og:type"/>
<meta content="#ff6f00" name="theme-color"/>
<meta charset="utf-8"/>
<meta content="IE=Edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link crossorigin="use-credentials" href="_pwa/tensorflow/manifest.json" rel="manifest"/>
<link crossorigin="" href="/www.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.googleapis.com" rel="preconnect"/>
<link href="../../../../../../../main.css" rel="stylesheet"/>

<noscript>

</noscript>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/favicon.png" rel="shortcut icon"/>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/apple-touch-icon-180x180.png" rel="apple-touch-icon"/><link href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/experimental/enable_mixed_precision_graph_rewrite" rel="canonical"/><link href="https://www.tensorflow.org/s/opensearch.xml" rel="search" title="TensorFlow" type="application/opensearchdescription+xml"/>
<title>tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite</title>
<meta content="tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite" property="og:title"/>
<meta content="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/experimental/enable_mixed_precision_graph_rewrite" property="og:url"/>
<meta content="en" property="og:locale"/>

</head>
<body class="" layout="docs" pending="" theme="tensorflow-theme" type="reference">
<devsite-progress id="app-progress" type="indeterminate"></devsite-progress>
<section class="devsite-wrapper"> <devsite-book-nav scrollbars="">

</devsite-book-nav>
<section id="gc-wrapper">
<main class="devsite-main-content" has-book-nav="" has-toc="" role="main">
<devsite-toc class="devsite-nav"></devsite-toc>
<devsite-content>
<article class="devsite-article">
<article class="devsite-article-inner"><style>
        /* Styles inlined from /site-assets/css/style.css */
/* override theme */
table img {
  max-width: 100%;
}

/* override var element to differentiate color from comment */
var, var code, var span, .prettyprint var span {
  color: #039be5;
}

/* .devsite-terminal virtualenv prompt */
.tfo-terminal-venv::before {
  content: "(venv) $ " !important;
}

/* .devsite-terminal root prompt */
.tfo-terminal-root::before {
  content: "# " !important;
}

/* .devsite-terminal Windows prompt */
.tfo-terminal-windows::before {
  content: "C:\\> " !important;
}

/* .devsite-terminal Windows prompt w/ virtualenv */
.tfo-terminal-windows-venv::before {
  content: "(venv) C:\\> " !important;
}

.tfo-diff-green-one-level + * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green + * > * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green-list + ul > li:first-of-type {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-red-one-level + * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red + * > * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red-list + ul > li:first-of-type {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

devsite-code .tfo-notebook-code-cell-output {
  max-height: 300px;
  overflow: auto;
  background: rgba(255, 247, 237, 1);  /* orange bg to distinguish from input code cells */
}

devsite-code .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(255, 247, 237, .7);  /* orange bg to distinguish from input code cells */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output {
  background: rgba(64, 78, 103, 1);  /* medium slate */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(64, 78, 103, .7);  /* medium slate */
}

/* override default table styles for notebook buttons */
.devsite-table-wrapper .tfo-notebook-buttons {
  display: inline-block;
  margin-left: 3px;
  width: auto;
}

.tfo-notebook-buttons td {
  padding-left: 0;
  padding-right: 20px;
}

.tfo-notebook-buttons a,
.tfo-notebook-buttons :link,
.tfo-notebook-buttons :visited {
  border-radius: 8px;
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 1px 3px 1px rgba(60, 64, 67, .15);
  color: #202124;
  padding: 12px 24px;
  transition: box-shadow 0.2s;
}

.tfo-notebook-buttons a:hover,
.tfo-notebook-buttons a:focus {
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 2px 6px 2px rgba(60, 64, 67, .15);
}

.tfo-notebook-buttons tr {
  background: 0;
  border: 0;
}

/* on rendered notebook page,
   remove link to webpage since we're already here */
.tfo-notebook-buttons:not(.tfo-api) td:first-child {
  display: none;
}

.tfo-notebook-buttons td > a {
  -webkit-box-align: center;
  -ms-flex-align: center;
  align-items: center;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
}

.tfo-notebook-buttons td > a > img {
  margin-right: 8px;
}

/* landing pages */

.tfo-landing-row-item-inset-white {
  background-color: #fff;
  padding: 32px;
}

.tfo-landing-row-item-inset-white ol,
.tfo-landing-row-item-inset-white ul {
  padding-left: 20px;
}

/* colab callout button */
.colab-callout-row devsite-code {
  border-radius: 8px 8px 0 0;
  box-shadow: none;
}

.colab-callout-footer {
  background: #e3e4e7;
  border-radius: 0 0 8px 8px;
  color: #37474f;
  padding: 20px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer {
  background: #3f4f66;
}


.colab-callout-footer > .button {
  margin-top: 4px;
  color: #ff5c00;
}

.colab-callout-footer > a > span {
  padding-top: 10px;
  vertical-align: middle;
  color: #37474f;
  padding-left: 10px;
  padding-right: 10px;
  font-size: 14px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer > a > span {
  color: #fff;
}

a.colab-button {
  background: rgba(255, 255, 255, .75);
  border: solid 1px rgba(0, 0, 0, .08);
  border-bottom-color: rgba(0, 0, 0, .15);
  border-radius: 4px;
  color: #aaa;
  display: inline-block;
  font-size: 11px !important;
  font-weight: 300;
  line-height: 16px;
  padding: 4px 8px;
  text-decoration: none;
  text-transform: uppercase;
}

a.colab-button:hover {
  background: white;
  border-color: rgba(0, 0, 0, .2);
  color: #666;
}

a.colab-button span {
  background: url(/images/colab_logo_button.svg) no-repeat 1px 1px / 20px;
  border-radius: 4px;
  display: inline-block;
  padding-left: 24px;
  text-decoration: none;
}

@media screen and (max-width: 600px) {
  .tfo-notebook-buttons td {
    display: block;
  }
}

/* guide and tutorials landing page cards and sections */

.tfo-landing-page-card {
  padding: 16px;
  box-shadow: 0 0 36px rgba(0,0,0,0.1);
  border-radius: 10px;
}

/* Page section headings */
.tfo-landing-page-heading h2, h2.tfo-landing-page-heading {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 30px;
  font-weight: 700;
  line-height: 40px;
}

/* Item title headings */
.tfo-landing-page-heading h3, h3.tfo-landing-page-heading,
.tfo-landing-page-card h3, h3.tfo-landing-page-card {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 20px;
  font-weight: 500;
  line-height: 26px;
}

/* List of tutorials notebooks for subsites */
.tfo-landing-page-resources-ul {
  padding-left: 15px
}

.tfo-landing-page-resources-ul > li {
  margin: 6px 0;
}

/* Temporary fix to hide product description in header on landing pages */
devsite-header .devsite-product-description {
  display: none;
}

        </style> <div class="devsite-banner devsite-banner-announcement">
<div class="devsite-banner-message">
<div class="devsite-banner-message-text">
            Missed TensorFlow Dev Summit? Check out the video playlist. <a class="button button-primary button-tfo-announcement" href="https://goo.gle/TFDS20AllSessions">Watch recordings</a>
</div>
</div>
</div>
<div class="devsite-article-meta">
<ul class="devsite-breadcrumb-list">
<li class="devsite-breadcrumb-item">
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="1" href="">
            TensorFlow
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="2" href="api">
            API
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="3" href="api_docs">
            TensorFlow Core v2.1.0
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="4" href="api_docs/python/tf">
            Python
      
  </a>
</li>
</ul>
<devsite-page-rating hover-rating-star="0" position="header" selected-rating="0">
</devsite-page-rating>
</div>
<a class="dashingAutolink" name="autolink-1069"></a><a class="dashAnchor" name="//apple_ref/cpp/Function/tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite"></a><h1 class="dash-function">tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite</h1>
<devsite-toc class="devsite-nav" devsite-toc-embedded="">
</devsite-toc>
<div class="devsite-article-body clearfix">
<p></p>
<!-- DO NOT EDIT! Automatically generated file. -->
<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<meta content="tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite" itemprop="name"/>
<meta content="Stable" itemprop="path"/>
</div>
<!-- Insert buttons and diff -->
<table align="left" class="tfo-notebook-buttons tfo-api">
<tbody><tr><td>
<a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/training/experimental/mixed_precision.py#L204-L330" target="_blank">
<img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png"/>
    View source on GitHub
  </a>
</td></tr></tbody></table>
<p>Enable mixed precision via a graph rewrite.</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite(
    opt, loss_scale=&#39;dynamic&#39;
)
</code></pre>
<!-- Placeholder for "Used in" -->
<p>Mixed precision is the use of both float32 and float16 data types when
training a model to improve performance. This is achieved via a graph rewrite
operation and a loss-scale optimizer.</p>
<p>Performing arithmetic operations in float16 takes advantage of specialized
processing units, such as NVIDIA Tensor Cores for much higher arithmetic
throughput. However, due to the smaller representable range, performing the
entire training with float16 can result in gradient underflow, that is, small
gradient values becoming zeroes. Instead, performing only select arithmetic
operations in float16 results in higher throughput and decreased training
time when using compatible hardware accelerators while also reducing memory
usage, typically without sacrificing model accuracy.</p>
<aside class="note"><strong>Note:</strong><span> While the mixed precision rewrite changes the datatype of various
layers throughout the model, the same accuracy reached in float32 is
expected. If a <code dir="ltr" translate="no">NaN</code> gradient occurs with dynamic loss scaling, the model
update for that batch is skipped. In this case, the global step count is not
incremented, and the <code dir="ltr" translate="no">LossScaleOptimizer</code> attempts to decrease the loss
scaling value to avoid <code dir="ltr" translate="no">NaN</code> values in subsequent iterations. This approach
has been shown to achieve the same accuracy as float32 and, in most cases,
better training throughput.</span></aside>
<h4 id="example">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">model = tf.keras.models.Sequential([
  ...
])

opt = tf.keras.optimizers.SGD()
opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)

model.compile(loss=&#34;categorical_crossentropy&#34;,
            optimizer=opt,
            metrics=[&#34;accuracy&#34;])

model.fit(x_train, y_train,
        batch_size=batch_size,
        epochs=epochs)
</code></pre>
<p>For a complete example showing the speed-up on training an image
classification task on CIFAR10, check out this
<a href="https://colab.research.google.com/github/NVIDIA/DeepLearningExamples/blob/master/TensorFlow/docs/amp/notebook_v1.14/auto_mixed_precision_demo_cifar10">Colab notebook</a>.</p>
<p>Calling <code dir="ltr" translate="no">enable_mixed_precision_graph_rewrite(opt)</code> enables the graph rewrite
operation before computing gradients. The function additionally returns an
<code dir="ltr" translate="no">Optimizer</code>(<code dir="ltr" translate="no">opt</code>) wrapped with a <code dir="ltr" translate="no">LossScaleOptimizer</code>. This prevents
underflow in the float16 tensors during the backward pass. An optimizer of
type <code dir="ltr" translate="no">tf.train.Optimizer</code> or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"><code dir="ltr" translate="no">tf.keras.optimizers.Optimizer</code></a> must be passed
to this function, which will then be wrapped to use loss scaling.</p>
<p><img src="http://developer.download.nvidia.com/compute/machine-learning/frameworks/TF_mixed_precision_training.png" width="500px"/></p>
<p>The graph rewrite operation changes the <code dir="ltr" translate="no">dtype</code> of certain operations in the
graph from float32 to float16. There are several categories of operations
that are either included or excluded by this rewrite operation. The following
categories of Ops are defined inside corresponding functions under the class 
<code dir="ltr" translate="no">AutoMixedPrecisionLists</code> in
<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/auto_mixed_precision_lists.h">
auto_mixed_precision_lists.h</a>:</p>
<ul>
<li><code dir="ltr" translate="no">ClearList</code>: Ops that do not have numerically significant adverse effects.
E.g. <code dir="ltr" translate="no">ArgMax</code> and <code dir="ltr" translate="no">Floor</code>.</li>
<li><code dir="ltr" translate="no">WhiteList</code>: Ops that are considered numerically safe for execution in
float16, and thus are always converted. E.g. <code dir="ltr" translate="no">Conv2D</code>.</li>
<li><code dir="ltr" translate="no">BlackList</code>: Ops that are numerically unsafe to execute in float16 and
can negatively affect downstream nodes. E.g. <code dir="ltr" translate="no">Softmax</code>.</li>
<li><code dir="ltr" translate="no">GrayList</code>: Ops that are considered numerically safe for execution in
float16 unless downstream from a BlackList Op. E.g. <code dir="ltr" translate="no">Add</code> and <code dir="ltr" translate="no">AvgPool</code>.</li>
</ul>
<p>When this function is used, gradients should only be computed and applied
with the returned optimizer, either by calling <code dir="ltr" translate="no">opt.minimize()</code> or
<code dir="ltr" translate="no">opt.compute_gradients()</code> followed by <code dir="ltr" translate="no">opt.apply_gradients()</code>.
Gradients should not be computed with <a href="https://www.tensorflow.org/api_docs/python/tf/gradients"><code dir="ltr" translate="no">tf.gradients</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf/GradientTape"><code dir="ltr" translate="no">tf.GradientTape</code></a>.
This is because the returned optimizer will apply loss scaling, and
<a href="https://www.tensorflow.org/api_docs/python/tf/gradients"><code dir="ltr" translate="no">tf.gradients</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf/GradientTape"><code dir="ltr" translate="no">tf.GradientTape</code></a> will not. If you do directly use
<a href="https://www.tensorflow.org/api_docs/python/tf/gradients"><code dir="ltr" translate="no">tf.gradients</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf/GradientTape"><code dir="ltr" translate="no">tf.GradientTape</code></a>, your model may not converge due to
float16 underflow problems.</p>
<p>When eager execution is enabled, the mixed precision graph rewrite is only
enabled within <a href="https://www.tensorflow.org/api_docs/python/tf/function"><code dir="ltr" translate="no">tf.function</code></a>, as outside <a href="https://www.tensorflow.org/api_docs/python/tf/function"><code dir="ltr" translate="no">tf.function</code></a>, there is no graph.</p>
<p>For NVIDIA GPUs with Tensor cores, as a general performance guide, dimensions
(such as batch size, input size, output size, and channel counts)
should be powers of two if under 256, or  otherwise divisible by 8 if above
256. For more information, check out the
<a href="https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html">NVIDIA Deep Learning Performance Guide</a>.</p>
<p>Currently, mixed precision is only enabled on NVIDIA Tensor Core GPUs with
Compute Capability 7.0 and above (Volta, Turing, or newer architectures). The
parts of the graph on CPUs and TPUs are untouched by the graph rewrite. TPU
support is coming soon. CPUs are not supported, as CPUs do not run float16
operations faster than float32 operations.</p>
<h4 id="raises">Raises:</h4>
<p><code dir="ltr" translate="no">ValueError</code> when
<code dir="ltr" translate="no">mixed_precision_global_state.using_default_mixed_precision_policy</code>
is set to <code dir="ltr" translate="no">False</code> before
<a href="https://www.tensorflow.org/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite"><code dir="ltr" translate="no">tf.train.experimental.enable_mixed_precision_graph_rewrite()</code></a>
is called.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">opt</code></b>: An instance of a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"><code dir="ltr" translate="no">tf.keras.optimizers.Optimizer</code></a> or a
<code dir="ltr" translate="no">tf.train.Optimizer</code>.</li>
<li><b><code dir="ltr" translate="no">loss_scale</code></b>: Either an int/float, the string <code dir="ltr" translate="no">&#34;dynamic&#34;</code>, or an instance of
a <a href="https://www.tensorflow.org/api_docs/python/tf/mixed_precision/experimental/LossScale"><code dir="ltr" translate="no">tf.mixed_precision.experimental.LossScale</code></a>. The loss scale to use. It
is recommended to keep this as its default value of <code dir="ltr" translate="no">&#34;dynamic&#34;</code>, which
will adjust the scaling automatically to prevent <code dir="ltr" translate="no">Inf</code> or <code dir="ltr" translate="no">NaN</code> values.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A version of <code dir="ltr" translate="no">opt</code> that will use loss scaling to prevent underflow.</p>
</div>
<devsite-page-rating hover-rating-star="0" position="footer" selected-rating="0">
</devsite-page-rating>
</article>
</article>

</devsite-content>
</main>
<devsite-footer-promos class="devsite-footer">
</devsite-footer-promos>
<devsite-footer-linkboxes class="devsite-footer">

</devsite-footer-linkboxes>
<devsite-footer-utility class="devsite-footer">
<div class="devsite-footer-utility nocontent">

</div>
</devsite-footer-utility>
</section></section>
<devsite-sitemask></devsite-sitemask>
<devsite-snackbar></devsite-snackbar> <devsite-tooltip></devsite-tooltip>
<devsite-heading-link></devsite-heading-link>
<devsite-analytics>


</devsite-analytics>
 
</body></html>