<!DOCTYPE html><html dir="ltr" lang="en"><head>
<meta content="157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com" name="google-signin-client-id"/>
<meta content="profile email" name="google-signin-scope"/>
<meta content="TensorFlow" property="og:site_name"/>
<meta content="website" property="og:type"/>
<meta content="#ff6f00" name="theme-color"/>
<meta charset="utf-8"/>
<meta content="IE=Edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link crossorigin="use-credentials" href="_pwa/tensorflow/manifest.json" rel="manifest"/>
<link crossorigin="" href="/www.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.googleapis.com" rel="preconnect"/>
<link href="../../../../../../main.css" rel="stylesheet"/>

<noscript>

</noscript>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/favicon.png" rel="shortcut icon"/>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/apple-touch-icon-180x180.png" rel="apple-touch-icon"/><link href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/raw_rnn" rel="canonical"/><link href="https://www.tensorflow.org/s/opensearch.xml" rel="search" title="TensorFlow" type="application/opensearchdescription+xml"/>
<title>tf.compat.v1.nn.raw_rnn &nbsp;|&nbsp; TensorFlow Core v2.1.0</title>
<meta content="tf.compat.v1.nn.raw_rnn &nbsp;|&nbsp; TensorFlow Core v2.1.0" property="og:title"/>
<meta content="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/raw_rnn" property="og:url"/>
<meta content="en" property="og:locale"/>

</head>
<body class="" layout="docs" pending="" theme="tensorflow-theme" type="reference">
<devsite-progress id="app-progress" type="indeterminate"></devsite-progress>
<section class="devsite-wrapper"> <devsite-book-nav scrollbars="">

</devsite-book-nav>
<section id="gc-wrapper">
<main class="devsite-main-content" has-book-nav="" has-toc="" role="main">
<devsite-toc class="devsite-nav"></devsite-toc>
<devsite-content>
<article class="devsite-article">
<article class="devsite-article-inner"><style>
        /* Styles inlined from /site-assets/css/style.css */
/* override theme */
table img {
  max-width: 100%;
}

/* override var element to differentiate color from comment */
var, var code, var span, .prettyprint var span {
  color: #039be5;
}

/* .devsite-terminal virtualenv prompt */
.tfo-terminal-venv::before {
  content: "(venv) $ " !important;
}

/* .devsite-terminal root prompt */
.tfo-terminal-root::before {
  content: "# " !important;
}

/* .devsite-terminal Windows prompt */
.tfo-terminal-windows::before {
  content: "C:\\> " !important;
}

/* .devsite-terminal Windows prompt w/ virtualenv */
.tfo-terminal-windows-venv::before {
  content: "(venv) C:\\> " !important;
}

.tfo-diff-green-one-level + * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green + * > * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green-list + ul > li:first-of-type {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-red-one-level + * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red + * > * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red-list + ul > li:first-of-type {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

devsite-code .tfo-notebook-code-cell-output {
  max-height: 300px;
  overflow: auto;
  background: rgba(255, 247, 237, 1);  /* orange bg to distinguish from input code cells */
}

devsite-code .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(255, 247, 237, .7);  /* orange bg to distinguish from input code cells */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output {
  background: rgba(64, 78, 103, 1);  /* medium slate */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(64, 78, 103, .7);  /* medium slate */
}

/* override default table styles for notebook buttons */
.devsite-table-wrapper .tfo-notebook-buttons {
  display: inline-block;
  margin-left: 3px;
  width: auto;
}

.tfo-notebook-buttons td {
  padding-left: 0;
  padding-right: 20px;
}

.tfo-notebook-buttons a,
.tfo-notebook-buttons :link,
.tfo-notebook-buttons :visited {
  border-radius: 8px;
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 1px 3px 1px rgba(60, 64, 67, .15);
  color: #202124;
  padding: 12px 24px;
  transition: box-shadow 0.2s;
}

.tfo-notebook-buttons a:hover,
.tfo-notebook-buttons a:focus {
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 2px 6px 2px rgba(60, 64, 67, .15);
}

.tfo-notebook-buttons tr {
  background: 0;
  border: 0;
}

/* on rendered notebook page,
   remove link to webpage since we're already here */
.tfo-notebook-buttons:not(.tfo-api) td:first-child {
  display: none;
}

.tfo-notebook-buttons td > a {
  -webkit-box-align: center;
  -ms-flex-align: center;
  align-items: center;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
}

.tfo-notebook-buttons td > a > img {
  margin-right: 8px;
}

/* landing pages */

.tfo-landing-row-item-inset-white {
  background-color: #fff;
  padding: 32px;
}

.tfo-landing-row-item-inset-white ol,
.tfo-landing-row-item-inset-white ul {
  padding-left: 20px;
}

/* colab callout button */
.colab-callout-row devsite-code {
  border-radius: 8px 8px 0 0;
  box-shadow: none;
}

.colab-callout-footer {
  background: #e3e4e7;
  border-radius: 0 0 8px 8px;
  color: #37474f;
  padding: 20px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer {
  background: #3f4f66;
}


.colab-callout-footer > .button {
  margin-top: 4px;
  color: #ff5c00;
}

.colab-callout-footer > a > span {
  padding-top: 10px;
  vertical-align: middle;
  color: #37474f;
  padding-left: 10px;
  padding-right: 10px;
  font-size: 14px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer > a > span {
  color: #fff;
}

a.colab-button {
  background: rgba(255, 255, 255, .75);
  border: solid 1px rgba(0, 0, 0, .08);
  border-bottom-color: rgba(0, 0, 0, .15);
  border-radius: 4px;
  color: #aaa;
  display: inline-block;
  font-size: 11px !important;
  font-weight: 300;
  line-height: 16px;
  padding: 4px 8px;
  text-decoration: none;
  text-transform: uppercase;
}

a.colab-button:hover {
  background: white;
  border-color: rgba(0, 0, 0, .2);
  color: #666;
}

a.colab-button span {
  background: url(/images/colab_logo_button.svg) no-repeat 1px 1px / 20px;
  border-radius: 4px;
  display: inline-block;
  padding-left: 24px;
  text-decoration: none;
}

@media screen and (max-width: 600px) {
  .tfo-notebook-buttons td {
    display: block;
  }
}

/* guide and tutorials landing page cards and sections */

.tfo-landing-page-card {
  padding: 16px;
  box-shadow: 0 0 36px rgba(0,0,0,0.1);
  border-radius: 10px;
}

/* Page section headings */
.tfo-landing-page-heading h2, h2.tfo-landing-page-heading {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 30px;
  font-weight: 700;
  line-height: 40px;
}

/* Item title headings */
.tfo-landing-page-heading h3, h3.tfo-landing-page-heading,
.tfo-landing-page-card h3, h3.tfo-landing-page-card {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 20px;
  font-weight: 500;
  line-height: 26px;
}

/* List of tutorials notebooks for subsites */
.tfo-landing-page-resources-ul {
  padding-left: 15px
}

.tfo-landing-page-resources-ul > li {
  margin: 6px 0;
}

/* Temporary fix to hide product description in header on landing pages */
devsite-header .devsite-product-description {
  display: none;
}

        </style> <div class="devsite-banner devsite-banner-announcement">
<div class="devsite-banner-message">
<div class="devsite-banner-message-text">
            Missed TensorFlow Dev Summit? Check out the video playlist. <a class="button button-primary button-tfo-announcement" href="https://goo.gle/TFDS20AllSessions">Watch recordings</a>
</div>
</div>
</div>
<div class="devsite-article-meta">
<ul class="devsite-breadcrumb-list">
<li class="devsite-breadcrumb-item">
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="1" href="">
            TensorFlow
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="2" href="api">
            API
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="3" href="api_docs">
            TensorFlow Core v2.1.0
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="4" href="api_docs/python/tf">
            Python
      
  </a>
</li>
</ul>
<devsite-page-rating hover-rating-star="0" position="header" selected-rating="0">
</devsite-page-rating>
</div>
<a class="dashingAutolink" name="autolink-815"></a><a class="dashAnchor" name="//apple_ref/cpp/Function/tf.compat.v1.nn.raw_rnn"></a><h1 class="dash-function">tf.compat.v1.nn.raw_rnn</h1>
<devsite-toc class="devsite-nav" devsite-toc-embedded="">
</devsite-toc>
<div class="devsite-article-body clearfix">
<p></p>
<!-- DO NOT EDIT! Automatically generated file. -->
<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<meta content="tf.compat.v1.nn.raw_rnn" itemprop="name"/>
<meta content="Stable" itemprop="path"/>
</div>
<!-- Insert buttons and diff -->
<table align="left" class="tfo-notebook-buttons tfo-api">
<tbody><tr><td>
<a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/rnn.py#L939-L1259" target="_blank">
<img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png"/>
    View source on GitHub
  </a>
</td></tr></tbody></table>
<p>Creates an <code dir="ltr" translate="no">RNN</code> specified by RNNCell <code dir="ltr" translate="no">cell</code> and loop function <code dir="ltr" translate="no">loop_fn</code>.</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">tf.compat.v1.nn.raw_rnn(
    cell, loop_fn, parallel_iterations=None, swap_memory=False, scope=None
)
</code></pre>
<!-- Placeholder for "Used in" -->
<p><strong>NOTE: This method is still in testing, and the API may change.</strong></p>
<p>This function is a more primitive version of <code dir="ltr" translate="no">dynamic_rnn</code> that provides
more direct access to the inputs each iteration.  It also provides more
control over when to start and finish reading the sequence, and
what to emit for the output.</p>
<p>For example, it can be used to implement the dynamic decoder of a seq2seq
model.</p>
<p>Instead of working with <code dir="ltr" translate="no">Tensor</code> objects, most operations work with
<code dir="ltr" translate="no">TensorArray</code> objects directly.</p>
<p>The operation of <code dir="ltr" translate="no">raw_rnn</code>, in pseudo-code, is basically the following:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">time = tf.constant(0, dtype=tf.int32)
(finished, next_input, initial_state, emit_structure, loop_state) = loop_fn(
    time=time, cell_output=None, cell_state=None, loop_state=None)
emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)
state = initial_state
while not all(finished):
  (output, cell_state) = cell(next_input, state)
  (next_finished, next_input, next_state, emit, loop_state) = loop_fn(
      time=time + 1, cell_output=output, cell_state=cell_state,
      loop_state=loop_state)
  # Emit zeros and copy forward state for minibatch entries that are finished.
  state = tf.where(finished, state, next_state)
  emit = tf.where(finished, tf.zeros_like(emit_structure), emit)
  emit_ta = emit_ta.write(time, emit)
  # If any new minibatch entries are marked as finished, mark these.
  finished = tf.logical_or(finished, next_finished)
  time += 1
return (emit_ta, state, loop_state)
</code></pre>
<p>with the additional properties that output and state may be (possibly nested)
tuples, as determined by <code dir="ltr" translate="no">cell.output_size</code> and <code dir="ltr" translate="no">cell.state_size</code>, and
as a result the final <code dir="ltr" translate="no">state</code> and <code dir="ltr" translate="no">emit_ta</code> may themselves be tuples.</p>
<p>A simple implementation of <code dir="ltr" translate="no">dynamic_rnn</code> via <code dir="ltr" translate="no">raw_rnn</code> looks like this:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">inputs = tf.compat.v1.placeholder(shape=(max_time, batch_size, input_depth),
                        dtype=tf.float32)
sequence_length = tf.compat.v1.placeholder(shape=(batch_size,),
dtype=tf.int32)
inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)
inputs_ta = inputs_ta.unstack(inputs)

cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units)

def loop_fn(time, cell_output, cell_state, loop_state):
  emit_output = cell_output  # == None for time == 0
  if cell_output is None:  # time == 0
    next_cell_state = cell.zero_state(batch_size, tf.float32)
  else:
    next_cell_state = cell_state
  elements_finished = (time &gt;= sequence_length)
  finished = tf.reduce_all(elements_finished)
  next_input = tf.cond(
      finished,
      lambda: tf.zeros([batch_size, input_depth], dtype=tf.float32),
      lambda: inputs_ta.read(time))
  next_loop_state = None
  return (elements_finished, next_input, next_cell_state,
          emit_output, next_loop_state)

outputs_ta, final_state, _ = raw_rnn(cell, loop_fn)
outputs = outputs_ta.stack()
</code></pre>
<h4 id="args">Args:</h4>
<ul>
<li><b><code dir="ltr" translate="no">cell</code></b>: An instance of RNNCell.</li>
<li><b><code dir="ltr" translate="no">loop_fn</code></b>: A callable that takes inputs <code dir="ltr" translate="no">(time, cell_output, cell_state,
loop_state)</code> and returns the tuple <code dir="ltr" translate="no">(finished, next_input,
next_cell_state, emit_output, next_loop_state)</code>. Here <code dir="ltr" translate="no">time</code> is an int32
scalar <code dir="ltr" translate="no">Tensor</code>, <code dir="ltr" translate="no">cell_output</code> is a <code dir="ltr" translate="no">Tensor</code> or (possibly nested) tuple of
tensors as determined by <code dir="ltr" translate="no">cell.output_size</code>, and <code dir="ltr" translate="no">cell_state</code> is a
<code dir="ltr" translate="no">Tensor</code> or (possibly nested) tuple of tensors, as determined by the
<code dir="ltr" translate="no">loop_fn</code> on its first call (and should match <code dir="ltr" translate="no">cell.state_size</code>).
The outputs are: <code dir="ltr" translate="no">finished</code>, a boolean <code dir="ltr" translate="no">Tensor</code> of
shape <code dir="ltr" translate="no">[batch_size]</code>, <code dir="ltr" translate="no">next_input</code>: the next input to feed to <code dir="ltr" translate="no">cell</code>,
<code dir="ltr" translate="no">next_cell_state</code>: the next state to feed to <code dir="ltr" translate="no">cell</code>,
and <code dir="ltr" translate="no">emit_output</code>: the output to store for this iteration.  Note that
<code dir="ltr" translate="no">emit_output</code> should be a <code dir="ltr" translate="no">Tensor</code> or (possibly nested) tuple of tensors
which is aggregated in the <code dir="ltr" translate="no">emit_ta</code> inside the <code dir="ltr" translate="no">while_loop</code>. For the
first call to <code dir="ltr" translate="no">loop_fn</code>, the <code dir="ltr" translate="no">emit_output</code> corresponds to the
<code dir="ltr" translate="no">emit_structure</code> which is then used to determine the size of the
<code dir="ltr" translate="no">zero_tensor</code> for the <code dir="ltr" translate="no">emit_ta</code> (defaults to <code dir="ltr" translate="no">cell.output_size</code>). For
the subsequent calls to the <code dir="ltr" translate="no">loop_fn</code>, the <code dir="ltr" translate="no">emit_output</code> corresponds to
the actual output tensor that is to be aggregated in the <code dir="ltr" translate="no">emit_ta</code>. The
parameter <code dir="ltr" translate="no">cell_state</code> and output <code dir="ltr" translate="no">next_cell_state</code> may be either a
single or (possibly nested) tuple of tensors.  The parameter
<code dir="ltr" translate="no">loop_state</code> and output <code dir="ltr" translate="no">next_loop_state</code> may be either a single or
(possibly nested) tuple of <code dir="ltr" translate="no">Tensor</code> and <code dir="ltr" translate="no">TensorArray</code> objects.  This
last parameter may be ignored by <code dir="ltr" translate="no">loop_fn</code> and the return value may be
<code dir="ltr" translate="no">None</code>.  If it is not <code dir="ltr" translate="no">None</code>, then the <code dir="ltr" translate="no">loop_state</code> will be propagated
through the RNN loop, for use purely by <code dir="ltr" translate="no">loop_fn</code> to keep track of its
own state. The <code dir="ltr" translate="no">next_loop_state</code> parameter returned may be <code dir="ltr" translate="no">None</code>.  The
first call to <code dir="ltr" translate="no">loop_fn</code> will be <code dir="ltr" translate="no">time = 0</code>, <code dir="ltr" translate="no">cell_output = None</code>,
<code dir="ltr" translate="no">cell_state = None</code>, and <code dir="ltr" translate="no">loop_state = None</code>.  For this call: The
<code dir="ltr" translate="no">next_cell_state</code> value should be the value with which to initialize the
cell&#39;s state.  It may be a final state from a previous RNN or it may be
the output of <code dir="ltr" translate="no">cell.zero_state()</code>.  It should be a (possibly nested)
tuple structure of tensors. If <code dir="ltr" translate="no">cell.state_size</code> is an integer, this
must be a <code dir="ltr" translate="no">Tensor</code> of appropriate type and shape <code dir="ltr" translate="no">[batch_size,
cell.state_size]</code>. If <code dir="ltr" translate="no">cell.state_size</code> is a <code dir="ltr" translate="no">TensorShape</code>, this must be
a <code dir="ltr" translate="no">Tensor</code> of appropriate type and shape <code dir="ltr" translate="no">[batch_size] +
cell.state_size</code>. If <code dir="ltr" translate="no">cell.state_size</code> is a (possibly nested) tuple of
ints or <code dir="ltr" translate="no">TensorShape</code>, this will be a tuple having the corresponding
shapes. The <code dir="ltr" translate="no">emit_output</code> value may be either <code dir="ltr" translate="no">None</code> or a (possibly
nested) tuple structure of tensors, e.g., <code dir="ltr" translate="no">(tf.zeros(shape_0,
dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))</code>. If this first
<code dir="ltr" translate="no">emit_output</code> return value is <code dir="ltr" translate="no">None</code>, then the <code dir="ltr" translate="no">emit_ta</code> result of
<code dir="ltr" translate="no">raw_rnn</code> will have the same structure and dtypes as <code dir="ltr" translate="no">cell.output_size</code>.
Otherwise <code dir="ltr" translate="no">emit_ta</code> will have the same structure, shapes (prepended with
a <code dir="ltr" translate="no">batch_size</code> dimension), and dtypes as <code dir="ltr" translate="no">emit_output</code>.  The actual
values returned for <code dir="ltr" translate="no">emit_output</code> at this initializing call are ignored.
Note, this emit structure must be consistent across all time steps.</li>
<li><b><code dir="ltr" translate="no">parallel_iterations</code></b>: (Default: 32).  The number of iterations to run in
parallel.  Those operations which do not have any temporal dependency and
can be run in parallel, will be.  This parameter trades off time for
space.  Values &gt;&gt; 1 use more memory but take less time, while smaller
values use less memory but computations take longer.</li>
<li><b><code dir="ltr" translate="no">swap_memory</code></b>: Transparently swap the tensors produced in forward inference
but needed for back prop from GPU to CPU.  This allows training RNNs which
would typically not fit on a single GPU, with very minimal (or no)
performance penalty.</li>
<li><b><code dir="ltr" translate="no">scope</code></b>: VariableScope for the created subgraph; defaults to &#34;rnn&#34;.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tuple <code dir="ltr" translate="no">(emit_ta, final_state, final_loop_state)</code> where:</p>
<p><code dir="ltr" translate="no">emit_ta</code>: The RNN output <code dir="ltr" translate="no">TensorArray</code>.
   If <code dir="ltr" translate="no">loop_fn</code> returns a (possibly nested) set of Tensors for
   <code dir="ltr" translate="no">emit_output</code> during initialization, (inputs <code dir="ltr" translate="no">time = 0</code>,
   <code dir="ltr" translate="no">cell_output = None</code>, and <code dir="ltr" translate="no">loop_state = None</code>), then <code dir="ltr" translate="no">emit_ta</code> will
   have the same structure, dtypes, and shapes as <code dir="ltr" translate="no">emit_output</code> instead.
   If <code dir="ltr" translate="no">loop_fn</code> returns <code dir="ltr" translate="no">emit_output = None</code> during this call,
   the structure of <code dir="ltr" translate="no">cell.output_size</code> is used:
   If <code dir="ltr" translate="no">cell.output_size</code> is a (possibly nested) tuple of integers
   or <code dir="ltr" translate="no">TensorShape</code> objects, then <code dir="ltr" translate="no">emit_ta</code> will be a tuple having the
   same structure as <code dir="ltr" translate="no">cell.output_size</code>, containing TensorArrays whose
   elements&#39; shapes correspond to the shape data in <code dir="ltr" translate="no">cell.output_size</code>.</p>
<p><code dir="ltr" translate="no">final_state</code>: The final cell state.  If <code dir="ltr" translate="no">cell.state_size</code> is an int, this
  will be shaped <code dir="ltr" translate="no">[batch_size, cell.state_size]</code>.  If it is a
  <code dir="ltr" translate="no">TensorShape</code>, this will be shaped <code dir="ltr" translate="no">[batch_size] + cell.state_size</code>.
  If it is a (possibly nested) tuple of ints or <code dir="ltr" translate="no">TensorShape</code>, this will
  be a tuple having the corresponding shapes.</p>
<p><code dir="ltr" translate="no">final_loop_state</code>: The final loop state as returned by <code dir="ltr" translate="no">loop_fn</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">TypeError</code></b>: If <code dir="ltr" translate="no">cell</code> is not an instance of RNNCell, or <code dir="ltr" translate="no">loop_fn</code> is not
a <code dir="ltr" translate="no">callable</code>.</li>
</ul>
</div>
<devsite-page-rating hover-rating-star="0" position="footer" selected-rating="0">
</devsite-page-rating>
</article>
</article>

</devsite-content>
</main>
<devsite-footer-promos class="devsite-footer">
</devsite-footer-promos>
<devsite-footer-linkboxes class="devsite-footer">

</devsite-footer-linkboxes>
<devsite-footer-utility class="devsite-footer">
<div class="devsite-footer-utility nocontent">

</div>
</devsite-footer-utility>
</section></section>
<devsite-sitemask></devsite-sitemask>
<devsite-snackbar></devsite-snackbar> <devsite-tooltip></devsite-tooltip>
<devsite-heading-link></devsite-heading-link>
<devsite-analytics>


</devsite-analytics>
 
</body></html>