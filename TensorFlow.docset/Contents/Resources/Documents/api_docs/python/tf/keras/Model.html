<!DOCTYPE html><html dir="ltr" lang="en"><head>
<meta content="157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com" name="google-signin-client-id"/>
<meta content="profile email" name="google-signin-scope"/>
<meta content="TensorFlow" property="og:site_name"/>
<meta content="website" property="og:type"/>
<meta content="#ff6f00" name="theme-color"/>
<meta charset="utf-8"/>
<meta content="IE=Edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link crossorigin="use-credentials" href="_pwa/tensorflow/manifest.json" rel="manifest"/>
<link crossorigin="" href="/www.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.gstatic.com" rel="preconnect"/>
<link crossorigin="" href="/fonts.googleapis.com" rel="preconnect"/>
<link href="../../../../main.css" rel="stylesheet"/>

<noscript>

</noscript>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/favicon.png" rel="shortcut icon"/>
<link href="https://www.gstatic.com/devrel-devsite/prod/v3e2dbdc40e7394635e5230ecc02cb28039ea55a5d72db9939d2fb9fc9e16d0ff/tensorflow/images/apple-touch-icon-180x180.png" rel="apple-touch-icon"/><link href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="canonical"/><link href="https://www.tensorflow.org/s/opensearch.xml" rel="search" title="TensorFlow" type="application/opensearchdescription+xml"/>
<title>tf.keras.Model &nbsp;|&nbsp; TensorFlow Core v2.1.0</title>
<meta content="tf.keras.Model &nbsp;|&nbsp; TensorFlow Core v2.1.0" property="og:title"/>
<meta content="https://www.tensorflow.org/api_docs/python/tf/keras/Model" property="og:url"/>
<meta content="en" property="og:locale"/>

</head>
<body class="" layout="docs" pending="" theme="tensorflow-theme" type="reference">
<devsite-progress id="app-progress" type="indeterminate"></devsite-progress>
<section class="devsite-wrapper"> <devsite-book-nav scrollbars="">

</devsite-book-nav>
<section id="gc-wrapper">
<main class="devsite-main-content" has-book-nav="" has-toc="" role="main">
<devsite-toc class="devsite-nav"></devsite-toc>
<devsite-content>
<article class="devsite-article">
<article class="devsite-article-inner"><style>
        /* Styles inlined from /site-assets/css/style.css */
/* override theme */
table img {
  max-width: 100%;
}

/* override var element to differentiate color from comment */
var, var code, var span, .prettyprint var span {
  color: #039be5;
}

/* .devsite-terminal virtualenv prompt */
.tfo-terminal-venv::before {
  content: "(venv) $ " !important;
}

/* .devsite-terminal root prompt */
.tfo-terminal-root::before {
  content: "# " !important;
}

/* .devsite-terminal Windows prompt */
.tfo-terminal-windows::before {
  content: "C:\\> " !important;
}

/* .devsite-terminal Windows prompt w/ virtualenv */
.tfo-terminal-windows-venv::before {
  content: "(venv) C:\\> " !important;
}

.tfo-diff-green-one-level + * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green + * > * {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-green-list + ul > li:first-of-type {
  background: rgba(175, 245, 162, .6)  !important;
}

.tfo-diff-red-one-level + * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red + * > * {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

.tfo-diff-red-list + ul > li:first-of-type {
  background: rgba(255, 230, 230, .6)  !important;
  text-decoration: line-through  !important;
}

devsite-code .tfo-notebook-code-cell-output {
  max-height: 300px;
  overflow: auto;
  background: rgba(255, 247, 237, 1);  /* orange bg to distinguish from input code cells */
}

devsite-code .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(255, 247, 237, .7);  /* orange bg to distinguish from input code cells */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output {
  background: rgba(64, 78, 103, 1);  /* medium slate */
}

devsite-code[dark-code] .tfo-notebook-code-cell-output + .devsite-code-buttons-container button {
  background: rgba(64, 78, 103, .7);  /* medium slate */
}

/* override default table styles for notebook buttons */
.devsite-table-wrapper .tfo-notebook-buttons {
  display: inline-block;
  margin-left: 3px;
  width: auto;
}

.tfo-notebook-buttons td {
  padding-left: 0;
  padding-right: 20px;
}

.tfo-notebook-buttons a,
.tfo-notebook-buttons :link,
.tfo-notebook-buttons :visited {
  border-radius: 8px;
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 1px 3px 1px rgba(60, 64, 67, .15);
  color: #202124;
  padding: 12px 24px;
  transition: box-shadow 0.2s;
}

.tfo-notebook-buttons a:hover,
.tfo-notebook-buttons a:focus {
  box-shadow: 0 1px 2px 0 rgba(60, 64, 67, .3), 0 2px 6px 2px rgba(60, 64, 67, .15);
}

.tfo-notebook-buttons tr {
  background: 0;
  border: 0;
}

/* on rendered notebook page,
   remove link to webpage since we're already here */
.tfo-notebook-buttons:not(.tfo-api) td:first-child {
  display: none;
}

.tfo-notebook-buttons td > a {
  -webkit-box-align: center;
  -ms-flex-align: center;
  align-items: center;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
}

.tfo-notebook-buttons td > a > img {
  margin-right: 8px;
}

/* landing pages */

.tfo-landing-row-item-inset-white {
  background-color: #fff;
  padding: 32px;
}

.tfo-landing-row-item-inset-white ol,
.tfo-landing-row-item-inset-white ul {
  padding-left: 20px;
}

/* colab callout button */
.colab-callout-row devsite-code {
  border-radius: 8px 8px 0 0;
  box-shadow: none;
}

.colab-callout-footer {
  background: #e3e4e7;
  border-radius: 0 0 8px 8px;
  color: #37474f;
  padding: 20px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer {
  background: #3f4f66;
}


.colab-callout-footer > .button {
  margin-top: 4px;
  color: #ff5c00;
}

.colab-callout-footer > a > span {
  padding-top: 10px;
  vertical-align: middle;
  color: #37474f;
  padding-left: 10px;
  padding-right: 10px;
  font-size: 14px;
}

.colab-callout-row devsite-code[dark-code] + .colab-callout-footer > a > span {
  color: #fff;
}

a.colab-button {
  background: rgba(255, 255, 255, .75);
  border: solid 1px rgba(0, 0, 0, .08);
  border-bottom-color: rgba(0, 0, 0, .15);
  border-radius: 4px;
  color: #aaa;
  display: inline-block;
  font-size: 11px !important;
  font-weight: 300;
  line-height: 16px;
  padding: 4px 8px;
  text-decoration: none;
  text-transform: uppercase;
}

a.colab-button:hover {
  background: white;
  border-color: rgba(0, 0, 0, .2);
  color: #666;
}

a.colab-button span {
  background: url(/images/colab_logo_button.svg) no-repeat 1px 1px / 20px;
  border-radius: 4px;
  display: inline-block;
  padding-left: 24px;
  text-decoration: none;
}

@media screen and (max-width: 600px) {
  .tfo-notebook-buttons td {
    display: block;
  }
}

/* guide and tutorials landing page cards and sections */

.tfo-landing-page-card {
  padding: 16px;
  box-shadow: 0 0 36px rgba(0,0,0,0.1);
  border-radius: 10px;
}

/* Page section headings */
.tfo-landing-page-heading h2, h2.tfo-landing-page-heading {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 30px;
  font-weight: 700;
  line-height: 40px;
}

/* Item title headings */
.tfo-landing-page-heading h3, h3.tfo-landing-page-heading,
.tfo-landing-page-card h3, h3.tfo-landing-page-card {
  font-family: "Google Sans", sans-serif;
  color: #425066;
  font-size: 20px;
  font-weight: 500;
  line-height: 26px;
}

/* List of tutorials notebooks for subsites */
.tfo-landing-page-resources-ul {
  padding-left: 15px
}

.tfo-landing-page-resources-ul > li {
  margin: 6px 0;
}

/* Temporary fix to hide product description in header on landing pages */
devsite-header .devsite-product-description {
  display: none;
}

        </style> <div class="devsite-banner devsite-banner-announcement">
<div class="devsite-banner-message">
<div class="devsite-banner-message-text">
            Missed TensorFlow Dev Summit? Check out the video playlist. <a class="button button-primary button-tfo-announcement" href="https://goo.gle/TFDS20AllSessions">Watch recordings</a>
</div>
</div>
</div>
<div class="devsite-article-meta">
<ul class="devsite-breadcrumb-list">
<li class="devsite-breadcrumb-item">
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="1" href="">
            TensorFlow
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="2" href="api">
            API
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="3" href="api_docs">
            TensorFlow Core v2.1.0
      
  </a>
</li>
<li class="devsite-breadcrumb-item">
<div aria-hidden="true" class="devsite-breadcrumb-guillemet material-icons"></div>
<a class="devsite-breadcrumb-link gc-analytics-event" data-category="Site-Wide Custom Events" data-label="Breadcrumbs" data-value="4" href="api_docs/python/tf">
            Python
      
  </a>
</li>
</ul>
<devsite-page-rating hover-rating-star="0" position="header" selected-rating="0">
</devsite-page-rating>
</div>
<a class="dashingAutolink" name="autolink-1564"></a><a class="dashAnchor" name="//apple_ref/cpp/Function/tf.keras.Model"></a><h1 class="dash-function">tf.keras.Model</h1>
<devsite-toc class="devsite-nav" devsite-toc-embedded="">
</devsite-toc>
<div class="devsite-article-body clearfix">
<p></p>
<!-- DO NOT EDIT! Automatically generated file. -->
<div itemscope="" itemtype="http://developers.google.com/ReferenceObject">
<meta content="tf.keras.Model" itemprop="name"/>
<meta content="Stable" itemprop="path"/>
<meta content="__init__" itemprop="property"/>
<meta content="compile" itemprop="property"/>
<meta content="evaluate" itemprop="property"/>
<meta content="evaluate_generator" itemprop="property"/>
<meta content="fit" itemprop="property"/>
<meta content="fit_generator" itemprop="property"/>
<meta content="get_layer" itemprop="property"/>
<meta content="load_weights" itemprop="property"/>
<meta content="predict" itemprop="property"/>
<meta content="predict_generator" itemprop="property"/>
<meta content="predict_on_batch" itemprop="property"/>
<meta content="reset_metrics" itemprop="property"/>
<meta content="reset_states" itemprop="property"/>
<meta content="save" itemprop="property"/>
<meta content="save_weights" itemprop="property"/>
<meta content="summary" itemprop="property"/>
<meta content="test_on_batch" itemprop="property"/>
<meta content="to_json" itemprop="property"/>
<meta content="to_yaml" itemprop="property"/>
<meta content="train_on_batch" itemprop="property"/>
</div>
<p><devsite-nav-buttons name="version" param="reset">
<button default="" value="stable">See Stable</button>
<button value="nightly">See Nightly</button>
</devsite-nav-buttons></p>
<!-- Stable -->
<table align="left" class="tfo-notebook-buttons tfo-api">
<tbody><tr><td>
<a href="versions/r1.15/api_docs/python/tf/keras/Model" target="_blank">
<img src="https://www.tensorflow.org/images/tf_logo_32px.png"/>
  TensorFlow 1 version</a>
</td>
<td>
<a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L81-L2865" target="_blank">
<img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png"/>
    View source on GitHub
  </a>
</td></tr></tbody></table>
<p><code dir="ltr" translate="no">Model</code> groups layers into an object with training and inference features.</p>
<section class="expandable">
<h4 class="showalways">View aliases</h4>
<p>
<b>Main aliases</b>
</p><p><a href="api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.keras.models.Model</code></a></p>
<b>Compat aliases for migration</b>
<p>See
<a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for
more details.</p>
<p><a href="api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.compat.v1.keras.Model</code></a>, <a href="api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.compat.v1.keras.models.Model</code></a></p>
</section>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">tf.keras.Model(
    *args, **kwargs
)
</code></pre>
<h3>Used in the notebooks</h3>
<table class="vertical-rules">
<thead>
<tr>
<th>Used in the guide</th>
<th>Used in the tutorials</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<ul>
<li><a href="https://www.tensorflow.org/guide/keras/functional">The Keras functional API</a></li>
<li><a href="https://www.tensorflow.org/guide/keras/train_and_evaluate">Train and evaluate with Keras</a></li>
<li><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Writing custom layers and models with Keras</a></li>
<li><a href="https://www.tensorflow.org/guide/keras/save_and_serialize">Save and serialize models with Keras</a></li>
<li><a href="https://www.tensorflow.org/guide/keras/rnn">Recurrent Neural Networks (RNN) with Keras</a></li>
</ul>
</td>
<td>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/generative/pix2pix">Pix2Pix</a></li>
<li><a href="https://www.tensorflow.org/tutorials/images/segmentation">Image segmentation</a></li>
<li><a href="https://www.tensorflow.org/tutorials/distribute/save_and_load">Save and load a model using a distribution strategy</a></li>
<li><a href="https://www.tensorflow.org/tutorials/generative/deepdream">DeepDream</a></li>
<li><a href="https://www.tensorflow.org/tutorials/generative/style_transfer">Neural style transfer</a></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>There are two ways to instantiate a <code dir="ltr" translate="no">Model</code>:</p>
<p>1 - With the &#34;functional API&#34;, where you start from <code dir="ltr" translate="no">Input</code>,
you chain layer calls to specify the model&#39;s forward pass,
and finally you create your model from inputs and outputs:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
</code></pre>
<p>2 - By subclassing the <code dir="ltr" translate="no">Model</code> class: in that case, you should define your
layers in <code dir="ltr" translate="no">__init__</code> and you should implement the model&#39;s forward pass
in <code dir="ltr" translate="no">call</code>.</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super(MyModel, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)

  def call(self, inputs):
    x = self.dense1(inputs)
    return self.dense2(x)

model = MyModel()
</code></pre>
<p>If you subclass <code dir="ltr" translate="no">Model</code>, you can optionally have
a <code dir="ltr" translate="no">training</code> argument (boolean) in <code dir="ltr" translate="no">call</code>, which you can use to specify
a different behavior in training and inference:</p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super(MyModel, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
    self.dropout = tf.keras.layers.Dropout(0.5)

  def call(self, inputs, training=False):
    x = self.dense1(inputs)
    if training:
      x = self.dropout(x, training=training)
    return self.dense2(x)

model = MyModel()
</code></pre>
<h4 id="attributes_2">Attributes:</h4>
<ul>
<li><b><code dir="ltr" translate="no">layers</code></b></li>
<li><b><code dir="ltr" translate="no">metrics_names</code></b>:   Returns the model&#39;s display labels for all outputs.</li>
<li><p><b><code dir="ltr" translate="no">run_eagerly</code></b>:   Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become easier
for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p></li>
<li><p><b><code dir="ltr" translate="no">sample_weights</code></b></p></li>
<li><p><b><code dir="ltr" translate="no">state_updates</code></b>:   Returns the <code dir="ltr" translate="no">updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer&#39;s internal state
during prediction.</p></li>
</ul>
<h2 id="methods_2">Methods</h2>
<h3 id="compile"><code dir="ltr" translate="no">compile</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L236-L471" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">compile(
    optimizer=&#39;rmsprop&#39;, loss=None, metrics=None, loss_weights=None,
    sample_weight_mode=None, weighted_metrics=None, target_tensors=None,
    distribute=None, **kwargs
)
</code></pre>
<p>Configures the model for training.</p>
<h4 id="arguments_21">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">optimizer</code></b>: String (name of optimizer) or optimizer instance.
See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"><code dir="ltr" translate="no">tf.keras.optimizers</code></a>.</li>
<li><b><code dir="ltr" translate="no">loss</code></b>: String (name of objective function), objective function or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss"><code dir="ltr" translate="no">tf.keras.losses.Loss</code></a> instance. See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses"><code dir="ltr" translate="no">tf.keras.losses</code></a>. An objective
function is any callable with the signature
<code dir="ltr" translate="no">scalar_loss = fn(y_true, y_pred)</code>. If the model has multiple
outputs, you can use a different loss on each output by passing a
dictionary or a list of losses. The loss value that will be
minimized by the model will then be the sum of all individual
losses.</li>
<li><b><code dir="ltr" translate="no">metrics</code></b>: List of metrics to be evaluated by the model during training
and testing. Typically you will use <code dir="ltr" translate="no">metrics=[&#39;accuracy&#39;]</code>.
To specify different metrics for different outputs of a
multi-output model, you could also pass a dictionary, such as
<code dir="ltr" translate="no">metrics={&#39;output_a&#39;: &#39;accuracy&#39;, &#39;output_b&#39;: [&#39;accuracy&#39;, &#39;mse&#39;]}</code>.
You can also pass a list (len = len(outputs)) of lists of metrics
such as <code dir="ltr" translate="no">metrics=[[&#39;accuracy&#39;], [&#39;accuracy&#39;, &#39;mse&#39;]]</code> or
<code dir="ltr" translate="no">metrics=[&#39;accuracy&#39;, [&#39;accuracy&#39;, &#39;mse&#39;]]</code>.</li>
<li><b><code dir="ltr" translate="no">loss_weights</code></b>: Optional list or dictionary specifying scalar
coefficients (Python floats) to weight the loss contributions
of different model outputs.
The loss value that will be minimized by the model
will then be the <em>weighted sum</em> of all individual losses,
weighted by the <code dir="ltr" translate="no">loss_weights</code> coefficients.
If a list, it is expected to have a 1:1 mapping
to the model&#39;s outputs. If a tensor, it is expected to map
output names (strings) to scalar coefficients.</li>
<li><b><code dir="ltr" translate="no">sample_weight_mode</code></b>: If you need to do timestep-wise
sample weighting (2D weights), set this to <code dir="ltr" translate="no">&#34;temporal&#34;</code>.
<code dir="ltr" translate="no">None</code> defaults to sample-wise weights (1D).
If the model has multiple outputs, you can use a different
<code dir="ltr" translate="no">sample_weight_mode</code> on each output by passing a
dictionary or a list of modes.</li>
<li><b><code dir="ltr" translate="no">weighted_metrics</code></b>: List of metrics to be evaluated and weighted
by sample_weight or class_weight during training and testing.</li>
<li><b><code dir="ltr" translate="no">target_tensors</code></b>: By default, Keras will create placeholders for the
model&#39;s target, which will be fed with the target data during
training. If instead you would like to use your own
target tensors (in turn, Keras will not expect external
Numpy data for these targets at training time), you
can specify them via the <code dir="ltr" translate="no">target_tensors</code> argument. It can be
a single tensor (for a single-output model), a list of tensors,
or a dict mapping output names to target tensors.</li>
<li><b><code dir="ltr" translate="no">distribute</code></b>: NOT SUPPORTED IN TF 2.0, please create and compile the
model under distribution strategy scope instead of passing it to
compile.</li>
<li><b><code dir="ltr" translate="no">**kwargs</code></b>: Any additional arguments.</li>
</ul>
<h4 id="raises_15">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of invalid arguments for
<code dir="ltr" translate="no">optimizer</code>, <code dir="ltr" translate="no">loss</code>, <code dir="ltr" translate="no">metrics</code> or <code dir="ltr" translate="no">sample_weight_mode</code>.</li>
</ul>
<h3 id="evaluate"><code dir="ltr" translate="no">evaluate</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L821-L930" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">evaluate(
    x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None,
    callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False
)
</code></pre>
<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches.</p>
<h4 id="arguments_22">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input data. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset.</li>
<li>A generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance.
A more detailed description of unpacking behavior for iterator types
(Dataset, generator, Sequence) is given in the <code dir="ltr" translate="no">Unpacking behavior
for iterator-like inputs</code> section of <code dir="ltr" translate="no">Model.fit</code>.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">y</code></b>: Target data. Like the input data <code dir="ltr" translate="no">x</code>,
it could be either Numpy array(s) or TensorFlow tensor(s).
It should be consistent with <code dir="ltr" translate="no">x</code> (you cannot have Numpy inputs and
tensor targets, or inversely).
If <code dir="ltr" translate="no">x</code> is a dataset, generator or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance, <code dir="ltr" translate="no">y</code> should not be specified (since
targets will be obtained from the iterator/dataset).</li>
<li><b><code dir="ltr" translate="no">batch_size</code></b>: Integer or <code dir="ltr" translate="no">None</code>.
Number of samples per gradient update.
If unspecified, <code dir="ltr" translate="no">batch_size</code> will default to 32.
Do not specify the <code dir="ltr" translate="no">batch_size</code> if your data is in the
form of symbolic tensors, dataset,
generators, or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instances (since they generate
batches).</li>
<li><b><code dir="ltr" translate="no">verbose</code></b>: 0 or 1. Verbosity mode.
0 = silent, 1 = progress bar.</li>
<li><b><code dir="ltr" translate="no">sample_weight</code></b>: Optional Numpy array of weights for
the test samples, used for weighting the loss function.
You can either pass a flat (1D)
Numpy array with the same length as the input samples
(1:1 mapping between weights and samples),
or in the case of temporal data,
you can pass a 2D array with shape
<code dir="ltr" translate="no">(samples, sequence_length)</code>,
to apply a different weight to every timestep of every sample.
In this case you should make sure to specify
<code dir="ltr" translate="no">sample_weight_mode=&#34;temporal&#34;</code> in <code dir="ltr" translate="no">compile()</code>. This argument is not
supported when <code dir="ltr" translate="no">x</code> is a dataset, instead pass
sample weights as the third element of <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">steps</code></b>: Integer or <code dir="ltr" translate="no">None</code>.
Total number of steps (batches of samples)
before declaring the evaluation round finished.
Ignored with the default value of <code dir="ltr" translate="no">None</code>.
If x is a <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset and <code dir="ltr" translate="no">steps</code> is
None, &#39;evaluate&#39; will run until the dataset is exhausted.
This argument is not supported with array inputs.</li>
<li><b><code dir="ltr" translate="no">callbacks</code></b>: List of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback"><code dir="ltr" translate="no">keras.callbacks.Callback</code></a> instances.
List of callbacks to apply during evaluation.
See <a href="api_docs/python/tf/keras/callbacks">callbacks</a>.</li>
<li><b><code dir="ltr" translate="no">max_queue_size</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a>
input only. Maximum size for the generator queue.
If unspecified, <code dir="ltr" translate="no">max_queue_size</code> will default to 10.</li>
<li><b><code dir="ltr" translate="no">workers</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input
only. Maximum number of processes to spin up when using
process-based threading. If unspecified, <code dir="ltr" translate="no">workers</code> will default
to 1. If 0, will execute the generator on the main thread.</li>
<li><b><code dir="ltr" translate="no">use_multiprocessing</code></b>: Boolean. Used for generator or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input only. If <code dir="ltr" translate="no">True</code>, use process-based
threading. If unspecified, <code dir="ltr" translate="no">use_multiprocessing</code> will default to
<code dir="ltr" translate="no">False</code>. Note that because this implementation relies on
multiprocessing, you should not pass non-picklable arguments to
the generator as they can&#39;t be passed easily to children processes.</li>
</ul>
<p>See the discussion of <code dir="ltr" translate="no">Unpacking behavior for iterator-like inputs</code> for
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"><code dir="ltr" translate="no">Model.fit</code></a>.</p>
<h4 id="returns_17">Returns:</h4>
<p>Scalar test loss (if the model has a single output and no metrics)
or list of scalars (if the model has multiple outputs
and/or metrics). The attribute <code dir="ltr" translate="no">model.metrics_names</code> will give you
the display labels for the scalar outputs.</p>
<h4 id="raises_16">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: in case of invalid arguments.</li>
</ul>
<h3 id="evaluate_generator"><code dir="ltr" translate="no">evaluate_generator</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1308-L1334" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">evaluate_generator(
    generator, steps=None, callbacks=None, max_queue_size=10, workers=1,
    use_multiprocessing=False, verbose=0
)
</code></pre>
<p>Evaluates the model on a data generator. (deprecated)</p>
<aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use Model.evaluate, which supports generators.</span></aside>
<h4 id="deprecated_4">DEPRECATED:</h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate"><code dir="ltr" translate="no">Model.evaluate</code></a> now supports generators, so there is no longer any need
to use this endpoint.</p>
<h3 id="fit"><code dir="ltr" translate="no">fit</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L596-L819" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">fit(
    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,
    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,
    sample_weight=None, initial_epoch=0, steps_per_epoch=None,
    validation_steps=None, validation_freq=1, max_queue_size=10, workers=1,
    use_multiprocessing=False, **kwargs
)
</code></pre>
<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<h4 id="arguments_23">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input data. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset. Should return a tuple
of either <code dir="ltr" translate="no">(inputs, targets)</code> or
<code dir="ltr" translate="no">(inputs, targets, sample_weights)</code>.</li>
<li>A generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> returning <code dir="ltr" translate="no">(inputs, targets)</code>
or <code dir="ltr" translate="no">(inputs, targets, sample weights)</code>.
A more detailed description of unpacking behavior for iterator types
(Dataset, generator, Sequence) is given below.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">y</code></b>: Target data. Like the input data <code dir="ltr" translate="no">x</code>,
it could be either Numpy array(s) or TensorFlow tensor(s).
It should be consistent with <code dir="ltr" translate="no">x</code> (you cannot have Numpy inputs and
tensor targets, or inversely). If <code dir="ltr" translate="no">x</code> is a dataset, generator,
or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance, <code dir="ltr" translate="no">y</code> should
not be specified (since targets will be obtained from <code dir="ltr" translate="no">x</code>).</li>
<li><b><code dir="ltr" translate="no">batch_size</code></b>: Integer or <code dir="ltr" translate="no">None</code>.
Number of samples per gradient update.
If unspecified, <code dir="ltr" translate="no">batch_size</code> will default to 32.
Do not specify the <code dir="ltr" translate="no">batch_size</code> if your data is in the
form of symbolic tensors, datasets,
generators, or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instances (since they generate
batches).</li>
<li><b><code dir="ltr" translate="no">epochs</code></b>: Integer. Number of epochs to train the model.
An epoch is an iteration over the entire <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code>
data provided.
Note that in conjunction with <code dir="ltr" translate="no">initial_epoch</code>,
<code dir="ltr" translate="no">epochs</code> is to be understood as &#34;final epoch&#34;.
The model is not trained for a number of iterations
given by <code dir="ltr" translate="no">epochs</code>, but merely until the epoch
of index <code dir="ltr" translate="no">epochs</code> is reached.</li>
<li><b><code dir="ltr" translate="no">verbose</code></b>: 0, 1, or 2. Verbosity mode.
0 = silent, 1 = progress bar, 2 = one line per epoch.
Note that the progress bar is not particularly useful when
logged to a file, so verbose=2 is recommended when not running
interactively (eg, in a production environment).</li>
<li><b><code dir="ltr" translate="no">callbacks</code></b>: List of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback"><code dir="ltr" translate="no">keras.callbacks.Callback</code></a> instances.
List of callbacks to apply during training.
See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"><code dir="ltr" translate="no">tf.keras.callbacks</code></a>.</li>
<li><b><code dir="ltr" translate="no">validation_split</code></b>: Float between 0 and 1.
Fraction of the training data to be used as validation data.
The model will set apart this fraction of the training data,
will not train on it, and will evaluate
the loss and any model metrics
on this data at the end of each epoch.
The validation data is selected from the last samples
in the <code dir="ltr" translate="no">x</code> and <code dir="ltr" translate="no">y</code> data provided, before shuffling. This argument is
not supported when <code dir="ltr" translate="no">x</code> is a dataset, generator or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance.</li>
<li><b><code dir="ltr" translate="no">validation_data</code></b>: Data on which to evaluate
the loss and any model metrics at the end of each epoch.
The model will not be trained on this data.
<code dir="ltr" translate="no">validation_data</code> will override <code dir="ltr" translate="no">validation_split</code>.
<code dir="ltr" translate="no">validation_data</code> could be:
<ul>
<li>tuple <code dir="ltr" translate="no">(x_val, y_val)</code> of Numpy arrays or tensors</li>
<li>tuple <code dir="ltr" translate="no">(x_val, y_val, val_sample_weights)</code> of Numpy arrays</li>
<li>dataset
For the first two cases, <code dir="ltr" translate="no">batch_size</code> must be provided.
For the last case, <code dir="ltr" translate="no">validation_steps</code> could be provided.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">shuffle</code></b>: Boolean (whether to shuffle the training data
before each epoch) or str (for &#39;batch&#39;).
&#39;batch&#39; is a special option for dealing with the
limitations of HDF5 data; it shuffles in batch-sized chunks.
Has no effect when <code dir="ltr" translate="no">steps_per_epoch</code> is not <code dir="ltr" translate="no">None</code>.</li>
<li><b><code dir="ltr" translate="no">class_weight</code></b>: Optional dictionary mapping class indices (integers)
to a weight (float) value, used for weighting the loss function
(during training only).
This can be useful to tell the model to
&#34;pay more attention&#34; to samples from
an under-represented class.</li>
<li><b><code dir="ltr" translate="no">sample_weight</code></b>: Optional Numpy array of weights for
the training samples, used for weighting the loss function
(during training only). You can either pass a flat (1D)
Numpy array with the same length as the input samples
(1:1 mapping between weights and samples),
or in the case of temporal data,
you can pass a 2D array with shape
<code dir="ltr" translate="no">(samples, sequence_length)</code>,
to apply a different weight to every timestep of every sample.
In this case you should make sure to specify
<code dir="ltr" translate="no">sample_weight_mode=&#34;temporal&#34;</code> in <code dir="ltr" translate="no">compile()</code>. This argument is not
supported when <code dir="ltr" translate="no">x</code> is a dataset, generator, or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance, instead provide the sample_weights
as the third element of <code dir="ltr" translate="no">x</code>.</li>
<li><b><code dir="ltr" translate="no">initial_epoch</code></b>: Integer.
Epoch at which to start training
(useful for resuming a previous training run).</li>
<li><b><code dir="ltr" translate="no">steps_per_epoch</code></b>: Integer or <code dir="ltr" translate="no">None</code>.
Total number of steps (batches of samples)
before declaring one epoch finished and starting the
next epoch. When training with input tensors such as
TensorFlow data tensors, the default <code dir="ltr" translate="no">None</code> is equal to
the number of samples in your dataset divided by
the batch size, or 1 if that cannot be determined. If x is a
<a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset, and &#39;steps_per_epoch&#39;
is None, the epoch will run until the input dataset is exhausted.
This argument is not supported with array inputs.</li>
<li><b><code dir="ltr" translate="no">validation_steps</code></b>: Only relevant if <code dir="ltr" translate="no">validation_data</code> is provided and
is a <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset. Total number of steps (batches of
samples) to draw before stopping when performing validation
at the end of every epoch. If &#39;validation_steps&#39; is None, validation
will run until the <code dir="ltr" translate="no">validation_data</code> dataset is exhausted. In the
case of a infinite dataset, it will run into a infinite loop.
If &#39;validation_steps&#39; is specified and only part of the dataset
will be consumed, the evaluation will start from the beginning of
the dataset at each epoch. This ensures that the same validation
samples are used every time.</li>
<li><b><code dir="ltr" translate="no">validation_freq</code></b>: Only relevant if validation data is provided. Integer
or <code dir="ltr" translate="no">collections_abc.Container</code> instance (e.g. list, tuple, etc.).
If an integer, specifies how many training epochs to run before a
new validation run is performed, e.g. <code dir="ltr" translate="no">validation_freq=2</code> runs
validation every 2 epochs. If a Container, specifies the epochs on
which to run validation, e.g. <code dir="ltr" translate="no">validation_freq=[1, 2, 10]</code> runs
validation at the end of the 1st, 2nd, and 10th epochs.</li>
<li><b><code dir="ltr" translate="no">max_queue_size</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a>
input only. Maximum size for the generator queue.
If unspecified, <code dir="ltr" translate="no">max_queue_size</code> will default to 10.</li>
<li><b><code dir="ltr" translate="no">workers</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input
only. Maximum number of processes to spin up
when using process-based threading. If unspecified, <code dir="ltr" translate="no">workers</code>
will default to 1. If 0, will execute the generator on the main
thread.</li>
<li><b><code dir="ltr" translate="no">use_multiprocessing</code></b>: Boolean. Used for generator or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input only. If <code dir="ltr" translate="no">True</code>, use process-based
threading. If unspecified, <code dir="ltr" translate="no">use_multiprocessing</code> will default to
<code dir="ltr" translate="no">False</code>. Note that because this implementation relies on
multiprocessing, you should not pass non-picklable arguments to
the generator as they can&#39;t be passed easily to children processes.</li>
<li><b><code dir="ltr" translate="no">**kwargs</code></b>: Used for backwards compatibility.</li>
</ul>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code dir="ltr" translate="no">x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code dir="ltr" translate="no">({&#34;x0&#34;: x0, &#34;x1&#34;: x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code dir="ltr" translate="no">namedtuple(&#34;example_tuple&#34;, [&#34;y&#34;, &#34;x&#34;])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code dir="ltr" translate="no">namedtuple(&#34;other_tuple&#34;, [&#34;x&#34;, &#34;y&#34;, &#34;z&#34;])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code dir="ltr" translate="no">x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<h4 id="returns_18">Returns:</h4>
<p>A <code dir="ltr" translate="no">History</code> object. Its <code dir="ltr" translate="no">History.history</code> attribute is
a record of training loss values and metrics values
at successive epochs, as well as validation loss values
and validation metrics values (if applicable).</p>
<h4 id="raises_17">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">RuntimeError</code></b>: If the model was never compiled.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of mismatch between the provided input data
and what the model expects.</li>
</ul>
<h3 id="fit_generator"><code dir="ltr" translate="no">fit_generator</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1268-L1306" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">fit_generator(
    generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None,
    validation_data=None, validation_steps=None, validation_freq=1,
    class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False,
    shuffle=True, initial_epoch=0
)
</code></pre>
<p>Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)</p>
<aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.</span></aside>
<h4 id="deprecated_5">DEPRECATED:</h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"><code dir="ltr" translate="no">Model.fit</code></a> now supports generators, so there is no longer any need to use
this endpoint.</p>
<h3 id="get_layer"><code dir="ltr" translate="no">get_layer</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L517-L548" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">get_layer(
    name=None, index=None
)
</code></pre>
<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code dir="ltr" translate="no">name</code> and <code dir="ltr" translate="no">index</code> are both provided, <code dir="ltr" translate="no">index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<h4 id="arguments_24">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">name</code></b>: String, name of layer.</li>
<li><b><code dir="ltr" translate="no">index</code></b>: Integer, index of layer.</li>
</ul>
<h4 id="returns_19">Returns:</h4>
<p>A layer instance.</p>
<h4 id="raises_18">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of invalid layer name or index.</li>
</ul>
<h3 id="load_weights"><code dir="ltr" translate="no">load_weights</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L183-L234" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">load_weights(
    filepath, by_name=False, skip_mismatch=False
)
</code></pre>
<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code dir="ltr" translate="no">by_name</code> is False weights are loaded based on the network&#39;s
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don&#39;t have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don&#39;t have weights.</p>
<p>If <code dir="ltr" translate="no">by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code dir="ltr" translate="no">by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.keras.Model</code></a>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code dir="ltr" translate="no">Model</code>&#39;s constructor.</p>
<h4 id="arguments_25">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">filepath</code></b>: String, path to the weights file to load. For weight files in
TensorFlow format, this is the file prefix (the same as was passed
to <code dir="ltr" translate="no">save_weights</code>).</li>
<li><b><code dir="ltr" translate="no">by_name</code></b>: Boolean, whether to load weights by name or by topological
order. Only topological loading is supported for weight files in
TensorFlow format.</li>
<li><b><code dir="ltr" translate="no">skip_mismatch</code></b>: Boolean, whether to skip loading of layers where there is
a mismatch in the number of weights, or a mismatch in the shape of
the weight (only valid when <code dir="ltr" translate="no">by_name=True</code>).</li>
</ul>
<h4 id="returns_20">Returns:</h4>
<p>When loading a weight file in TensorFlow format, returns the same status
object as <a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restore"><code dir="ltr" translate="no">tf.train.Checkpoint.restore</code></a>. When graph building, restore
ops are run automatically as soon as the network is built (on first call
for user-defined classes inheriting from <code dir="ltr" translate="no">Model</code>, immediately if it is
already built).</p>
<p>When loading weights in HDF5 format, returns <code dir="ltr" translate="no">None</code>.</p>
<h4 id="raises_19">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ImportError</code></b>: If h5py is not available and the weight file is in HDF5
format.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: If <code dir="ltr" translate="no">skip_mismatch</code> is set to <code dir="ltr" translate="no">True</code> when <code dir="ltr" translate="no">by_name</code> is
<code dir="ltr" translate="no">False</code>.</li>
</ul>
<h3 id="predict"><code dir="ltr" translate="no">predict</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L932-L1013" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">predict(
    x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,
    workers=1, use_multiprocessing=False
)
</code></pre>
<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches.</p>
<h4 id="arguments_26">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input samples. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset.</li>
<li>A generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instance.
A more detailed description of unpacking behavior for iterator types
(Dataset, generator, Sequence) is given in the <code dir="ltr" translate="no">Unpacking behavior
for iterator-like inputs</code> section of <code dir="ltr" translate="no">Model.fit</code>.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">batch_size</code></b>: Integer or <code dir="ltr" translate="no">None</code>.
Number of samples per gradient update.
If unspecified, <code dir="ltr" translate="no">batch_size</code> will default to 32.
Do not specify the <code dir="ltr" translate="no">batch_size</code> if your data is in the
form of symbolic tensors, dataset,
generators, or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> instances (since they generate
batches).</li>
<li><b><code dir="ltr" translate="no">verbose</code></b>: Verbosity mode, 0 or 1.</li>
<li><b><code dir="ltr" translate="no">steps</code></b>: Total number of steps (batches of samples)
before declaring the prediction round finished.
Ignored with the default value of <code dir="ltr" translate="no">None</code>. If x is a <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a>
dataset and <code dir="ltr" translate="no">steps</code> is None, <code dir="ltr" translate="no">predict</code> will
run until the input dataset is exhausted.</li>
<li><b><code dir="ltr" translate="no">callbacks</code></b>: List of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback"><code dir="ltr" translate="no">keras.callbacks.Callback</code></a> instances.
List of callbacks to apply during prediction.
See <a href="api_docs/python/tf/keras/callbacks">callbacks</a>.</li>
<li><b><code dir="ltr" translate="no">max_queue_size</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a>
input only. Maximum size for the generator queue.
If unspecified, <code dir="ltr" translate="no">max_queue_size</code> will default to 10.</li>
<li><b><code dir="ltr" translate="no">workers</code></b>: Integer. Used for generator or <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input
only. Maximum number of processes to spin up when using
process-based threading. If unspecified, <code dir="ltr" translate="no">workers</code> will default
to 1. If 0, will execute the generator on the main thread.</li>
<li><b><code dir="ltr" translate="no">use_multiprocessing</code></b>: Boolean. Used for generator or
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code dir="ltr" translate="no">keras.utils.Sequence</code></a> input only. If <code dir="ltr" translate="no">True</code>, use process-based
threading. If unspecified, <code dir="ltr" translate="no">use_multiprocessing</code> will default to
<code dir="ltr" translate="no">False</code>. Note that because this implementation relies on
multiprocessing, you should not pass non-picklable arguments to
the generator as they can&#39;t be passed easily to children processes.</li>
</ul>
<p>See the discussion of <code dir="ltr" translate="no">Unpacking behavior for iterator-like inputs</code> for
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"><code dir="ltr" translate="no">Model.fit</code></a>. Note that Model.predict uses the same interpretation rules as
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"><code dir="ltr" translate="no">Model.fit</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate"><code dir="ltr" translate="no">Model.evaluate</code></a>, so inputs must be unambiguous for all
three methods.</p>
<h4 id="returns_21">Returns:</h4>
<p>Numpy array(s) of predictions.</p>
<h4 id="raises_20">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of mismatch between the provided
input data and the model&#39;s expectations,
or in case a stateful model receives a number of samples
that is not a multiple of the batch size.</li>
</ul>
<h3 id="predict_generator"><code dir="ltr" translate="no">predict_generator</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1336-L1360" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">predict_generator(
    generator, steps=None, callbacks=None, max_queue_size=10, workers=1,
    use_multiprocessing=False, verbose=0
)
</code></pre>
<p>Generates predictions for the input samples from a data generator. (deprecated)</p>
<aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use Model.predict, which supports generators.</span></aside>
<h4 id="deprecated_6">DEPRECATED:</h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict"><code dir="ltr" translate="no">Model.predict</code></a> now supports generators, so there is no longer any need
to use this endpoint.</p>
<h3 id="predict_on_batch"><code dir="ltr" translate="no">predict_on_batch</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1220-L1266" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">predict_on_batch(
    x
)
</code></pre>
<p>Returns predictions for a single batch of samples.</p>
<h4 id="arguments_27">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input data. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset.</li>
</ul></li>
</ul>
<h4 id="returns_22">Returns:</h4>
<p>Numpy array(s) of predictions.</p>
<h4 id="raises_21">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of mismatch between given number of inputs and
expectations of the model.</li>
</ul>
<h3 id="reset_metrics"><code dir="ltr" translate="no">reset_metrics</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1015-L1023" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">reset_metrics()
</code></pre>
<p>Resets the state of metrics.</p>
<h3 id="reset_states"><code dir="ltr" translate="no">reset_states</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L455-L458" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">reset_states()
</code></pre>
<h3 id="save"><code dir="ltr" translate="no">save</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L954-L1008" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">save(
    filepath, overwrite=True, include_optimizer=True, save_format=None,
    signatures=None, options=None
)
</code></pre>
<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<h4 id="the_savefile_includes_2">The savefile includes:</h4>
<ul>
<li>The model architecture, allowing to re-instantiate the model.</li>
<li>The model weights.</li>
<li>The state of the optimizer, allowing to resume training
exactly where you left off.</li>
</ul>
<p>This allows you to save the entirety of the state of a model
in a single file.</p>
<p>Saved models can be reinstantiated via <a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model"><code dir="ltr" translate="no">keras.models.load_model</code></a>.
The model returned by <code dir="ltr" translate="no">load_model</code> is a compiled model ready to be used
(unless the saved model was never compiled in the first place).</p>
<p>Models built with the Sequential and Functional API can be saved to both the
HDF5 and SavedModel formats. Subclassed models can only be saved with the
SavedModel format.</p>
<h4 id="arguments_28">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">filepath</code></b>: String, path to SavedModel or H5 file to save the model.</li>
<li><b><code dir="ltr" translate="no">overwrite</code></b>: Whether to silently overwrite any existing file at the
target location, or provide the user with a manual prompt.</li>
<li><b><code dir="ltr" translate="no">include_optimizer</code></b>: If True, save optimizer&#39;s state together.</li>
<li><b><code dir="ltr" translate="no">save_format</code></b>: Either &#39;tf&#39; or &#39;h5&#39;, indicating whether to save the model
to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X, and
&#39;h5&#39; in TF 1.X.</li>
<li><b><code dir="ltr" translate="no">signatures</code></b>: Signatures to save with the SavedModel. Applicable to the
&#39;tf&#39; format only. Please see the <code dir="ltr" translate="no">signatures</code> argument in
<a href="https://www.tensorflow.org/api_docs/python/tf/saved_model/save"><code dir="ltr" translate="no">tf.saved_model.save</code></a> for details.</li>
<li><b><code dir="ltr" translate="no">options</code></b>: Optional <a href="https://www.tensorflow.org/api_docs/python/tf/saved_model/SaveOptions"><code dir="ltr" translate="no">tf.saved_model.SaveOptions</code></a> object that specifies
options for saving to SavedModel.</li>
</ul>
<h4 id="example_2">Example:</h4>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">from keras.models import load_model

model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;
del model  # deletes the existing model

# returns a compiled model
# identical to the previous one
model = load_model(&#39;my_model.h5&#39;)
</code></pre>
<h3 id="save_weights"><code dir="ltr" translate="no">save_weights</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L1010-L1129" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">save_weights(
    filepath, overwrite=True, save_format=None
)
</code></pre>
<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code dir="ltr" translate="no">save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:</p>
<ul>
<li><code dir="ltr" translate="no">layer_names</code> (attribute), a list of strings
  (ordered names of model layers).</li>
<li>For every layer, a <code dir="ltr" translate="no">group</code> named <code dir="ltr" translate="no">layer.name</code>
<ul>
<li>For every such layer group, a group attribute <code dir="ltr" translate="no">weight_names</code>,
  a list of strings
  (ordered names of weights tensor of the layer).</li>
<li>For every weight in the layer, a dataset
  storing the weight value, named after the weight tensor.</li>
</ul></li>
</ul>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"><code dir="ltr" translate="no">tf.train.Checkpoint</code></a>, including any <code dir="ltr" translate="no">Layer</code>
instances or <code dir="ltr" translate="no">Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code dir="ltr" translate="no">tf.keras.Model(inputs,
outputs)</code>, <code dir="ltr" translate="no">Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.keras.Model</code></a>,
<code dir="ltr" translate="no">Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"><code dir="ltr" translate="no">tf.train.Checkpoint</code></a> and
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.keras.Model</code></a> for details.</p>
<p>While the formats are the same, do not mix <code dir="ltr" translate="no">save_weights</code> and
<a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"><code dir="ltr" translate="no">tf.train.Checkpoint</code></a>. Checkpoints saved by <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#save_weights"><code dir="ltr" translate="no">Model.save_weights</code></a> should be
loaded using <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights"><code dir="ltr" translate="no">Model.load_weights</code></a>. Checkpoints saved using
<a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#save"><code dir="ltr" translate="no">tf.train.Checkpoint.save</code></a> should be restored using the corresponding
<a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restore"><code dir="ltr" translate="no">tf.train.Checkpoint.restore</code></a>. Prefer <a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"><code dir="ltr" translate="no">tf.train.Checkpoint</code></a> over
<code dir="ltr" translate="no">save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code dir="ltr" translate="no">self</code> for <code dir="ltr" translate="no">save_weights</code>, and greedily matching attribute
names. For <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#save"><code dir="ltr" translate="no">Model.save</code></a> this is the <code dir="ltr" translate="no">Model</code>, and for <a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#save"><code dir="ltr" translate="no">Checkpoint.save</code></a> this
is the <code dir="ltr" translate="no">Checkpoint</code> even if the <code dir="ltr" translate="no">Checkpoint</code> has a model attached. This
means saving a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code dir="ltr" translate="no">tf.keras.Model</code></a> using <code dir="ltr" translate="no">save_weights</code> and loading into a
<a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"><code dir="ltr" translate="no">tf.train.Checkpoint</code></a> with a <code dir="ltr" translate="no">Model</code> attached (or vice versa) will not match
the <code dir="ltr" translate="no">Model</code>&#39;s variables. See the <a href="https://www.tensorflow.org/guide/checkpoint">guide to training
checkpoints</a> for details
on the TensorFlow format.</p>
<h4 id="arguments_29">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">filepath</code></b>: String, path to the file to save the weights to. When saving
in TensorFlow format, this is the prefix used for checkpoint files
(multiple files are generated). Note that the &#39;.h5&#39; suffix causes
weights to be saved in HDF5 format.</li>
<li><b><code dir="ltr" translate="no">overwrite</code></b>: Whether to silently overwrite any existing file at the
target location, or provide the user with a manual prompt.</li>
<li><b><code dir="ltr" translate="no">save_format</code></b>: Either &#39;tf&#39; or &#39;h5&#39;. A <code dir="ltr" translate="no">filepath</code> ending in &#39;.h5&#39; or
&#39;.keras&#39; will default to HDF5 if <code dir="ltr" translate="no">save_format</code> is <code dir="ltr" translate="no">None</code>. Otherwise
<code dir="ltr" translate="no">None</code> defaults to &#39;tf&#39;.</li>
</ul>
<h4 id="raises_22">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ImportError</code></b>: If h5py is not available when attempting to save in HDF5
format.</li>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: For invalid/unknown format arguments.</li>
</ul>
<h3 id="summary"><code dir="ltr" translate="no">summary</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L1283-L1310" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">summary(
    line_length=None, positions=None, print_fn=None
)
</code></pre>
<p>Prints a string summary of the network.</p>
<h4 id="arguments_30">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">line_length</code></b>: Total length of printed lines
(e.g. set this to adapt the display to different
terminal window sizes).</li>
<li><b><code dir="ltr" translate="no">positions</code></b>: Relative or absolute positions of log elements
in each line. If not provided,
defaults to <code dir="ltr" translate="no">[.33, .55, .67, 1.]</code>.</li>
<li><b><code dir="ltr" translate="no">print_fn</code></b>: Print function to use. Defaults to <code dir="ltr" translate="no">print</code>.
It will be called on each line of the summary.
You can set it to a custom function
in order to capture the string summary.</li>
</ul>
<h4 id="raises_23">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: if <code dir="ltr" translate="no">summary()</code> is called before the model is built.</li>
</ul>
<h3 id="test_on_batch"><code dir="ltr" translate="no">test_on_batch</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1132-L1218" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">test_on_batch(
    x, y=None, sample_weight=None, reset_metrics=True
)
</code></pre>
<p>Test the model on a single batch of samples.</p>
<h4 id="arguments_31">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input data. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">y</code></b>: Target data. Like the input data <code dir="ltr" translate="no">x</code>,
it could be either Numpy array(s) or TensorFlow tensor(s).
It should be consistent with <code dir="ltr" translate="no">x</code> (you cannot have Numpy inputs and
tensor targets, or inversely). If <code dir="ltr" translate="no">x</code> is a dataset <code dir="ltr" translate="no">y</code> should
not be specified (since targets will be obtained from the iterator).</li>
<li><b><code dir="ltr" translate="no">sample_weight</code></b>: Optional array of the same length as x, containing
weights to apply to the model&#39;s loss for each sample.
In the case of temporal data, you can pass a 2D array
with shape (samples, sequence_length),
to apply a different weight to every timestep of every sample.
In this case you should make sure to specify
sample_weight_mode=&#34;temporal&#34; in compile(). This argument is not
supported when <code dir="ltr" translate="no">x</code> is a dataset.</li>
<li><b><code dir="ltr" translate="no">reset_metrics</code></b>: If <code dir="ltr" translate="no">True</code>, the metrics returned will be only for this
batch. If <code dir="ltr" translate="no">False</code>, the metrics will be statefully accumulated across
batches.</li>
</ul>
<h4 id="returns_23">Returns:</h4>
<p>Scalar test loss (if the model has a single output and no metrics)
or list of scalars (if the model has multiple outputs
and/or metrics). The attribute <code dir="ltr" translate="no">model.metrics_names</code> will give you
the display labels for the scalar outputs.</p>
<h4 id="raises_24">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of invalid user-provided arguments.</li>
</ul>
<h3 id="to_json"><code dir="ltr" translate="no">to_json</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L1241-L1256" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">to_json(
    **kwargs
)
</code></pre>
<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/model_from_json"><code dir="ltr" translate="no">keras.models.model_from_json(json_string, custom_objects={})</code></a>.</p>
<h4 id="arguments_32">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">**kwargs</code></b>: Additional keyword arguments
to be passed to <code dir="ltr" translate="no">json.dumps()</code>.</li>
</ul>
<h4 id="returns_24">Returns:</h4>
<p>A JSON string.</p>
<h3 id="to_yaml"><code dir="ltr" translate="no">to_yaml</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/network.py#L1258-L1281" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">to_yaml(
    **kwargs
)
</code></pre>
<p>Returns a yaml string containing the network configuration.</p>
<p>To load a network from a yaml save file, use
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/model_from_yaml"><code dir="ltr" translate="no">keras.models.model_from_yaml(yaml_string, custom_objects={})</code></a>.</p>
<p><code dir="ltr" translate="no">custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<h4 id="arguments_33">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">**kwargs</code></b>: Additional keyword arguments
to be passed to <code dir="ltr" translate="no">yaml.dump()</code>.</li>
</ul>
<h4 id="returns_25">Returns:</h4>
<p>A YAML string.</p>
<h4 id="raises_25">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ImportError</code></b>: if yaml module is not found.</li>
</ul>
<h3 id="train_on_batch"><code dir="ltr" translate="no">train_on_batch</code></h3>
<p><a href="https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L1025-L1130" target="_blank">View source</a></p>
<pre class="prettyprint lang-python" dir="ltr" translate="no"><code dir="ltr" translate="no">train_on_batch(
    x, y=None, sample_weight=None, class_weight=None, reset_metrics=True
)
</code></pre>
<p>Runs a single gradient update on a single batch of data.</p>
<h4 id="arguments_34">Arguments:</h4>
<ul>
<li><b><code dir="ltr" translate="no">x</code></b>: Input data. It could be:
<ul>
<li>A Numpy array (or array-like), or a list of arrays
(in case the model has multiple inputs).</li>
<li>A TensorFlow tensor, or a list of tensors
(in case the model has multiple inputs).</li>
<li>A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.</li>
<li>A <a href="https://www.tensorflow.org/api_docs/python/tf/data"><code dir="ltr" translate="no">tf.data</code></a> dataset.</li>
</ul></li>
<li><b><code dir="ltr" translate="no">y</code></b>: Target data. Like the input data <code dir="ltr" translate="no">x</code>, it could be either Numpy
array(s) or TensorFlow tensor(s). It should be consistent with <code dir="ltr" translate="no">x</code>
(you cannot have Numpy inputs and tensor targets, or inversely). If
<code dir="ltr" translate="no">x</code> is a dataset, <code dir="ltr" translate="no">y</code> should not be specified
(since targets will be obtained from the iterator).</li>
<li><b><code dir="ltr" translate="no">sample_weight</code></b>: Optional array of the same length as x, containing
weights to apply to the model&#39;s loss for each sample. In the case of
temporal data, you can pass a 2D array with shape (samples,
sequence_length), to apply a different weight to every timestep of
every sample. In this case you should make sure to specify
sample_weight_mode=&#34;temporal&#34; in compile(). This argument is not
supported when <code dir="ltr" translate="no">x</code> is a dataset.</li>
<li><b><code dir="ltr" translate="no">class_weight</code></b>: Optional dictionary mapping class indices (integers) to a
weight (float) to apply to the model&#39;s loss for the samples from this
class during training. This can be useful to tell the model to &#34;pay
more attention&#34; to samples from an under-represented class.</li>
<li><b><code dir="ltr" translate="no">reset_metrics</code></b>: If <code dir="ltr" translate="no">True</code>, the metrics returned will be only for this
batch. If <code dir="ltr" translate="no">False</code>, the metrics will be statefully accumulated across
batches.</li>
</ul>
<h4 id="returns_26">Returns:</h4>
<p>Scalar training loss
(if the model has a single output and no metrics)
or list of scalars (if the model has multiple outputs
and/or metrics). The attribute <code dir="ltr" translate="no">model.metrics_names</code> will give you
the display labels for the scalar outputs.</p>
<h4 id="raises_26">Raises:</h4>
<ul>
<li><b><code dir="ltr" translate="no">ValueError</code></b>: In case of invalid user-provided arguments.</li>
</ul>
</div>
<devsite-page-rating hover-rating-star="0" position="footer" selected-rating="0">
</devsite-page-rating>
</article>
</article>

</devsite-content>
</main>
<devsite-footer-promos class="devsite-footer">
</devsite-footer-promos>
<devsite-footer-linkboxes class="devsite-footer">

</devsite-footer-linkboxes>
<devsite-footer-utility class="devsite-footer">
<div class="devsite-footer-utility nocontent">

</div>
</devsite-footer-utility>
</section></section>
<devsite-sitemask></devsite-sitemask>
<devsite-snackbar></devsite-snackbar> <devsite-tooltip></devsite-tooltip>
<devsite-heading-link></devsite-heading-link>
<devsite-analytics>


</devsite-analytics>
 
</body></html>